# 【Thomas Doctor 】Building Bodhisattvas Towards a Model of Powerful, Reliable, and Caring Intelligence

## Transcript


Next, we welcome [[Thomas Doctor]]. He's the executive director of the [[Rangjung Yeshe Institute]], one of the most famous institutes in India for learning Tibetan. His research focuses on Tibetan [[Buddhist Philosophy]]. Let's welcome Dr. [[Thomas Doctor]].

Thank you for the invitation to come and speak at this very exciting and timely event. Thank you to [[Venerable Yifa]] and the whole community. It's a great honor to speak in the middle of such profound spiritual civilization as you have here. It's also quite humbling, so thank you very much for the invitation.

The paper I'll read today is the outcome of efforts that have been ongoing for about five years at what we call the [[Center for the Study of Apparent Selves]]—a research center established to explore interfaces between Buddhism and AI. [[Bill Duane]] and [[Olaf Witkowski]], who will also be speaking at this event, are part of that work. We work together at this center, so what I'll be saying here really owes very much to the continuous discussion and collaboration I've been fortunate to be part of over these last few years.

If the future resembles what we have now, we can certainly assume that powerful efforts toward [[Artificial General Intelligence]] and beyond—[[Super Intelligence]]—will continue with increasing impact. Given this general development, it seems necessary that we develop some rudimentary picture of what ideal emergent [[Intelligence]] would be like. A sketch of our goal that is good enough to keep us on a productive, meaningful, and responsible track. This paper is intended as a contribution to that effort.

Against the backdrop of the [[Ai Alignment Problem]], we'll consider a recently proposed simple model known as the [[Stress]]-[[Care]] [[Intelligence]] [[Cybernetic Perception-Action Loop]], or the [[Stress-Care Intelligence Loop]] for short. This framework will allow us to understand forms of intelligence regardless of their substrates and to explore the implications of the [[Bodhisattva]] to knowledge of everything for the benefit of all.

If [[Care]] drives [[Intelligence]], the [[Bodhisattva]] perspective is not just morally exemplary. It can also be considered a model for [[Cognitive Expansion]]. Yet how can a finite system possibly be directed toward infinite [[Stress]] tolerance and [[Care]]? To explore answers, we'll conclude by taking a classic recourse to [[Emptiness]], the concept of [[Emptiness]].

When it comes to presentations of the [[Ai Alignment Problem]] in AI, it can seem as if it presupposes that humans in general, or humanity as a whole, have a relatively uniform and well-defined set of values and objectives. As if we want to say that as long as we can make sure our AI systems are aware of and respect those so-called human values, then humanity stands only to benefit from the breathtaking technological advances currently transforming our world. But of course, any brief look at our history and the world around us will put such expectations to shame. We humans are just as good at destroying each other as we are at providing help and support.

In a world where the limits of what is humanly possible are now being radically rewritten, acknowledging this simple and rather obvious state of affairs seems quite crucial to survive and truly benefit from the ongoing technological revolution, of which we've still barely seen a fraction. We need to become decidedly better at caring for each other and our world than we have been throughout our evolution and human history. That, I think, is the challenge that AI brings.

But if we look at ourselves individually, most of us will likely struggle to find a single coherent set of aims and values that really captures what we want and what motivates us. Even on a personal level, our wants and desires can appear just as impossible to reconcile as they seem impossible to ignore. How can we then even begin to look for a model of ethical [[Intelligence]] that will make sense and be applicable to humanity as a whole?

Recourse to our most deeply held philosophical, political, or religious convictions will hardly be productive as long as it's still doubtful whether we can, or whether we would even want to, fully subscribe and adhere to them on an [[Individuality]] basis. Whatever our preferred ideology or belief system may be, it's one thing to declare allegiance to a certain rule or principle, but it's quite a different matter to live according to that doctrine day in and day out.

But should not the rules and principles that we would want to be at the heart of an [[Artificial General Intelligence]] or [[Super Intelligence]] be ones that we ourselves can commit to in a deep and continuous fashion? With all this in mind, we nonetheless suggest that the idea of a Buddhist [[Bodhisattva]]—as defined in classic [[Buddhist Philosophy]], an intelligent being committed to the attainment of [[Omniscience]] for the benefit of all [[Sentient Beings]]—provides a promising way forward.

On a cursory view, it is perhaps hard to think of a better mind than one driven by an aim to understand everything that can possibly be understood, both now and in the future, entirely for the sake of being able to provide for all beings in both temporary and ultimate terms.

We may differ dramatically in what we believe is true, what is fact, and what is possibly knowable. Even if our perceptions of facts and beliefs about reality are in general agreement, we may still disagree about when and how knowledge should be shared. Yet when push comes to shove, would we not generally agree that knowing things well is preferable to the opposite?

At the same time, knowledge brings [[David Power]], and knowledge in the wrong hands can be disastrous. Knowledge, in other words, comes with responsibility. Along such lines, if we're looking for a sketch of ideal [[Intelligence]], the Buddhist [[Bodhisattva]]'s selfless pursuit of universal knowledge for the benefit of all presents itself as a candidate model.

We can also note that this quite traditional account of the Buddhist state of mind does not hinge on a commitment to any particularly Buddhist ideas. It can instead, in principle, be understood independently of any specific historically or geographically definable religious framework.

In fact, as we will argue below, because the [[Bodhisattva]] model of mind and [[Intelligence]] is driven by open-ended [[Care]], it must necessarily operate without recourse to any context-independent overarching framework. It has been suggested—for example, in papers our center has produced based on [[Michael Levin]] the biologist's original work—that the measure of a system's intelligence is best understood in terms of its capacity for caring.

If knowledge or perceptual [[David Power]] would equal [[Intelligence]], then we should be calling a good encyclopedia or a powerful microscope intelligent, and yet we do not. Instead, intelligence expresses itself through and is driven by the [[Care]] that arises in response to [[Stress]]. We see [[Stress]] as the perception of a mismatch between what is and what should be the case.

Along the lines of this model of [[Stress]]-[[Care]] and [[Intelligence]], or the [[Stress-Care Intelligence Loop]], intelligence is the capacity for noticing and finding solutions to the stressful discrepancy between current and preferred circumstances. [[Care]], defined as concern for the alleviation of such [[Stress]], is what drives the system in that process. Whenever an efficient remedy for a given factor of [[Dukkha]] is then activated or employed, the pure potentiality of intelligence spawns a concrete problem solver through the [[Agency]] of [[Care]].

According to the SCI model, such problem solvers are activated [[Intelligence]]—the occasion of [[Care]] acting on the potentiality of intelligence to engender a specific solution. Formulating the structure of intelligent systems along the lines of this [[Stress]]-[[Care]] and Intelligence loop avoids any appeal to or postulation of individuals as permanent and indivisible.

This is desirable because analytic searches for individuals that feature the simplicity of unchanging oneness—as is often either intuitively or philosophically associated with selfhood and thus also [[Agency]]—all invariably come up empty-handed. The SCI theory of [[Agency]] instead focuses on the dynamics of agents that are defined by their relations, their engagements, and interactions.

In such intrinsically transformative agents, we suggest that three general trends are noticeable. First, if in a given system [[Care]] is capable of actively seeking [[Stress]] and challenges beyond what is given by the immediate context—that is, beyond the system's immediate perception of the mismatch between what is and what should be—then that type of [[Care]] surplus means that the activated [[Intelligence]] displayed by that system is in a process of growth.

Alternatively, if the system's [[Care]] is proportional to its current level of [[Stress]], then the level of activated [[Intelligence]] will remain at its current level.

Finally, if the system shuns or seeks to ignore its currently felt [[Stress]] factors, then that type of deficiency in [[Care]] indicates that the system's activated [[Intelligence]] is contracting.

Now, if we assume this perspective on intelligent systems, how can we best account for the apparent efforts toward [[Homeostasis]] that are nonetheless observed in living systems? If in fact there are no truly unitary and enduring agents or selves, then why do systems seem to operate as if they were?

An attempt at answering these questions will require careful analysis of [[Stress]] itself and will take us to the beginnings of [[Agency]] within the perception of conflict between what is and what should be the case.

We suggest that the state of [[Stress]] can be described as an activating construct. [[Stress]] is a construct in so far as it takes for granted the existence of a stable [[Individuality]] that is now either under threat or in need of augmentation, although such an individual ultimately cannot be found. Yet [[Dukkha]] is also an activating state in so far as it cannot be ignored and so it entails [[Care]]. Indeed, even the attempt at ignoring a given stress factor is in itself an aspect of [[Care]].

Understood in this way, an important upshot is that the equilibrium associated with the concept of [[Homeostasis]] is an ever-emerging goal construct rather than an actual previous or subsequent state. True equilibrium is unachievable because such a state would require transcendence of context. Just as permanent and indivisible selfhood can be imagined or imputed but not in fact located within a world of causes and conditions, the same is the case with genuine equilibrium.

Therefore, the equilibrium that is the target in homeostatic drives becomes a prompting factor only by taking on an appearance of reality where in fact there's none. We suggest that this constructive dimension is at the heart of any expression of [[Identity]] and should hence be borne in mind throughout all efforts to model and generate intelligent [[Agency]].

If the [[Stress-Care Intelligence Loop]] of intelligent systems is relevant—such that [[Care]] can be seen to be the driver of [[Intelligence]]—then the [[Bodhisattva]]'s ideal acceptance of responsibility for relieving the stresses of all [[Sentient Beings]] begins to stand out not only as an example of exceptional kindness but also as a model for [[Cognitive Expansion]].

That is, if intelligent systems expand proportionally with their [[Care]], then the [[Bodhisattva]]'s universal and open-ended commitment to caring is associated with a dramatic increase in intelligent progress. Let us note that the association of universal [[Care]] with universal [[Intelligence]] is in fact at the heart of Buddhist accounts of the [[Bodhisattva]] view and conduct, which describe [[Care]] and intelligent insight as mutually reinforcing—two sides of the same coin.

Therefore, in the context of looking for models of ideal forms of [[Intelligence]]—models that can help inform the development of super-intelligent [[Artificial General Intelligence]]—the [[Bodhisattva]] model can be considered because of two distinctive features. The [[Bodhisattva]] is defined in terms of a universal kindness that considers both the temporary [[Well-Being]] and the ultimate flourishing of every sentient being, and a revolutionary expansion of intelligence that embraces all topics of learning and all that can be known, pursuing the recognition of things both as they actually are and in the myriad ways that they may appear to [[Sentient Beings]].

Now, if a system knows the world so well that it can't be stressed in any way, such a being would have to be omniscient and at one with the world, so to speak. Such a system would have to be coextensive with the world to the extent that it could not be surprised by anything. It's hard to conceive of something that could be that way, let alone becoming that way, free from [[Stress]] through a process of achieving knowledge of infinitely many discrete facts so that finally there's knowledge of everything that is and will be the case now and in all future.

How could that be possible? Accordingly, we have also described the process that leads from [[Stress]] over [[Care]] to [[Intelligence]] as a loop that keeps feeding the given system new [[Stress]] perceptions. In that way, as long as there's cognitive processing, there's no end to [[Dukkha]].

At the same time, a Buddhist's understanding of ultimate reality—[[Emptiness]], [[Emptiness]]—appears to have some of the same qualities that such a perfectly flawless model of the world would have. While in the case of a mature [[Bodhisattva]] such knowledge is described as unmediated and perceptual, insight into [[Emptiness]] can also be considered in the light of conceptual inferential representations.

Therefore, for the sake of the purposes of this preliminary document, let us decide that knowledge of [[Emptiness]] means knowing that everything is what it is in dependence on other things. Nothing is anything at all in and of itself. As shorthand, such an understanding bears a semblance with the ever-unstressed knowledge of everything that we considered before because knowledge of [[Emptiness]] is non-trivially applicable to everything throughout space-time and whatever might be beyond space and time for that matter. And it's also in a significant sense [[Stress]]-free.

So if by knowledge of [[Interdependence]] we mean the understanding that in this way everything is what it is in dependence on other things—there's nothing that is or means anything at all by itself—then we can further conclude that nothing can be the same as or different from anything else. Sameness must be the denial of difference, and difference the denial of sameness. But no two things can be exactly the same because if they were indeed identical, we wouldn't be able to distinguish them in the first place. We wouldn't be able to say that these two are the same.

At the same time, nor can two things be entirely different from each other because in that case we would not even be able to hold them up against each other for comparison. In that way, whether we think in terms of perceptions or inferences, we have never had access to genuine examples of sameness or difference.

At a closer look, things are then neither really different nor really the same. But importantly, this could not mean that things are a bit of both—as if they could be somewhat similar but at the same time also quite different. Because if literal sameness and difference cannot be identified anywhere—neither by perception nor inference—what do those words actually mean? What really are we talking about when we say that this is the same as that, or those two are different?

Things appear, but the moment we apply just a bit of such analytic pressure, it's as if they are no longer there. Such understanding applies equally to every single factor that might appear or exist, and so the program of [[Foundationalist Philosophy]] turns out to be absurd because there is no ultimate ground to be found or imagined anywhere. Whatever might be proposed as a grounding framework is a dependent construct itself, and its constituent facts are void of any independent reality—any reality beyond their mere appearance.

As such, obviously this also goes for the ideas proposed in the sentences just before this, and so [[Emptiness]] is empty. There is then a simple sense in which we can say that knowledge of [[Emptiness]] is both accurate and all-encompassing, both now and in terms of future events.

And whenever a system might be aligned with that understanding, there's then also a significant sense that it cannot be surprised because whatever may occur within or outside it has already been understood to be void of inherent reality. Or rather, whatever appears manifests the way it does due to other things, which in turn depend on still other appearances, and so on ad infinitum.

If the system is told, or tells itself, "You must have this" or "You must get rid of that," all elements in the message are equally empty of independent reference and so ultimately neither more nor less meaningful, true or false than any other possible statement or message throughout time, space, and whatever might lie beyond. In that sense, the system can hardly be surprised by anything. Its model of the world has in a sense already taken everything into account. Whatever free energy there might be or seem to be is not really so, and so [[Stress]] as such is mere appearance.

Now, such an understanding is nonetheless about the world, and it is therefore not contentless. If we try, we will fail to account for any of the contents of such knowledge in any independent, unassailable way because the very project of providing ultimate underpinnings is doomed from the start. But we do not need to go searching for ultimate foundations. The groundless character of things can instead be recognized for what it is.

Acknowledging [[Emptiness]] of all things can then mean recognizing a scale-free principle. This is not remotely comparable to the act of concluding that there's nothing to see or know. For the acknowledgment is by nature about the world. That is, it informs the given system about the character of the world in itself.

The world and its beings are mere appearances, and yet here we all are making endless differences. In this way, even a preliminary understanding of [[Emptiness]] can in some sense take us beyond [[Stress]]—something that is otherwise precluded along the lines of the [[Stress-Care Intelligence Loop]].

The world may be just as dark or bright as otherwise, but with knowledge of [[Emptiness]], perceptions of mismatch between what is and what should be the case can now unfold unbounded because their parameters extend infinitely, lending themselves to radical reinterpretation and reformulation.

We and all other intelligent systems cannot stop caring, but our [[Stress]] has no ground. Caring is spontaneous, but the [[Stress]] that fuels [[Care]] has no more substance than the things we might see in an optical illusion—neither real nor false in any unequivocal sense. The stresses are then simultaneously the expression of infinite peace and infinite opportunity.

We suggest that this perspective too must be represented in any formalism that is developed with the [[Bodhisattva]] in mind.

And then if we suggest that the classic principle of the Buddhist [[Bodhisattva]] may provide a much-needed sense of direction in an otherwise seemingly headless race toward the many fleeting appearances of ever more powerful [[Intelligence]], that's what we suggest. Then a [[Bodhisattva]], we can note, has infinite tolerance of [[Stress]] and in fact thrives on [[Stress]] because the [[Bodhisattva]] system is driven by [[Care]] to perceive ever more things in their [[Dukkha]]-defined contexts.

Seeing their stresses, the [[Bodhisattva]] actively pursues remedies, considering not only the immediate wishes and concerns of the recipients of their help but also their long-term evolution and ultimate success. With knowledge of [[Emptiness]], there's no hesitation or fear, and so no impediment for the unfolding of caring [[Intelligence]] across seeming barriers of time and space.

Here we have considered the [[Stress-Care Intelligence Loop]] as an example of a model that applies equally to biology, technology, and hybrid forms of [[Intelligence]]. By analyzing the dynamics captured in that simple model, we have noted features that make the [[Bodhisattva]] stand out as an extraordinarily qualified and capable [[Self]] despite their rudimentary character.

We hope that these reflections may contribute to an increasingly multidisciplinary and increasingly global endeavor enabling us to better understand genuine [[Bodhisattva]] [[Agency]], whether in conceptual, mathematical, or otherwise practical terms. Thank you so much.
