# Creating and Communicating Across the Intelligence Spectrum

## Transcript


# Creating and Communicating Across the Intelligence Spectrum

So normally when we approach problems, we approach them from the prefrontal cortex—the thinking brain. Something we can get from these sorts of exercises is this: What if we engage different parts of our intelligences to address problems?

With that, let me introduce Mike. Mike is the Vannevar Bush Distinguished Professor of Biology at Tufts and associate faculty at Harvard's Wyss Institute. He serves as director of the [[Allen Discovery Center]] at Tufts and co-director of the [[Institute For Computationally Designed Organisms]] at Tufts and UVM.

He's published over 400 peer-reviewed publications—I think three just this morning—across developmental biology, computer science, and philosophy of mind. Dr. Levin received dual degrees in computer science and biology, followed by a [[Play The Hand You'Re Dealt]] from Harvard. His graduate work on the molecular basis of [[Left-Right Asymmetry]] was chosen by the journal Nature as a milestone in developmental biology in the last century. He [[Dissociative Identity Disorder]] his postdoc at [[Harvard School Of Medicine]] in cell biology and started his independent lab in 2000.

His group at Tufts works to understand [[Cognition]] and problem-solving across scales in a range of naturally evolved, synthetically engineered, and hybrid living systems. His lab has pioneered approaches to organ [[Regeneration]], cancer reprogramming, non-genetic modification of body plans, and the engineering of novel living protoorganisms. A lesser-known fact is that Mike is one of the foremost super-spreaders of impostor syndrome. I may be projecting.

I've had the amazing opportunity to work with Mike on some projects, and some of the work we've done together is actually what brought me here to X. I'm so pleased and grateful to have you with us today, Mike. With that, I'll hand it off to you.

---

Thank you so much, Bill, for that extremely kind introduction and for the opportunity to share some ideas with you. Can everybody see the slide?

Yes.

All right. Perfect. I have a challenge in 20 minutes to transmit some fairly unconventional concepts. I'll do that and then I can answer questions about the details of how it all works. Actually, at this website you can download all of the data sets, the software, the controls—everything is here. And then this is my own personal thoughts about what this all means.

I want to start with this classic piece of art: Adam Names the Animals in the Garden of Eden. This worldview, even for people who aren't overtly religious, permeates modern science. It's the idea that there are distinct categorical species, all different from each other, innumerable, and we know what they are. And then Adam here is different. I think we're going to have to blow this up and show the ways in which we dissolve that.

But what's interesting about this depiction is that, according to the old biblical story, it was Adam's task to name the animals. God couldn't do it. The angels couldn't do it. It had to be Adam. In these ancient traditions, naming something means you've discovered its true inner nature. By discovering its name and giving it the right name, you've learned something profound about it. And I think that part is absolutely right.

We're going to try to get rid of this anthropocentrism and [[Brain Chauvinism]], but we're going to keep part of this.

The first thing is that we now know, ever since evolution and developmental biology, that this standard modern adult human—which features so prominently in stories of philosophy 101, all these things about what humans do—we actually know that we are at the center of several continua. These are continuous, slow processes that got us from a single cell on an evolutionary or developmental scale. Whatever you say about this human regarding the ability to understand, [[Moral Worth]], responsibilities, credit and blame, and all those things—whatever this magical agential glow is that modern humans have—you would have to be able to tell a story of how we got here slowly and gradually from these continua.

More importantly, there's now an additional continuum, which means that both along the biological axis and the technological axis, you can make slow and gradual changes and get progressively further and further from this archetype. What we need in science and philosophy are stories of transformation, not magical categories like a "real human" or "proof of humanity certificates." We are at a place where we now understand none of that works.

What I think is really interesting is an analogy to the electromagnetic spectrum. Back in the day, before we had a mature theory of electromagnetism, we had lightning, static electricity, light, magnets, and various other phenomena. We thought those were all different things. Not only [[Dissociative Identity Disorder]] we think they were different, but we were actually only directly sensitive to an extremely narrow part of this whole spectrum.

What happened? We acquired a good theory of electromagnetism, and that allowed us to do several things. First, it allowed us to understand that things we think of as quite different are actually the same thing—different expressions of the same underlying dynamic. That's an incredibly powerful unification. Second, it allowed us to build technologies and realize that while we're directly sensitive only here, that's just a contingent fact of our evolutionary history. With the right equipment and tools, we're now sensitive to all of this.

Of course, there are many applications. What I'm really interested in is creating tools—conceptual tools and practical bench tools—because the implications of this work have very practical effects on birth defects, [[Regenerative Medicine]], cancer medicine, and bio-engineering.

What we want are tools that allow us to see across the spectrum of minds. We want to fight the [[Mind Blindness]] we have by default because of our evolutionary history. We're hyperfixated on three-dimensional space and medium-sized objects moving in three-dimensional space as intelligent beings. I'm interested in developing a framework where we can see how you get all the way from what we call "passive matter"—and by the way, I'm no longer sure there is any such thing—all the way up to human level and beyond, to metacognitive minds. I want to understand these things together as being on the same spectrum: not just mammals and birds, but all kinds of weird organisms, including things that aren't even physical, such as patterns within media.

We need this not only for biomedical and bio-engineering applications, but because this is a profoundly important step towards an ethics of a mature species that has some chance of long-term survival—meaning us.

The first thing I want to remind us all of is that we all start life as a single cell—a little bag of chemicals that obey physical laws. Slowly, surely, there's this gradual, amazing process of embryonic development that takes the system from being the domain of physics and chemistry to being the domain of psychology and behavioral science. We know from developmental biology that there is no special magical point where these things kick in and you become a mind as opposed to previously being just physics. We need to understand the scaling of mind as it goes from these very simple things to something much more complex.

There are some other paths along this journey. I won't have time to talk about it today, but if anyone wants to ask, we can discuss what happens later in terms of [[Dissociative Identity Disorder]] of your body, which is basically [[Cancer]], and some other even weirder things that can happen where your cells can have an entirely new life even after the death of the original human donor, as [[Anthrobots]]. The key to understanding this process is that, very differently from how we build our computers and robots, we are made of an [[Agential Material]].

The reason robots and computers don't get [[Cancer]]—at least for now—is because they're made of passive parts, and then hopefully the whole system has some degree of [[Intelligence]]. But life isn't like that. Every part of our body has agendas and competencies.

This is a single cell known as a paramecium—just one cell, no brain, no nervous system. This thing has massive [[Competency]] within its own tiny cognitive cone. It only cares about things with a very short spatial-temporal horizon. But put together, they can form much greater things.

A lot of folks will say that [[Intelligence]] goes down to the single cell level. But it's actually well below that. The molecular networks inside cells already have six different kinds of learning, including Pavlovian conditioning. If you're interested in things like causal information theory or [[Integrated Information]] that some people think is associated with [[Consciousness]], those already exist at the molecular network level inside that cell.

The tiniest material already has aspects of learning and [[Integrated Information]]. We're making use of that by developing applications in drug conditioning to train these pathways. Our bodies have this amazing nested [[Intelligence]]. I call it a [[Multiscale Competency Architecture]] where every level of organization has the ability to learn and solve problems in different spaces.

[[William James]] defined [[Intelligence]] as the ability to get to the same goal by different means. That's a very good definition because it doesn't say it has to be a brain. It doesn't say what [[Problem Space]] you're operating with. It just says you have a capacity to navigate that space and solve problems.

The very first problem that the collective has to solve is to get aligned towards a specific journey in [[Anatomical Morphospace]]. When you look at an early embryo—say, a blastocyst with about 100,000 cells—we say "There's an embryo." But what are you counting when you say there's one embryo? What is there one of? Actually, there are 100,000 cells, and within each one are organelles and chemicals. What are you actually counting?

I'm going to say that what you're actually counting is alignment. You're counting the fact that all of these cells, under normal circumstances, are committed to the same story—the same model of where in [[Anatomical Morphospace]] they're going to go. [[Anatomical Morphospace]] is the space of all possible geometric configurations of the body. All these cells are going to collaborate on building one particular structure. They're going to get from the point of a single cell to the configuration of this complicated embryo because they've all bought into the same story about where they're going to go.

What keeps these things aligned is a [[Self-Model]] that they all accept. I said under normal circumstances because you can make little scratches in this blastula, and every island that forms doesn't know about the existence of the others. They form their own embryo, and then you eventually get twins and triplets. The number of individuals in this embryo is not set by genetics. It's not obvious. It's not determined upfront. They can [[Self]]-organize by all aligning towards different aspects of that story and complete the journey on their own.

The very first thing that has to happen is that a bioelectrical mechanism aligns them together. It's a bioelectrical network that allows them to remember what pattern they're supposed to build. That's what makes an embryo an [[Individuality]] rather than millions or billions of cells.

This has many implications in cognitive science. My lab has driven the development of a parallel between [[Cognition]] and [[Morphogenesis]]—between the formation of the body and the formation of the mind. They're basically the same problem.

When you look at this dissociation, there are many things we learn about [[Commissurotomy]] patients and dissociative [[Identity]] disorders. What's really interesting is the scaling of goals. I coined this thing called the [[Cognitive Light Cone]], which is meant to be the boundary of the [[Self]]—the thing that distinguishes a self from the outside world. It's the scale of the largest goal you can pursue—not the range of your senses or the reach of your actuators, but the size of the largest goal state you can remember and pursue.

In single cells, they have tiny goals. They have short memories and short anticipatory [[David Power]]. Their goals are things like pH—scalers, single numbers about things within the cell. But when they get together into networks, that electrical network allows them to store grand-ose goals.

Here's a salamander. These amphibians regenerate most of their body parts—limbs, eyes, jaws, spinal cords, and so on. If you amputate anywhere along this plane of a limb, the cells immediately sense they've been taken away from their goal. They work really hard to rebuild. When they get there, they stop. How do they know when to stop? They stop when a correct salamander limb has been completed, when they get back to their homeostatic state.

No [[Individuality]] cell knows what a finger is or how many fingers you're supposed to have, but the collective absolutely does. It performs a means-ends analysis to get back to where it needs to be once you've deviated.

This whole thing is not just about damage. It's not about just fixing a surgical defect. It also allows you to do these amazing things. Here's a tadpole we made. What you'll notice is there are no eyes where the eyes belong, but instead we put an eye on its tail. There's a whole story about how we do it, but what happens is that this eye makes an optic nerve. That optic nerve doesn't go to the brain. It synapses on the spinal cord or sometimes on the gut, sometimes nowhere at all. The most amazing thing is that these animals can see. We know because we built a device that trains them for visual learning tasks, and they can see perfectly well.

This is shocking. Why doesn't it take additional rounds of mutation and selection to radically change this animal's sensory-motor architecture and make things work? You don't need it. It works out of the box because that process where all cells, every single time, have to solve the problem of what we are and where we're going is never obvious to them or assumed. The story that genetics tells you what you're going to be is not the right story. Instead, genetics builds a [[Problem-Solving Agent]] that is very creative in interpreting its environment and the genetics that have been passed down.

That's why there are hours of examples of creative problem-solving where you don't need additional rounds of mutation because the material never thought it was going to be a perfect tadpole. It's able to adapt to all kinds of novel manipulations.

I've been mentioning [[Bioelectricity]]. What we've developed are methods to read and write the mind of the body the way neuroscientists have done in the brain. Here you're seeing [[Membrane Potential (Vmem)]]-sensitive fluorescent dyes tracking [[Bioelectricity]]. The color corresponds to voltage, and you're seeing a time-lapse of a frog embryo. What you're seeing is all the electrical communications that allow this thing to be more than the sum of its parts.

[[Bioelectricity]] is the cognitive glue that binds your neurons together into not just a pile of neurons, but into you. [[Bioelectricity]] is also the cognitive glue that binds [[Individuality]] cells into a collective that can remember what a tadpole is supposed to look like. We have lots of tools for simulations that we've created. We're trying to merge those with all kinds of connectionist ideas about attractors in memory networks that can do [[Downward Causation]] and navigate space.

One way we know that bioelectric pattern is actually the memory of this [[Collective Intelligence]] is that we can read and modify it. Let's get back to the beginning of the talk. What I was pointing out is that there are some really weird intelligences out there that we're not familiar with. We use [[Morphogenesis]] as one example. Groups of cells are an unconventional [[Collective Intelligence]] that navigates a really strange space we cannot visualize—a high-dimensional anatomical morph space.

Our goal is to learn to communicate with that [[Intelligence]], predict its behavior, and ask it to do different things in biomedical contexts. To do that, we've developed a bioelectrical interface. Now we can directly read the memory states of this intelligence and try to rewrite them, give it new ideas.

What idea could you give it? Well, one thing you might say is that a proper tadpole should have an eye on its tail or gut. You would do that by injecting RNA that encodes a particular ion channel protein—in this case, a potassium channel. You establish a little [[Membrane Potential (Vmem)]] that says to the surrounding cells: you should build an eye.

How [[Dissociative Identity Disorder]] we know? Ten years of work trying to understand how cells interpret these [[Membrane Potential (Vmem)]] gradients. When you do that, you make an eye. These eyes have all the right structures—lens, retina, optic nerve. If you only inject a few of them, the blue ones are the ones we injected, they will actually recruit their neighbors to make this lovely lens sitting out in the tail of a tadpole. We didn't have to touch these other cells. All we said is: you guys should make an eye. They take it from there and say, "Well, there aren't enough of us. Let's get our friends to help." They convince the others. It's really a process of trying to infect them with a better world model of what they should be doing. There's actually a debate, and the cells resist, but when they win, you get this beautiful eye.

Of course, there are many other collective intelligences that scale to problem size on their own. Here's a useful application where we're looking for limb [[Regeneration]]. Frogs, unlike salamanders, do not regenerate their limbs, nor do we. After losing a leg, there's normally no regeneration at 45 days. But if we give the cells an early signal—a wearable bioreactor with some ion channel payload—it immediately tells the cells to get going. 45 days later, you've got toes, a toenail, eventually a touch-sensitive and functional leg.

The most important thing is that like any good [[Self]], you do not micromanage the molecules. When I'm talking to you right now, I'm not worried about reaching into your brain and arranging all the synapses so you remember what I've said. I'm giving you information on a very thin communications channel, and I'm trusting you as a high-end cognitive system to do all the biochemistry downstream required for you to react to what I'm saying.

The same thing is true here. This signal was present for 24 hours. After that, we've shown a year and a half of leg growth during which time we don't touch it at all. The goal is not to micromanage it. It's not to tell the cells what to do. It's not to 3D print scaffolds for stem cells. None of that. The goal is to convince it on day one that this is the path you should go—the leg-building path is the right one, not the scarring path.

In the last two minutes, I want to show you something even further removed: the remarkable [[Plasticity]] of life. If I show you this video and ask what you think this is, a reasonable guess would be that it's a primitive organism from a pond. If I ask what genome it would have, you'd guess it has one of these ancient genomes for tiny creatures.

I can tell you that this genome is 100% Homo sapiens. These are perfectly normal human adult cells. They haven't been manipulated with any [[Artificial Life]] circuits. There are no scaffolds, no transgenes, no genomic editing. What this is, is taking cells from an adult human patient—tracheal epithelial cells from their airway—and giving them a chance to have another lease on life, to reboot their multicellularity.

The original patient may or may not be alive, but the cells, in a slightly different environment (not that different actually, but liberated from the rest of the body), could have this completely novel life. You wouldn't know that by looking at it, but this doesn't look like any stage of human development. It's completely novel. They have novel capabilities. Half their genome is expressed differently. Each red dot is a gene that's expressed differently than it would have if it had stayed in your airway. About half the genome—9,000 genes—are completely altered because genetics doesn't drive what you are. Genetics is a resource book that active systems dip into as [[Affordances]].

One cool thing they can do is that if you plate a bunch of human neurons and put a big wound through them, the bots will gather together into what we call a superbot cluster. They start knitting the two sides together. When you take it off, you can see what happened. Who would have thought that your tracheal cells, sitting quietly for long periods dealing with mucus, would have the ability to [[Self]]-assemble into a novel protoorganism with its own life, its own gene expression, its own set of behaviors and capabilities we're only now beginning to scratch the surface of?

This is going to be personalized body therapeutics. These [[Hybrots]] made of your own cells don't need immune suppression. You can put them back in the body, and we're working up the full list of what they can actually repair.

To end: life is a problem-solving process from the beginning. Almost any combination of evolved material, engineered material, and software is some viable [[Self]]. Life is incredibly interoperable. [[Cyborg]], [[Cyborg]], and [[Chimeras]] of every kind all make use of these ingressing patterns, which create viable beings.

Everything that Darwin saw when he said "endless forms most beautiful"—meaning natural life—is a tiny blip here on this enormous space of beings with whom we are going to share our world. Many of these things already exist. Many more are forthcoming.

What we need is better recognition of other minds and ethical relationships with them so we can all have a more positive [[Embodiment]]. This idea—what I think of as it—has a word that GPT-4 came up with for me: [[Synthibiosis]]. This is the idea that we're going to have to get better at recognizing other minds and ethically relating to them.

This is what I think the future of the garden of Eden is going to look like. It's going to be very weird. It's on us to really understand what we're dealing with: [[Xenobots]], [[Anthrobots]], augmented humans, [[Chimeras]] of all kinds. We're really going to have to raise our game because the things that used to work—what do you look like and where and how [[Dissociative Identity Disorder]] you get here (meaning factory versus trial and error of evolution)—those categories aren't going to be any good anymore.

I'm going to skip ahead and just point out that there's some amazing people who deserve credit for all the things I showed you today. These are my postdocs and graduate students. We have lots of remarkable collaborators, our funders, and these are three spin-off companies from our work that support our research. The biggest thanks go to the model systems because they do all the heavy lifting and teach us about this stuff.

I'll stop here and thank you for listening.

---

All right, you have all been initiated to the [[Michael Levin]] fire hose of knowledge. I'll start with a few questions and then we'll open it up to the group.

One of the things I find really interesting about your exploration of [[Bioelectricity]] is this idea of finding the right lever at the right scale. You use the term micromanaging. So for moving my arm, if I wanted to take control of each atom and manually push it around versus just having a few discrete places where some electricity makes it do this—that makes me think that here at X, we talk about cutting Gordian knots, which is some shortening of the way, some technical ability that makes the problem much more tractable. That really aligns with finding the right tool at the right scale.

Thinking about all the potential scales you mentioned and the different problem spaces—from transcriptional to morphological—how [[Dissociative Identity Disorder]] you figure out that [[Bioelectricity]] was a high-value, high-leverage point out of all the possible spaces? How do you narrow down which one you think will be useful in that way?

Yeah, it's an art. I don't have an algorithm for it, but I will tell you some heuristics. The biggest thing we have to work on is detecting other minds. In other words, who am I talking to when I exert influence? What am I talking to, and what is their level of [[Competency]]?

If you insist on micromanaging things, if you think the world is built like Legos, then your assumption—and it's just an assumption—is that the [[Competency]] level of your components is very low and that it's on you to micromanage them. Now the question is: can we test this and look for other things?

If you were an octopus, your limbs have a degree of autonomy. Whatever signals you send to them are suggestions, and the limbs will take some, they won't take others. What you're doing is hacking everything—your environment, your parts. This is a notion called [[Polycomputing]].

This is something [[Josh Bongard]] and I developed as a system to formalize the idea that biology—and I think soon engineering—is a soup of diverse observers, all of them looking at the exact same set of physical events and interpreting them differently. Any given computation doesn't have one objective, agreed-upon thing that it's computing. It's actually up to multiple observers.

Josh has some very beautiful work on physical events that, if you look at them one way, you see an AND gate. If you look at them another way, you see an OR gate. It's up to the observer to look at the exact same set of events and say, "What the heck does this mean for me? How am I going to use it?"

Learning to use your arms as a baby or as a baby octopus is a very different task because your assessment of the autonomy of the thing you're trying to talk to will be quite different. We can talk about some tools we've developed for that, but the question is: who are you talking to, and what is their level of autonomy that you can usefully exploit?

As engineers and technologists, we immediately begin to think about how we might develop tools. But even the ability to perceive the possibility of a tool means there has to be some precursor, human cognitive step of realizing that might be possible.

What you're pointing to sounds like a radical theory of minds—maybe instead of "mind," plural minds. And then two, like radical empathy, right? To abandon the human scale and look at lower scales but also superhuman scales. There's a line from one of our shared papers—I think [[Thomas Doctor]] came up with it—saying that if [[Consciousness]] evolves on other substrates, it might be so different from ours that we might not even recognize it, even though it's there, because it's so different.

That's right.

I think part of your gift is an intuitive sense of that radical empathy. First, do you agree? Second, how might we perceive these things? Do you have any thoughts on how we can actually perceive these things?

Yeah, absolutely. I'm actually finishing a talk called "Radical Empathy," and I'll just show something quickly. This is a slide I jumped over.

The idea is that over time, we've expanded the set of things we're willing to understand as numbers, right? We had counting numbers, then we came up with zero—people were a little freaked out. Then negative numbers, then irrationals. People got killed over it. Then infinities. Every single time we've had to make a conceptual leap to see it. We've had to break a whole bunch of assumptions that established the old categories. We've had to figure out how to do something useful with them.

In our case, we've had to develop what I think of as active [[Compassion]] towards them. The point is this: I think we can progressively work up the ladder and say, well, we all know how to have [[Compassion]] here, but we actually can get down to cells and all kinds of weird stuff and then all kinds of machine-looking things and then actually things that aren't physical at all—meaning patterns and excitable media that I think are actually agents. And then something really weird that I won't have time to talk about today: not even active patterns, but frozen patterns.

What I think this all means is exactly what you said. When I say apparatus, I don't just mean the third-person science of creating equipment outside ourselves. I also mean the first-person science of modifying your own evolutionary firmware to enable you to have thoughts you couldn't have before. I think the meaning is how to enlarge categories so that you can recognize and have relationships with entities that are extremely different from you.

I take this to be—and I don't know if this is getting too weird—the difference between chemistry and alchemy, right? When you do chemistry, it's understood that you're manipulating stuff in the third person and you'll be the same at the end of the chemistry experiment as you were at the beginning. What I take to be the message of alchemy is that there is some work where it doesn't work like that. You cannot remain the same. You can't do it purely outside yourself and be the same at the end as you were when you went in. You have to actually change your own structure and [[Cognition]] in order to really understand what you're working with. And I think that's certainly going to be the case here.

Yeah, I think that's radically transgressive and beautiful in two ways. One is that you're talking to worlds of frontier science that put first-person experience front and center, whereas normally our tool set as engineers and scientists treats first-person experience as unreliable. You're actually saying it's a necessary but insufficient condition for those other kinds of sciences. And you and I have talked quite a bit over the years about testing institutions' window of tolerance for getting into that weirdness.

So the first thing is this idea that first-person experience matters from a scientific standpoint, and then the second part is like Varela's [[Enactive Approach]], where the idea of a neutral independent observer is a radical simplification that helps some models and some problem spaces but in others just puts it in the tank.

Yep. I agree with that.

All right. With that, I would love to turn it over. People are diving for Q&A.

Hello. Mike, incredible talk. Thank you so much.

I also have a question that I think puts both of you in conversation. And here I think the motivation is that I'd like an education. My understanding of [[Artificial General Intelligence]] is that there's a group of people who believe we'll teach [[Artificial General Intelligence]] by embodying agents or embodying the model—that is, giving the model the five senses of the human. And within that, there's a deeper part of people who believe that universal sensors are the way to [[Artificial General Intelligence]]—that is, you need to sense things beyond the human level.

I think that both of you view sensing. I even heard the word a couple times in the very beginning—you referred to our ability to view light as sensitivity to light. I'd love to understand how you think of sensors as they play a part in developing [[Intelligence]].

What part do sensors play in the development of [[Intelligence]]?

Yeah, okay. The more conventional part of how I think about this—believe it or not—is that I want to strongly redefine the notion of [[Embodiment]]. As humans, we're really focused on the three-dimensional world as the place for [[Embodiment]]. I think embodiment is absolutely critical, but we have to understand that the three-dimensional world is not the only place embodiment happens.

Living things use all kinds of weird spaces that are hard for us to visualize. They use metabolic spaces, physiological state spaces, gene expression spaces, anatomical morph space. Long before we got to humans, they were navigating these high-dimensional spaces with their own physics, their own [[Affordances]], their own restrictions and limitations. They were winning and losing and [[Dukkha]] in all of these other spaces.

So [[Embodiment]] is critical, but [[Embodiment]] does not mean a robot that lumbers around in the three-dimensional world.

If we had evolved with sensors that directly measured ten other parameters of your blood chemistry—like taste, right—if you could naturally perceive some other pH and some other things about your blood chemistry, I think you would have no problem at all visualizing that you live in a 13-dimensional world. Your liver and kidneys are symbiotic, navigating that space with you to keep you healthy. They would know where to go. They're intelligent. They solve problems. This would all be very natural to you.

But we don't have those senses. We're optimized for three-dimensional sensing. I think, with respect to [[Artificial General Intelligence]] and [[Intelligence]] in general, we have a really big humility problem. We think that we make intelligence, but my claim is that we don't make intelligence—either in the biological case or in the engineered software sense. What we make are pointers into a [[Platonic Space Of Patterns]].

Some of these patterns are very simple—the truths of mathematics that mathematicians study when they make a map of mathematics. Some of these patterns are high-[[Agency]] things that look to us like behavioral propensities, or minds. But in either case, both machines and biologicals are beneficiaries of patterns that don't fundamentally come from the space of physics. Evolution continuously takes advantage of all kinds of free lunches that I can name—things not determined by anything in the physical world. These are facts of mathematics, number theory, computation. They don't come from the physical world. They're not determined by it.

The focus on [[Embodiment]]—it isn't the physics of the three-dimensional world that I think is important for being an intelligent [[Self]]. It's being able to do the loop of sensing, model building—creative model building, not algorithmic—and then acting towards goals. That loop can be performed in numerous spaces we find very hard to visualize and is a beneficiary of patterns not determined by the environment or any genetic history.

The implications are simply this: when somebody says to me, "I make these things. I know what they do. It's just linear algebra. There's no magic here," I say, no, you don't know what they do. We've published on unexpected, not just unpredictability, but unexpected problem-solving capacities of things like bubble sort—six lines of code that every computer science student has studied for decades. It has unexpected competencies not in the algorithm. Yeah, it sorts numbers, but if you look at it a different way, you see something completely different.

I would urge a lot of humility: yes, [[Embodiment]], but not because you're going to use the features of three-dimensional space to create [[Intelligence]]. I don't think that's what's going on here at all.

Thanks for that. Curious about the classic argument of nature versus nurture. What I'm getting from your 30,000-foot view is this message: you can nurture nature to change its course. I'm curious for your take on it.

Yeah, okay. Biologists love two things as causes. If you look at a creature and ask why it has the shape it has or the behavior it has, biologists love two things: history, meaning it's that way because everything else died out and it has this long genetic lineage, which we'd like to cash out as genetics. And then the other thing they like is physics.

But of course, physics doesn't actually specify form. So they bring in this thing called [[Emergence]], which basically quantifies the level of surprise you got when you looked at it. You look at it, and the rules that the pieces follow didn't say anything about what actually happened. You say, "Wow, I didn't see that coming. It's emergent."

So nature is a combination of your history, and nurture is the interactions you have with the physical world and everything else. There's a really important third component that's critical. When I showed that diagram at the end with a tree of [[Cyborg]], I said: evolved material, engineered material, software, and then there was this other weird fourth thing called patterns.

Here's a very simple example. If you are a biological [[Self]] that relies on the properties of prime numbers—for example, you're a cicada that would like to emerge when no other predators are coming out, so you emerge at 13 or 17 years, or you're a sunflower and you want to obey the Fibonacci pattern because you want to arrange your leaves in a particular way, or you're doing something else requiring a particular fractal pattern—the explanation for why those mathematical facts are the way they are is nothing in the physical world.

There is nothing you can change in the physical world. You can scramble all the constants at the beginning of the big bang. You can do whatever we want in the physical world. You are not going to change the value of the natural logarithm. You're not going to change a Feigenbaum constant that governs transitions to chaos. Those things are outside the reach of the physical world. But evolution uses them all the time.

Just as a simple example, imagine you're in a world where the highest fitness belongs to a triangle of a particular shape. Evolution cranks a bunch of generations and finds the first angle. Great. Then it cranks more generations and finds the second angle. Fantastic. Now what? Now it gets to save a third of its effort because you don't need to look for the third angle. You get this magical free gift from geometry that says if I know two angles, I know what the third one is.

Where [[Dissociative Identity Disorder]] that come from? You didn't need to evolve it. There's no history behind it. It's a fact of geometry that in flat space
