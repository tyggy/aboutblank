# 【 Bill Duane】 Buddha and the Corporation in an AI world

## Transcript


We have Mr. B.D. He has worked at many leading companies like [[Google]], G Tech, and [[Amazon]], including inventing Gmail. He worked on machine learning, especially from workshops at the [[White House]], and teaches innovation and AI at [[Stanford]]. I think most significant is that he was one of the main contributors to "[[Search Inside Yourself]]," which bridges ancient wisdom and cutting-edge technology to foster [[Well-Being]] and ethical AI. Thank you for having you here.

Yes, let's welcome B.D. Thank you. So thank you very much. It's very much an honor to be here. I want to express gratitude for everyone involved, especially the organization of this event. I want to direct particular gratitude toward [[Venerable Akira]]. The last time I spoke at this conference was in 2018, and two very important things happened to me. One: I was introduced to [[Thomas Doctor]], whom you heard from before. Since then, he's become a treasured friend and colleague. He introduced me to [[Olaf Witkowski]], who you'll hear from tomorrow, and [[Lisa Solomon]], the core founding members of the [[Center For The Study Of Apparent Selves]]. This has led to a change in the trajectory of my career, so thank you for that. And then at the conference, I met a Chinese woman who became an online friend. I'm happy to report that as of last week, we decided to get married. Matchmaker! I have to say that in terms of value for the price of a conference ticket, a career and a marriage is very good value. Deep, sincere thanks.

Which brings us to today. We're going to undergo a bit of a switch—from metaphysics to engineering. I'm an engineer, so this is about how we apply these ideas in the world. My sincere goal is to finish on time. We're going to cover several things: first, I want to explain my journey and healing within a corporate organization; second, bounce between important context points about where the world is; third, a quick review of the [[Mindfulness]] movement, its benefits and shortcomings within organizations; and finally, ideas about how to bring everything together into a new endeavor.

I joined [[Google]] in 2005 after ten years of technical consulting. I worked on web search infrastructure production engineering, and later on Gmail, Docs, Calendar, and Spreadsheets. If I had to describe my engine for my life at that time, I would say it was fear and shame-based—always trying to outrun my own limitations and what people thought of me. This is a very powerful engine, but it's also quite destructive with a large shadow. I think it provides a metaphor for the energy at play in some corporate environments.

Being responsible for [[Google]]'s hypergrowth period while running on this engine, my father died. That experience was so painful. My methods of dealing with it were advanced [[Stress]] reduction strategies—the bourbon and cheeseburger method, which does not scale. I went to a lecture on the neuroscience of emotion, which told me that my own internal experience could be understood. I learned about [[Neuroplasticity]]—that you can change the structure and function of your brain. We've heard about the limitations of that mindset in earlier talks, but [[Neo-Buddhism]], despite its limits, was utterly healing and transformative. It absolutely set the stage to turn the most painful moment of my life into one of deep exploration and healing.

I bottomed out on secular [[Mindfulness]] programs like [[Mindfulness]] and [[Search Inside Yourself]] pretty early. I wanted to see the source code, as we say in computer science, which led me to explore Buddhism. I've probably done about thirty or thirty-five retreats. I [[Dissociative Identity Disorder]] five years of Buddhist teacher training in the [[Ajahn Chah Forest Lineage]]. Around this time, I wanted to shift my life toward service, so I switched from being an engineering executive to running the [[Well-Being]] program. That led to innovation work.

I think this points to the idea that we can use the difficulty in our lives and contexts—even if those contexts aren't ideal—to really grow. I want to note that in addition to being an expert and adviser, I'm also a student. I really want to give reverence to the teachers who have helped transform my life. [[Professor Ting]] inspired me with pictures of him and his teachers.

Now, let's change gears completely and talk about the context of the world. We've heard during talks, and certainly if you read the newspapers, it's like we're doomed or this will be the best thing ever. The answer is yes. To finish on time, I'm going to make these slides available and just describe them at a high level.

Major business leaders expect that within three years, more than twenty percent of the workforce will need to be reskilled, and the size of that workforce will shrink dramatically. One cannot ignore the societal implications of that much disruption, particularly during a time when populism is on the rise and leading to really unpleasant things. Something I communicate to my clients is that usually these dislocations are mostly visited on people who have less [[David Power]]. AI is interesting because it's really reaching into the middle and upper-middle classes—attorneys, for example.

Climate change: I really believe what was said before. This is a much bigger existential threat than AI, at least in the foreseeable term. Global warming is reaching Southeast Asia, where twenty percent of the population will be displaced within the next fifty years. This is deeply sad.

These numbers show young people versus older people. Young people report poor spiritual health—their connection with other people, their sense of meaning and purpose. You see poor social health and poor mental health. I wouldn't be surprised if these are effects of pollution from what was called the attention and intention economies. I think this is really important, and as older people, it's crucial to realize that young people need our help.

This is the last depressing graph, from the United States. We see that [[Diseases Of Despair]] have been increasing recently, mostly driven by Oxycontin and Fentanyl. Obviously, things are terrible, and we should all despair. But at the same time, this is also true: even the ones on the right are places where colonialism was really at effect, so it lags quite a bit. Child [[Epistemic Vulnerability]] rate is the lowest it's ever been. Education is continuously on the rise. This is very interesting: it basically shows correlation between economic activity and [[Self]]-reported life satisfaction.

To me, this says that one of the things that's come up recently is whether AI is good or bad. Again, the answer is yes. Different solutions are useful for different contexts. We can see some of the economic and systems of [[David Power]] producing the negative stuff are also producing these positive things. It's very contextual. The press makes it so easy to follow either "things are amazing" or "things are terrible," whereas I think it's really this idea of things being very contextual.

The traditional counterweight to corporate capitalist [[David Power]] is government. This research from the [[Edelman Foundation]] shows, over the last twenty years, people's faith in government across twenty-eight countries—roughly sixteen thousand people—has gone down dramatically. This data excludes China. For the last twenty years, government credibility has declined significantly. I'm deeply concerned we're going into this period without functional government ability to limit corporate power.

Then we have AI—all these questions about whether it's sentient or not. I don't think it matters in the short term because it's our relationship to it. If we interact with it as though it were sentient, then that is powerful enough. We have short-term things to be worried about and things to be helpful with.

To sum up: the bills for unlimited growth are coming due. We can't have unlimited growth forever. Life has gotten better in many ways for many people, but there's a sense that the systems we create may be beyond our control, combined with a massive decrease in trust in institutions. This is the strategic scenario. It's important to contextualize any particular topic about AI with all these other things going on in the world. It's absolutely clear to me that we're at an inflection point in history. For [[Wholesomeness]] to flower, we need to not just narrow down in our specific domains but look at the broader picture.

Now, shifting to how Buddhism might interact with these issues: the first wave of [[Mindfulness]] and Buddhism incorporation—aside from [[U Kyar Kin]] in Myanmar—was [[Mindfulness]]. I mentioned this was transformative for my life. It was skills-based: [[Self-Awareness]], [[Self-Regulation]], connection, understanding the skills to be trained. There was massive increase in popular attention and scientific press around this.

If I were to describe that movement as someone who administered and sat on the board of some of these programs, it was initially focused on [[Individuality]] and team performance. The material on concentration was more present than [[Compassion]], although as research on [[Compassion]] became stronger, they began to become more equal over time. Generally, these programs talk about the importance of ethics without putting forth an actual normative structure. This is probably due to two things: in a diverse environment, you don't want to enforce one particular religious view on a broad group of people. Also, leaving it fuzzy gives companies more room to operate.

The huge benefits—especially at the [[Individuality]] level—include [[Self-Awareness]], [[Self-Regulation]], kindness, meaning, and purpose. I don't think there's any person involved with this who would say it had the long-term systemic impact we hoped for. We thought if we trained people with these skills, it might shift the entire system toward the better. I don't think that happened.

I really loved [[Evans]]'s book "The [[Blind Spot]]." I read it very quickly. I think this is really important because when we start thinking about what to do now, I really think we need to meet people where they are. I didn't come to meditation to believe what I believe now—that the world is made of love. I came because I wanted to suffer a little bit less. If we can meet people where they are and give them a deeper program, the key thing is that for large tech companies, the things predictive in the past are starting to lose their predictive [[David Power]]. It's amazing that [[Google]] launched a new AI thing in search two weeks ago that [[Dissociative Identity Disorder]] terribly. How is that possible? They've been working on it for years.

I think the result is that not only do we have the [[Blind Spot]] of extrapolatory, reductionist science and engineering, but on top of that, we have a [[Blind Spot]] within us. If we don't have vocabulary around [[Compassion]], around how caring for other people works, around how to perceive and cognize these things, how could we possibly build tools? We have inner blind spots aligning with external blind spots.

The good news is this is causing pain and discomfort at the organizational level. A lot of what's been talked about today are ways at the [[Individuality]] and perhaps organizational level of perceiving and cognizing spaces that the [[Blind Spot]] has difficulty with. If they do that, they'll have more ability to traverse the problem spaces they're in.

One key way is to change from "me" to "we." One of the limitations of [[Large Language Models]] aside, one thing they're really great at—I don't know if you've done this—is you say, "Could you please tell the story from this person's point of view?" They actually do a great job. That ability to expand what we're looking at: if you're driving in your car, late for your doctor's appointment, and try to regain time by slamming through traffic, you make traffic worse. The more people do this, the slower traffic goes. But if you switch from "I am stuck in traffic" to "I am traffic," suddenly a number of means of traversing that [[Problem Space]] become available. If there's something that helps humans make that shift from me to we, I do think that even with AI's limitations, this is possible.

This brings us to the [[Stress-Care Loop]], with the idea that [[Care]] is a driver of [[Intelligence]]. Thomas mentioned that we start with [[Stress]] or [[Dukkha]], then [[Care]], which leads to intelligent, grief perception. We use the word "[[Care]]" because this model is intended to be scale-free—to work at the basic cellular level and also the super-organizational level.

Thomas discussed this mostly in terms of a human [[Individuality]], but now imagine recontextualizing it: an organization doesn't have a great way of perceiving that which is extremely causal. The things that are extremely causal in this world are love, trust, meaning, and purpose. The data points I showed initially show how the world destabilizes when we don't pay attention to that. But many organizations have this engineering way of looking at the world that's so good for solving the problems that are getting better, yet these other things—the externalities, which of course aren't actually externalities—are so hard to measure, which is rather convenient.

How could we give organizations and individuals within them the idea to perceive and cognize things that are important but very hard to measure? Hard to measure falls into two categories: one, there's just no good measure for it, like love. Two, in the complexity and ambiguity of this world, the relationships are so complex that the best you can come up with in a mathematical analysis is correlation, whereas every business wants hard causality.

I want to mention something: Thomas and I had discussions. I said this is a great model, but it doesn't really match the world. What if a being had infinite perception but was evil? Thomas eventually convinced me that if you have enough [[Care]], you can actually not collapse into an evil mind way of solving the problem. This is when you say "I am traffic" versus "I am stuck in traffic."

The other thing that needs to happen for this model to work at an organizational level is methods of perception and cognizing things that are hard, and then [[Care]].

Just a recap before we finish: the limits of [[Self]]-interest are becoming keenly apparent. The limits of reductionist, linear thinking and problem-solving are becoming self-evident in some domains. This provides motivation for organizations to pursue this for their own survival, which echoes my own experience when I hit my [[Dukkha]] wall. A desire for [[Wholesomeness]] is rising. Those kids are literally dying for meaning, purpose, and decency. This is huge [[David Power]]. If we can meet it, my belief is that love is the only rational move in this realm of interconnected [[Interdependence]].

I want to talk about an experiment in operationalizing love. What if we had tools and methods that developed our ability to perceive me versus we? This is crucial—it cannot just be code. It needs to be humans making the code. I will not work with any organization that refuses that. What if we trained in [[Care]] and [[Compassion]], [[Self-Awareness]], [[Self-Regulation]], and we were able to present these tools as something that would help them do what they're going to do? This means we have to be careful about which problems we engage with.

Maybe one day these tools become part of the "we."

Olaf and I are launching the [[Center For Compassionate Complexity]] to explore this [[Problem Space]]. [[Google X]] just hired us to do research and implement [[Human-Ai Hybrid Systems]] of [[Care]]. [[Google]] X is the Skunk Works—the part of [[Google]] that does experimentation and crazy projects. They want us to explore their problems and test the hypothesis that [[Care]] is a driver of [[Intelligence]].

I'm happy and excited about that. That's my talk, and I finished on time!
