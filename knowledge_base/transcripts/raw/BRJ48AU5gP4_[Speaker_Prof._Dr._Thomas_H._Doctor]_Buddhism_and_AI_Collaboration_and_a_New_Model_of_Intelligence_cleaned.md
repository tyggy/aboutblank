# [Speaker: Prof. Dr. Thomas H. Doctor] Buddhism and AI: Collaboration and a New Model of Intelligence

## Transcript

Good evening in the name of the center of Buddhist studies. I welcome you to this talk. My name is Clausida Mates and I joined HKU in August last year and I welcome our speaker professor Thomas Doctor who speaks about Buddhism and AI. Thank you very much for having come here. That's withstanding your your busiest cattle you have in Kandu and in other places of the world. and we really appreciate that that you came here. Thank you so much. Yeah. And I also thank the venerable Yunhang Memorial Trust for having provided the funds to invite you here. Like I like appreciate that very very much.

And well it is now my honor to introduce you and Thomas is the very good old friend.

I think we know each other already since 30 years because like we are both like scholars of Buddhist philosophy and Thomas like was became an outstanding scholar of Matyamaka philosophy very difficult reasonings establishing the emptiness of everything the absence of selves and so on and last year I came across your paper like which you published in entrop ropy Buddhism, AI and B in biology which you published together with Vitsky and other biologists and scientists and I was really impressed and surprised that you became a specialist in AI and neuroscience and so yeah I was reading what what what you published together with your like science colleagues and I I could use it also in my class And well that was really great what you achieved.

And so I had the idea like to invite you here to talk about like your definition of intelligent independent of whether it is artificial or biological. But you should also know like a few more things.

well Thomas he published like an English translationist study of a very difficult commentary on the moolaakarikas and you published like a few more philosophical papers and then like you are now like the principal of the ranges institute in Kathmandu and for those who don't know like it's it's a a huge center of Buddhist studies is affiliated with a traditional Tibetan monastery where like traditional Tibetan learning like profits from modern western scholarship and most of all western scholarship profits from traditional Tibetan learning.

So that there's something really fantastic and unique going on there and you are the principal of this institute. Moreover, you are the director of the center of apparent the study of apparent self. what what a name for a center, right? So denying self, , like that's like really like what Buddhism is about, isn't it? It seems, , it's a common ground also with artificial intelligence. And please go ahead with your talk. Thank you for coming here. Thank you, Professor Mus. And thank you to the center for the center for Buddhist studies here at HKU.

really appreciate this opportunity to come visit and and share ideas in this format. yeah so what I'll be speaking about today is precisely what what Klaus was mentioning. I will begin by talking about our center the center for the study of apparent selves and I'll talk about how it was formed how it came into being and how we have been working at the center and then in the second part of the talk I will introduce a model of intelligent systems that has emerged through our collaborative work. So the center for the study of apparent selves is a highly interdicciplinary enterprise.

we have physicists, we have biologists, developmental and evolutionary biologists, we have cognitive scientists, we have computer scientists, AI experts, we have mathematicians and also representatives of AI technology industry. And then last but very importantly, we have access to very valuable voices in the teaching of Buddhism such as Chikim who features in the middle of the photo there and whom I will speak about later on in the in the talk. So in short, it's highly interdicciplinary. We have a physiologist as well. highly interdicciplinary endeavor.

if you want to know more about our work and follow what we do then please visit our our website apparentelves. org center for the study of apparent selves. We have a blog also and we al always welcome response. We have very good experience with receiving response from from readers in general. so please don't hesitate to write good and bad whatever response you you have. If you feel that it's something that we should know, please don't hesitate. now the title of the to talk is Buddhism and AI, right? and why might it be at all meaningful to bring together Buddhism and AI?

So just as we talked about over the dinner before before now if we go back two years in time and if I told people that I work on the intersection between Buddhism and AI, people would say what intersection what on earth are you thinking about?

almost invariably there would be no one who just thought that was a natural connection to make and as you can imagine now is very very different during the last not even two years I think it's less than that no everything has changed because of the rapid advances in artificial intelligence in particular large language models now no one asks that question it's the opposite scenario really everyone says yes of course why wouldn't you be doing Buddhism and NI like last month when I visited the United States at the airport the immigration officers asking me why I was there in San Francisco I said it's to participate at an event on Buddhism and AI they too said yeah of course great and so it's just a different world in this sense as well as many others.

but it's still a valid question of course why Buddhism and AI and we have been thinking in terms of intersections interfaces between Buddhism and AI for a good number of years now. we began on the yeah in modest beginnings of the center for the study of apparent cells I think go back to 2015 16 when I was basically just surfing the internet and I came across some so so-called randomly came across some articles about the development of artificial intelligence and the ethics of artificial intelligence. So, I had not at all been following developments in artificial intelligence.

So it was very surprising to me very startling to hear that not just philosophers but actually AI scientists and engineers were talking about whether it's ethically justifiable to create a new being. to see that question brought up in such a a concrete matter and factly matterof factly context really surprised me.

I had no idea that this is these issues were no longer the preserve of philosophers armchair philosophers or not but that it was now also a discussion that was taking place in laboratories and scientific labs so that's one thing I noted and then secondly I was very surprised too and and shocked to see what the what the expectations were in association with developing such a new artificial being.

The question was is it viable and is it a good idea to u create artificial sense of self in in a system so that a construction of self as opposed to a world as opposed to other would arise in the artificial system and the general consensus at least that was the general tenor of this article that I was reading was that of course it would be this would be a way of tying together the many otherwise disconnected systems. And so by getting everything together around this constructed sense of self would amplify the power of artificial intelligence.

Not only that, it was also thought that according to this article that if we can do that, we might get a artificial intelligence that is more like us, more predictable, more better aligned with our human wishes and concerns. Because if there's this split where you have a subject as opposed to the objects of the world then having to interact with the world that would also be actions that would be the considered right and wrong from the perspective of the system and that's what the scientists were working on giving the system an artificial sense of conscience.

So not there was a sense that self-identification in an artificial intelligence would enhance the power the intelligence power and also that it would provide for a a ethically more sustainable better aligned form of intelligence and of course with a Buddhist perspective on things you would expect the exact opposite as From the general perspective of Buddhism, a general Buddhist philosophical perspective, we know that this split between self and other being that the idea of being a a self in the middle of the world but yet exposed to the world is not at all associated with growth of intelligence but with the opposite.

It's a an aspect of ignorance according to Buddhism and also very importantly it's not a innocent ignorance. It's one that really is considered the root of all problems. so that that shocked me to to to read about these developments and also about the expectations that seem to be quite widespread. so now I began to think that there would be then a a big role for Buddhism to play as we talked about tonight also there would be a a big role for Buddhism to play in this context of artificial intelligence. , and why?

Because in many ways I thought the perspective of AI science and the perspective of Buddhist philosophy, basic general Buddhist philosophy are profoundly similar if not the same in one particular sense. namely in so far as the Buddhist perspect perspective is one that denies the reality of a self that is permanent and singular. And yet this is arguably the intuition that we have. I now think that I am the same person who came in through the door a bit earlier. Different situation, different things have happened to me, but I'm the same guy who came in through the door. That is my basic intuition.

Now I stand here. Later I will hopefully do other things as well. And not only that, I also feel that I'm just one person because if any of you call my name, I won't pause. I won't wonder who is being called, which Thomas is it that they're calling. I will just respond right away. And in other words, I think there's only one me.

So we have these as as we know from this is what Buddhism makes us aware of right that we have this intuition but also that it's a an intuition that it's very difficult to find any actual bearing for any actual justification for because if I one of my basic in intuitions is also that this self is based on having a body like this one.

so because this body exists I also exist as a person but when I then look at as a as a person but when I then look at the body obviously immediately it becomes apparent that it's not one body but so many different things under analysis the body breaks up and becomes a universe ever expanding universe. So where to find singularity when where to find singularity when where to find permanence in this expanding universe of impermanent transient factors. So the body is not evidence of an actual permanent singular self. Then what where could it be then that why is it then that I believe like this?

We might talk about my feelings and my perceptions, my thoughts. But again those are all plural in the extreme, right? my feelings are utterly transient and there are so many of them. Where is the permanent stable singular self in all of that? Nowhere in the realm of what we call the mental either can we find any singular permanent self. So that is what Buddhist philosophy has been teaching for millennia, right?

but it's also the natural perspective in AI science at least in so far as no AI scientists I believe in her or his right mind thinks that there is a singular permanent individual in the artificial system. We may talk about an appearance of such a self and we may talk about whether it's a good idea or a bad idea for a system to work in such a way that involves the construction of a self. But no one believes that there actually is one.

So from the on the ontological perspect perspective there's then a profound commonality of the basic orientation in both Buddhist philosophy and AI science not only AI science but so much of the natural sciences go in that direction. No it's very difficult from a scientific perspective to find any grounding for a singular permanent self.

So I thought okay that's that's noteworthy and then what about the so not only that in the at the ontological level there is that commonality but also in terms of the aspirations that come with being a Buddhist and being an AI scientist there's a commonality and a and a deep one because AI AI science going back to the middle of the previous century has from the beginning been a pursuit of not just artificial general intelligence. In other words, artificial intelligence that would be comparable to the generality of intelligence that we have in human beings.

But beyond that, it's a pursuit of super intelligence. And that is still the case. So there's a deep concern for amplifying intelligence, letting it develop, increasing the power of intelligence which there is too in Buddhism obviously in particular in Mahayana Buddhism where the Buddhist vow is a commitment to achieve awakening defined as really omniscience knowing everything that there is to know and for the benefit of others.

So as well in terms of the aspiration there's a a clear and undeniable commonality and if you are interested in amplifying intelligence you also better know what you're talking about know what is intelligence then that is that concern what is intelligence what is mind and consciousness is there in AI science as well as in of course Buddhism where knowledge of the nature of intelligence or n nature of the mind is described as as liberating.

So there there's a common ground in in is what I want to to say but there are also differences and there are very profound differences as we already talked about in AI as we said selfident identification is associated with empower empowerment increase of intelligence and also with alignment being attuned with human concerns. So, and and being basically better in ethical terms as an as a cognitive system than than it would be otherwise. So, and in the case of Buddhism, the case is the exact opposite.

that grasping is considered a dimming of intelligence far from enhancing it and also deeply misguided in a dangerous way that creates misfortune for oneself and for others as well.

So in other words there's this contrasting contrasting views about the role that selfidentification the construction of a self plays in cognition in the development of cognizance and so now quite soon after I had read this paper and begin to think about it I had the opportunity to present these thoughts and what I had read in the paper to chug who's the abbot of shedling monastery in Kmenandu because I work at and live nearby the monastery in Kmenandu. So as a extra profound benefit of doing so I was able to quite naturally bring up this issue with chicken quite soon thereafter.

I should also say a little bit more about the monastery it's one of the largest monasteries in Nepal. It was built by Chugim and his father who you see in the center of the picture. both both of them are lineage holders in the Tibetan Buddhist traditions of Nema and Kaji. So I came to this monastery as a as a young man. I was 21 and just fortunate to come by and I have that's also how I know Claus is from from that environment.

So I was fortunate to meet his father and also appearing in the upper right corner and receive instructions profound advice from these these masters introduction to the spiritual life and the spiritual life and the spiritual life and the education that one receives in a monastery of this kind is remarkable this tradition that goes back to India of receiving information also in the scholarly context in the in the intellectual context receiving information which is then subjected to analysis careful analysis scrutiny and debate open undaunted debate and then whatever one comes to ascertain through that process of receiving information and working with it subjecting it to analy analytic pressure whatever one comes to understand in that process is immediately integrated into one's life.

That's the model. So that whatever one comes to see will immediately have a concrete consequence in how one perceives things. It becomes an actual fact of one's life. So in this way this model is remarkable in so far as it it is built to support a transformative process and that's also why I find the promise of this approach to learning as we say reflecting and meditating to be so promising for AI because what we want is transformation and wholesome transformation right in particular that is what AI scientists want from AI.

it is transformative expansion and wholesome and wholesomely and beneficially. So that's also why I'm happy to live with my family nearby and for my daughter to be able to grow up in a environment like that for the same reasons. So I was able to talk with Chima and go back a little bit. Sorry. and mentioned these concerns and as I talked to Liberty about what I had heard.

I had a smile on my face because in one way the idea of creating a sensient being from a new which what was what these articles were talking about is perhaps outrageous from a Buddhist perspective if you think of beginningless sequences of life and death and rebirth. So the very idea of being able to create a new being could sound very odd and I was trying to explain this in Tibetan as well. So I thought okay this this sounds funny but didn't seem to think it was funny.

So he he listened attentively and then with this very somber expression said what are you laughing about and just made it clear that this was really serious topics and concerns serious topics and concerns that were coming up. And he also encouraged me to then try to learn as much as I could and and possibly contribute to this developing in a this development in a in a meaningful helpful way. So I began to do that as best as I could keeping in mind's words and also his expression when he said this.

And I wrote down some of my thoughts in what later became this paper in journal of Buddhist ethics where I formulated some of the reflections and at the time I was working with professor Garfield Jay Garfield at Yale in US in Singapore working on a research project that was bringing together Buddhist classical Buddhist philosophy from Tibet into dial dialogue with contemporary philosophy. Professor Garfield has done so much as many of to making that happen to integrating profound Buddhist philosophy as a natural conversation partner in the general arena of philosophy in the world.

So I was fortunate to work with him and when I shared my my draft with Garfield, he wrote back and said, "Oh, these are nice ideas. , I think if you could find an AI scientist, but a real AI scientist and then work together with that person, I think I could help you find funding for a research project. So, I was very excited to hear that that was the case. I would love to work together with a AI scientist.

That was the whole purpose of beginning this was getting into a dialogue and disc discussion preferably collaboration with real scientists who are doing this but I had no idea where I would find such a person. So when I received the email from professor Garfield, I was on the way translating on the way to New York. I was attending a a meeting, a short meeting and then meant to return 3 days later. And I thought compared to the monastery in Nepal, as nice as it is, the likelihood of finding a real AI scientist is larger in New York than it is in in my monastery in Boden.

And so I thought I should really make the best of this this journey that I was making. And whenever there was a break in the program, I then was on the phone writing emails trying to activate whatever network I had. And there were some really kind people who helped me at that time like for example Daniel Goldman was extremely kind and supportive. brought me in contact with the media lab at MIT and so on. But in particular, it was Douglas Duckworth, professor at Temple University who connected with me with a very extraordinary person whom I Dr.

Pete Hutch, professor of astrophysic astrophysics at the Institute for Advanced Study in U Princeton. he is also the or was until last year when he formally retired from his position. and he was the head of the program in interdisciplinary studies at the Institute for Advanced Study. and he agreed to meet me and we we met in Manhattan and had coffee and at the end of this amazing conversation where I basically listened to Pete Hut and was tu taken by his extremely vast knowledge of so many fields and his ability of combining them.

when at the end of that conversation he said well I know you are supposed to go back to Nepal on Monday but how about if you come with me to Japan I'm going on Monday and if you come with me I can put you in touch with some people perhaps and of course that seemed like an amazing opportunity and in fact it was Pete invited me to come along to what is called what is it called the earth life science institute at Tokyo Tech, the institute the university of techn technological university in Tokyo. The institute is what you see there in the in the middle.

this is a space of profound interdicciplinary research that Pete had just built and he was heading it and it was a an amazing experience to set into this world of really profound expert minds who nonetheless were totally open to talk to talking with me. No one when they were most of them physicists, chemists, they they were biologists like the so-called hard sciences, geologists, and so forth. But when I introduced myself and talked about my background with Buddhism, no one thought it was odd. And everyone just said, "Okay, yes. So, so why are you here and please tell?

" and it was a a really intellectually empowering and liberating and very nurturing experience. So I'm always deeply grateful to Pete Hot for for introducing me to this way of doing science and this way of doing academic work. In fact, I didn't really know that it existed. So at the institute I met Peter introduced me to his close Peter introduced me to his close associate Olaf Vitkovski who is a linguist but most importantly he's a AI scientist and active in the field of artificial life. He's now in fact the president of the international association for artificial life.

so he and I spent a lot of time getting to know each other and understanding where each other were were coming from. And together with Pete, we developed a research proposal a research proposal which was intended for something called the Templeton World Charity foundation which had initiated a couple of years earlier a a program a research program called diverse intelligences.

So diverse intelligences was a program of this sort but it has now manifested as a new u discipline scientific and academic discipline concerned with recognizing understanding the plurality and the many many different versions of intelligence that we find in the world and in the realm of the mind. the spiritual realm too. Where do we find intelligence? what are its possible forms and how can we cultivate it? What are the sidet tracks? What are the potential benefits of doing so? the diverse intelligence is science and philosophy is concerned with these these issues.

So intrinsically multi-disiplinary bringing in biologists, zoologologists, AI scientists, philosophers, social scientists and so on. So it was yes so we decided to develop yes so we decided to develop as our research project our initial research project work towards the establishment of a shared vocabulary between AI and Buddhist concepts.

So we really want and we also wanted to along with that develop a way of thinking about int intelligence and identity consciousness thinking about that in a way that recognizes those as collective structures and so we wanted to explore Buddhist ideas of interdependent arising in the AI context. We wanted to create very specifically an AI Buddhism conceptual dictionary.

So we wanted to see if we could prod produce something that would allow AI AI scientists to understand Buddhist concepts, philosophical and practical concepts with the help of their own vocabulary and their own familiar sets of concepts. And we wanted to do the same from the Buddhist perspective relying on Buddhist frameworks, Buddhist concepts allowing access to the concerns and the issues that are at the forefront of AI. So analyze key concepts through of AI through Buddhist lens and then extrapolate also some Buddhist principles that could be helpful in the context of developing AI.

to all of that we had in mind when we w we wrote what we thought was a beautiful proposal. However, yeah and we had a lot of hopes about what this could lead to. We thought that in this way we would be able to enrich AI ethics with the help of this Buddhist perspective. We talk about the common ground and also the profound differences.

So bringing that to be those to bear on the evolving of AI could be a great enhancement we thought and we could also in this way help Buddhist communities traditional Buddhist communities engage with the new science and the new technology in a way that would be in fact empowering and enriching from for them rather than the opposite. So we hoped to be able to bridge the gap between ancient wisdom traditions and cutting edge technology.

We thought that we could in this way if we were lucky and and good at it that we could contribute to a more holistic and ethical AI development and explore new paths for human flourishing in the age of AI. So we had a very nice proposal ready but the first time around we were not successful. So we didn't g give up and undaunted we continued as before to to talk together and despite the challenges. Yeah. funding is important as anyone who works in research is very well aware of and it's a key factor to take into account when we talk about developing AI.

it presents its own profound challenges and and problems. It's a something that needs to be borne in mind. The role played by funders, investment companies and so on is obviously something that we need to have at in our minds as as we go.

Fortunately, we were developed, we were contacted again by the association by the foundation world Templeton Charity charity world temple world charity foundation and they asked us to we would be interested in reformulating what we wanted to do and basically just tone it down a little bit, not promise too many things but focus on something that seemed achievable. And so we decided to create to make the ma main concern of our research the development of this translation device. Before we had also thoughts about developing a computational model and and and so forth.

But we thought now in the first in the first go we will focus on developing this dictionary of sorts. And we also thought that it would be a good idea to not just be the two of us but found an actual center and in Shinjin at a conference on Buddhism and technology organized by the wooden fish foundation in 2017. I met Bill Dwayne who is a former Google executive who was in charge of core applications of the Google corporation in the early 2000s like the Gmail and other things that we use all the time.

So he he came with this deep experience in the world of AI industry and I at the conference he gave a keynote speech which impressed me very much and we got to talk afterwards and connected and when the opportunity to formulate this research project came up I I invited Bill to join and he very kindly and readily did so.

So then we were three Moreover, Olaf and also Peter knew Lisa Solomonova who is a cognitive scientist and also a phenomenologist and a philosopher based at McGill in in can in Montreal and she's an expert on dream and nightmares and we thought that bringing her into the discussion could help could help bridge the gap between Buddhism and AI. Finding someone who is able to address things from the perspective of neuroscience and also phenomenology could act as a nice bridge between AI on the one hand and then Buddhist views and practices on the other.

So in this way we started out as a group of four and when we started out it coincided with the onset of the corona epidemic pandemic and we had thought that our work would basically take place as around workshops where we would get together and work in an immersive environment intensely for perhaps a couple of weeks or something like that and otherwise just stay in loose contact and work on papers and so forth and that was our the the approach that we had in mind but as so many of you also I'm sure had similar experiences those u those agendas of that kind fell apart and we had to just face the reality of living in the corona world and in many ways turned out to be a blessing.

We as again you all have your own version of this story becoming familiar with zoom and other such media and being able to talk to one another across great distances. So in our group we were based I was at that time in in Denmark. I got stuck in Denmark over the for the course of the pandemic. My daughter got to go to school there also. was nice in many ways but it's not where I had thought to be for so long time.

However, I was there for the entire epidemic and meanwhile meanwhile Bill was in on the west coast of America, the United States in San Francisco, Olaf was in Tokyo and Lisa on the east coast. very difficult to find a a time that was not torturous for at least one person. But we got together once a week and and discussed and talked in in this cross-d disciplinary endeavor where it becomes for that thing to work in any in any way.

It's really necessary that everyone who participates that that person has a genuine wish to learn the perspective of the other obviously despite the challenges that comes with talking with someone who knows infinitely more not infinitely perhaps but perhaps infinitely more than oneself about a given subject to nevertheless try to understand and also question one's own understanding in the light of what one is. It sounds perhaps relatively doable but it is very difficult in practice to do that.

It's requires a lot of patience and endurance stamina to keep up that conversation because it's very easy to retreat into what is one one is familiar with. So every person in that discussion came with a set of concepts and and understandings that they had worked with for many many years and refined and spoken about with experts developed in amazing ways. So this sense of there's something here that I know that the others don't know can easily become predominant and then you don't really listen to what the other has has to say.

At least I noticed in my own mind, not that I usually think of myself as a great expert on anything. But talking about mine and about so far, I thought this is something that I really heard a lot about and something that I've good stuff that I have heard that I would like to pass on. So the urge to begin to speak your usual language is very strong. But if all what the endeavor is about is making everyone speak and think like yourself do now then then what's the point? Then there's nothing new will be achieved like by definition.

But it seems so tempting because it can easily look like the others are not precise. If only they would talk a little bit more like me then they could achieve that precision. So what we realized and it was a a a real experience to to come to that recognition. Perhaps it should be obvious but at least in my case it wasn't. What we realized is that you have to let go of that appearance of precision and then step into some field where things are more blurred where you don't really know what they're talking about. You don't even know what you're talking about all that well.

And so it is a misty foggy environment but suddenly it can be amazing and you you get to see things and think things understand things that would definitely not have happened otherwise. And also in particular you Yeah.

One beautiful aspect of this this is that then you can turn around and look at what you thought you knew in your own discipline and now you realize it was very superficial and some some new clarity some new color has has appeared so it can be extremely rewarding and I think this cross-disciplinary work is crucial for progress in in our world that's also something that I learned from Pet who has talen about the necessity of exactly this work radical radically cross-d disciplinary approach to academic work scientific work.

So that slowly began to dawn on me the importance of that the relevance of that and I'm still in that process. So one very decisive thing that happened in the course of our in the life of our center was that we connected with Dr. Michael Lean who is a groundbreaking trailblazing biologist based at T University in the United States and we got to know him at Thank you. we got to know him at the this better the summit of the diverse intelligences program. The the leaders of the different projects came together once a year to connect and report to each other.

And at one such event in fact it was online so testifying to the amazing potential of online conversations we got to know Michael Leven's work and connect with him discuss and we've been looking for a framework that would enable us to quite naturally connect Buddhist ideas with a an already accepted or at least proposed scientific model, but it was very difficult. There were there was always some stumble block that made it awkward and uneasy, but getting to know Mike was yeah, also a great profound catalyst for our work.

suddenly it just clicked what we heard when he talked about and described his cognitive light cone model of intelligence seemed immediately applicable to the Buddhist context. So the cognitive light cone which you see depicted down there in the left corner. These are two papers that we sub subsequently wrote with with Michael Leven, the four of us plus him. that model of intelligence is based on a particular ask it's based on asking the question. So what is intelligence? And for many of us it's easy to associate intelligence with knowledge. knowing a lot of things means to be intelligent.

but it couldn't be the case that knowledge as such were intelligence because if that were the case then when we see a great encyclopedia book lying on the table we would say there's something really intelligent there. Of course that's not what we talk how we talk it's not how we think. knowledge is important in the processes of intelligence, but it's not what intelligence is as such.

We could also think that intelligence perhaps has to do with seeing things, hearing things, registering things that are otherwise very difficult to register, like seeing things that are at a tremendous distance or extremely subtle. but again, this couldn't be intelligence as such because then the space telescope or powerful microscope would also be intelligent and that's not what we mean when we say intelligent. So what is intelligence then and Michael Lynn had come up with this profound insight that first of all every being seems to have a limit to what it can care about.

any intelligence system and certainly any living system can engage itself or can want to engage itself only to a certain limit in time and in space like for example a tick as we have in the upper left corner a tick which maybe lives in the hairs of a dog doesn't think presumably about things that go on in the next room or in the next garden or even much closer than that. It's concerned with its very immediate environment registering heats and so forth, whatever ticks do and it's also presumably not contemplating the deep past or the distant future. It is concerned.

It it reacts to things to past states of affairs. is informed by the past and it anticipates future events to some extent. But the and this is then what this model says. The care core of intelligence or the cognitive light of intelligence is compar comparably comparatively small when compared to for example the dog that as we know with dogs they can remember things that go quite some time back. Maybe they can't or they don't spend a lot of time thinking about what might happen in the future.

In other words, they don't care that much about the future, but they do care about what happened in the past. What happened in the past. What happened in the past in many ways determines how they react now. So, that's why the care cone of the dog looks like this. It's not as vast. in terms of space either because a in terms of space either because a dog again presumably because not think very deeply and care very much about what happens in the next village or in the next in the next town. It is very much concerned with what goes on in the immediate surroundings. Human beings we are also like that.

There seems to be a limit to what we can genuinely care about. something that actually makes a difference for us. Some of you may be concerned about the the future of the globe, perhaps of the whole universe and very genuinely so. But it's hard to think of a human being for whom it really matters deeply what may or may not happen millions of light years away and in the in the far far future. It's not something that actually makes a difference. We don't care that much.

So, Mike's brilliant idea was to say that that scope of one's intelligence which you can talk about in simple space and time terms that scope of your care is also the measure of your intelligence. the measure of a systems intelligence the computational surface of the self into being can be understood as this cognitive light. So of course the one beautiful thing about this framework was that it by no means appeals to the idea of the self that we talked about before singular permanent self. There's no need for that self.

there isn't one and there is no urge at all to appeal to the existence of such a self with this system. These these careorns can evolve or contract and they can integrate with one another very freely. It's very interesting then to think from a Buddhist perspective about what happens when someone takes the Buddhist abal which as we know is about assuming responsibility throughout space and time. So it's formally extending the cognitive liteco infinitely.

And if care drives intelligence, which is what we were arguing, then you should you cannot help but notice a correlation with this expansion radical expansion of the sphere of care and this the scope of intelligence. So we wrote the first paper that Claus mentioned with this in mind developing these ideas and yeah I'm very happy that actually many have read that paper turned out to the readership is stable and it's already now on the list of most read most viewed at least articles in the history of the journal entropy.

So yeah we continued we continued our work then and with that paper as the basis we had our first meeting in Nepal in the Himalayas we've had several of them now when again it became possible to travel the group came together in Kandu also at TUS university in the states and again in the Himalayas. So we have developed this tradition for having meetings of this kind. there's a similar conference happening in Kandu from the 15th to the 17th hosted and organized by the Institute.

So at this meeting in in Kandu but also at at tufts really was there to provide a really profound perspective Buddhist perspective on the nature of intelligence, the nature of care, the correlation between care and intelligence. And we talked about how difficult it is to bring academics and scientists together when they come from different backgrounds. it is perhaps even more difficult to bring together meaningfully scientists and and contemporary academics with this approach that we find in the monastic institutions of this deeply integrated learning reflection and meditating paradigm.

but and and was cautious from the beginning. He said very often scientists and Buddhists get together to talk at what is called a dialogue but it can often and that is beautiful and very very good that it happens but often all what goes on is really conversation and respectful polite conversation but it's hard how how might we be able to achieve something concrete like step and take an actual step together so that that's something that just said he would very interested in in doing. So is it at all meaningful to just as we can say why Buddhism and AI, we can also say why science and AI.

And I think one very good encouragement and admonishment really is found in Buddhist scripture itself like the rice seedlings sutra which you can find in available in translation at the 84, 000 sites there the Buddha says vious whoever sees dependent arising sees the dharma and whoever sees the dharma sees the Buddha.

So if that is the way it is, if understanding the causal contingencies of things in the outer world and in the so-called inner realm of the mind, in other words, if understanding how things work, if that means seeing the dharma, then then indeed there's a natural very natural and honor convergence there between the scientific and the Buddhist approach that cannot be ignored and not only sees the dharma but sees the Buddha. So if that seeing of dependent origination is also seeing the Buddha seeing the awakened state.

I think I find that a very profound encouragement and really admonishment to to try to to do this working together and suggested that we take as basis for discussion so that there was something concrete in front of us that we could either agree or disagree about that we look at the four seals of the dharma. so there was a talked on these four seals and we discussed them in the group all condition things are impermanent. All defiled factors are suffering and everything all factors are empty and devoid of self and finally passing beyond suffering is peace.

In here in this formulation there are also some arguments presented which is helpful of course when the context is a discussion where we want to make some progress. Do we agree or not and so forth and it was remarkable to note how much general agreement there was about impermanence for example from the scientific perspectives because there were many represented there and the Buddhist perspectives that were present. The same with the nature of the cliches, negative emotions that they involve suffering. That was not where we had to pause a whole lot.

And even emptiness and dependent ordination was something that didn't seem too foreign is my impression and it's also his impression according to what he says didn't seem too foreign to the scientists. There was general agreement. But and so too about no self. But when it comes to understanding what does it mean to know no self? What does it mean to understand and see that there is no self? And what are the consequences of getting to that insight whatever it may be? that's I think where we're still working.

That's where the the current discussions and and work is going on and the the fourth maximum very much rests on what you understand by the third. So I hope that we can continue our meetings and our discussions our our meetings and our discussions also with the involvement of edits and scholars like, now finally the the models when risking this feeling of being imprecise and letting go of one's customary understanding of things a new set of concepts can can emerge.

So perhaps we should have known from the beginning that we would not get a dictionary that would allow translation of terms from AI into a Buddhist conceptual. When you spend a lot of time time trying to do that then instead of getting that dictionary you get instead new understanding a new way of looking at the concepts and that's how this model of the stress care intelligence intelligence group began to form. So this is a very rudimentary a very basic model of what it means to be an intelligent system.

but it is one that we believe is applicable to everything and anything that is worthy of the name intelligence. No matter how many different forms of intelligence we may think of and want to acknowledge. I think it is possible to capture what goes on there in terms of first care and intelligence you can think yourself and very grateful for your feedback. so stress is where it all begins. Stress is the perception of discord mismatch between the way things are now present circumstances and then the way ought to be things ought to be.

So that perception we all know as human beings again and again we have the the sense that that's something that needs to be improved upon. Maybe there's something really wrong but that's scope for improvement. It happens to us all the time. Now when that perception occurs then it's not only something that we can notice in humans it's also something that seems to be applicable to animal life of other kinds and human beings. And in the paper we argued that stress is also a meaningful and very informative concept to bring up in the case of artificial intelligence and technology.

stress and stress transfer we Vikovski wrote a chapter on that in that first p paper. Now whenever there is that perception h it cannot be ignored. Once we have the sense that there's something that isn't the way it should be it's too late we have to respond even if we decide I don't want to respond I just want to ignore this that itself isn't a response. So that immediate response to the perception of stress is what we call define as care is the natural response to the perception that things are not the way they should be.

And whenever this care arises then implicitly we will be looking for a solution to our stress problem. Like for example if I feel thirsty which I do in fact then that stress immediately makes me want to do something to overcome the problem and so I can think about finding a glass of water somewhere and we know that that has no Sorry. Sorry. I'm fine. So whenever I do that the problem is solved. The original problem is solved. Yeah. But very importantly and that's what indicated by the yellow arrow. now I see the world in a different way. First is not my immediate concern. That problem is solved.

But I now see other problems. I now see other problems. I now see other ways that the world is not the way it ought to be. So I can distribute to new scenario through having solved the first stress problem. And so you can see the beginnings of a feedback loop that is also dynamic and when in this way so intelligence according to this way of looking at things is simply the capacity for solving such problems. Not the actual solution not the enacting of the procedure that solves the problem. That is more we could say the culmination of the course of care.

Intelligence is just the ability that a system an intelligent system has to overcome stressors and so when that happens when a when a means of talking and talking is found and actualized then we can we can call it intelligence but activated intelligence another way of talking about AI that's what the man solution is so it's where culminates in the activation of so we have talked about otherwise care as being a driving factor for the development of intelligence and that is also the case here. Yeah. Whereas the cognitive light cone presents a picture of what an intelligence system looks like.

This model of the SCI loop, stress care intelligence loop is a model that explains the dynamics we like to think of intelligent systems. And when an system can develop one way or the other a tolerance for stress expand that then the capacity for intelligence grows with it. So in the case of me feeling thirsty it's a very closed narrow loop and yes perhaps I begin to look around for something new to concern myself with but in principle what we see here is just a very simple loop. It's similar to what goes on in a single cell creature but it can it need not be like that.

for example, what goes on here is the STI loop evolving SDI loop of a dog who sees the stress of the person that the dog lives with and that stress of the other person becomes the stress of the dog. It's stressing for the dog to see that this person is upset. and so it responds. air is arises as a response to the perception of stress and dogs can find solutions to those problems, right? And both of them have a good time and are now able to again look at the world in a different way.

So that is a more sophisticated SCI loop, a more expensive one that engages the stresses that are found in external so-called external systems. Here is a example of how intell humans and technology can transfer their stresses between them. grandparents are in their holiday cabin in the forest and they write an email to the family saying we miss you guys. Wish you could come and visit.

In other words, they transfer the stress that they feel through technology which then transmits that stress signal to the human recipients and they respond by again activating in activating technology DPS what have you on the phone and so they're able to find the way to the little house in the forest and everyone is happy. The technology has solved this stress problem and so have the humans involved.

So that's what is depicted in the figure in the lower right corner is taken from our second paper which is specifically about this stress care intelligence loop and again the yellow arrow is important showing the dynamic evolutionary dimension to this. And finally here is a similar thing going on but it starts with technology. In this case, it's a technology that is disturbed by noticing a heart attack perhaps and it's goes off, sends a signal transmit transmits its stress to the responding team who then receive that stress signal, react with care.

And in this case they're able to find a solution. Perhaps it's a perhaps it's a perhaps it's a operation that takes place and the problem is solved. So the original stress of the technological system is overcome. So in this way loops between technology and human beings can go in and out of each other through stress and stress transfers. So what we so what we like about this way of looking at things is several things.

it is certainly a very simple way of looking at intelligence systems but it has some arguably very compelling features because this is a way of looking at intelligence that is open to the tremendous diversity that we have in the world in terms of which forms intelligence can take logical intelligence problem solving artistic intelligence emotional intelligence there are so ways that we can talk about intelligence but I don't think there's any any aspect of int of what we would like to call intelligence that cannot be described in these terms.

So it provides a way of putting everyone on a equal footing so to speak and that's important also in the context of AI because one of the very profound challenges that in particular AI industry is encountering and taking very seriously is the so-called alignment problem. How can we how can we ensure work towards and in fact ensure that the goals that artificial intelligence and perhaps artificial super intelligence has are amunable to and in alignment with the concerns that we as human beings may have.

If we have a way of understanding and and the black box problem is tremendous that we don't really know what goes on in the artificial systems the so-called black box. We don't know how they get to the conclusions they get to large language models for example. We have some general rules but not really the specifics of how a particular output arose. So they're profound problems. we just need to look up that word alignment online and or ask our AI assistant to explain us about it and and we will know. This is a very serious problem.

If at least we can have a way of talking about intelligence in human forms in biology based contexts and also in technological in technological context it seems that's desirable. It's preferable to dealing with something that is radically different and perhaps incomprehensible by by definition from a human perspective. So that's one virtue we say about this way this model. It is also a model that is in tune with science. In other words, you can call it a natural model, naturalized model of intelligence.

And because I think it's hard to get more to get to something more rock bottom when it comes to something like intelligence than the event of stress, this perception of things not being in the way they really should be. That is something that we all recognize and it seems to be a factor a a a core factor in the way the world works. It's something that science can acknowledge very readily too. So if you say that this is our theory of intelligence, it means that it is I would say a naturalized if by that we mean in accord with science approach.

I would s suggest that and not only intelligence because many ways what we talk about being the decisive elements in the unfolding or contraction of intelligence u is also what goes on in what we would call mind. So this gives us a way of talking about care which is otherwise can seem very intangible from a scientific perspective. What is care? Who has it and so on.

Gives us a way of talking about care which is very concrete grounded in in stress and it also gives us a way to talk about intelligence in a way that is equally increased based on not saying that intelligence systems can overcome stress. And finally, it gives us a way I would also suggest to talk about mind that is empirically and scientifically informed. finally and that's very important both from a Buddhist perspective and also from a scientific perspective.

It gives us a way to talk about agents that takes into account the difficulty that we find when it comes to delineating the difference or the barrier the demarcation that marks whether where one being ends and the world begins or where one being ends and another being begins. That is a profound scientific challenge to take the more this it's research the more complex the story of the interaction and the usual influences that go on between the so-called interior of a system and its external world.

so if if our model of intelligence and if our model of mind rests on a notion of mind which is clearly separate from world and so forth along with the conceptual framework then we will have a hard time talking with scientists biologists and also yeah AI sounds. So I think this framework is really helpful in that regard because what is it that goes on when we say stress is registered. It's I register the stress but what I see and what I feel I see is the world. It's the world that there's something wrong with and what is wrong is what I see.

So there's a natural interdependence between subject and object. And yet we're not just saying that everything is there is a predominance of objectivity and world in stress and that is the exact opposite with the response to stress which we said is yeah when there's this impulse to overcome the the imbalance that is stress then whereas of course we are reacting to something that is of the world is still felt as the subject to the master. So whereas stress is predominantly but not exclusively world care is predominantly but not exclusively subject and agent.

And finally and finally intelligence what about intelligence? We said that it's the mere capacity for overcoming stress problems not the actual implementation of a given remedy but it's the mere capacity for overcoming such such problems. A capacity I don't think is meaningful meaningfully described as object or subject. It's just that capacity.

So it also gives us a way of introducing again in a way that is in accord with science the notion of non-duality non-ifference between subject and object agent and object so then I'd like to conclude the talk with since this This is the center for Buddhist center for Buddhist center for Buddhist studies suggesting that this also then gives us a way to introduce the Buddhist idea and of of Buddha nature that there's something in all sentient beings that is a perfect capacity which is pure and unpolluted and ready to be actualized. Let's say that this is what Buddhist Buddha nature means.

professor Mus and others here have written extensively on this. But if we say that this is what the Buddha nature means then in just noticing that intelligence systems have this capacity And it doesn't make sense to say that some have it more than others. No, it the the capacity itself will have to be the same. The capacity for overcoming stress problems. It may be radically different in the support that it has. It may be radically different in terms of what this system can actually do in the present circumstances. But the mere capacity remains the same throughout.

So this gives us also a way of introducing Buddhist ideas and the perception of sentient beings as being basically the same and equally worthy of sustenance being cherished and from a Buddhist perspective than care that everyone deserves to awaken to the full potential. So I think with those words I will stop stop here for the presentation. Thanks for your patience and again very happy to keep in contact let us know your thoughts.

you're welcome to we can have discussion now but also in the future when you come back to these ideas if you do and if something comes up that you would like to share we are always excited to to hear from you. So thank you very much for now this interesting ideas and I'm sure there are a lot of questions or remarks open the floor for somebody hi thank you very much for the presentation. It was really interesting. I like the framework very much. The I I like the framework very much.

The SCI framework is very like minimal and elegant, but I have in mind some forms of intelligent cap capabil capacity or behavior that I think I wonder how you could fit into your model.

For example, like athletic abilities like trying to challenge yourself to to do like to jump higher or to run faster, swim faster, for example, or artistic musical abilities that you you pursue aesthetic value not you you you pursue aesthetic value not just for stress relief, but you think there is something intrinsic valuable in artistic pursuit or religious, spiritual or natural intelligences that you try to connect with nature, connect with something bigger but not necessarily for stress relief. I wonder how you could fit these forms of behavior and ability your model. Thank you.

something like that. Thank you very much for that for that Thank you very much for that for that question. I think I think so if we say artistic intelligence perhaps one of the the topics that you mentioned the the topics that you mentioned I'm not much of an artist but at the same time I'd like to think that I know a little bit what goes on in the mind of an artist and so say you are an an artist who have a dream to create something you have some inspiration that that means there's some goal. Yeah. One important thing.

So, thank you for bringing up the this is that when we say not noticing that something is not the way it ought to be, it doesn't mean that we necessarily have a very clear idea about what is wrong or what the what needs to be improved where in which direction it should go. So, I think it's a a matter of degree. It's perhaps a we can talk about the inspiration of an of a scientist of perhaps of an artist. We'll have to ask actual artists whether that makes sense to them, of course.

But I think we can talk about their inspiration and their yeah having a goal come to mind which is undefined but nevertheless takes you in a certain direction. That involves seeing the world as something that could be different and better different in a better way. And similarly with the other forms of events and cognitive events, mind events, I don't think we're pushing it when we say that they can be described as first perceptions of the world being something that could be better and then responding to that with care.

So the artist's work would be care and when it has worked out well and the artist sees the creation there that would then be actualized intelligence and having invoked activated the capacity. But that's a key claim that that this is a way of talking about intelligence that is just about universally I think it will help. Yeah, thank you professor.

I thought the SCI model is quite interesting but I just wonder what has been the biggest or the most contentious ethical issue that has happened in your that that has happened in your discussions with the group and whether you reached any consensus to address that ethical question. so there are many profound ethical issues. and I think we all should look into those. That's also what people even in the AI industry they often encourage lay people like me and users of AI. So it's just about everyone to to to to think and participate in the in the dialogue.

But there are many profound ethical questions that arise when thinking in terms of artificial intelligence. How the world will look like if we get artificial intelligence? if there's this misalignment between artificially intelligent systems and human beings. in fact human beings are not very good at getting along already we're not terribly well aligned. So when now suddenly we introduce super intelligent systems how can we assume that it can go well in the long run. Yeah there are many profound challenges. Yeah.

But I also think and what many are concerned also about what it means in terms of what we call human dignity or the loss of human dignity whatever it is that we associate with those terms. Is there something that is in the future in perhaps in the not so far future seemingly better at everything that I now pride myself of being able to do and that we are used to thinking of as the hallmark of human intelligence being able to speak and reflect form new ideas and so on. and and do tasks, practical tasks that are very sophisticated and very subtle much better than any of us than then who are we?

What what are we human beings? We're used to thinking perhaps some of us are as being the apex of the evolutionary process. What if this now occurs then and what does it mean to be a human being? what does it mean to have a fulfilling life in that environment?

So in in this regard I think again Buddhism has tremendous potential for the only problem is that for us to benefit from the Buddhist resources traditionally a lot is required understand what a self really is what an agent really is not just understanding it in not just understanding First of all, what does it at all mean to ask such a question? What is an agent? And what is an agent really? Is that a meaningful question to ask? Could there be a proper answer to that a a proper answer to that question? So many things come up. Yeah.

But Buddhism has this ancient tradition for looking at very very difficult questions like this in a sustained process and in a very supportive environment. where a lot of people come together to think about such things that perhaps seem very otherworldly from we're used to thinking of it like that but not in the in those communities. These are like key questions that people work on and not just intellectually whatever they understand about what it may mean or not to be an agent is something that they then are encouraged to integrate into their into their lives. Yeah.

So in short I think there are tremendous challenges that come with artificial intelligence. I also think that the general development cannot really be stopped. except if there's some disaster this research and propagation of AI will continue. So it's really important that we all do our best and I think Buddhism has so many resources. The challenge is in many ways what always has been the challenge is that it requires depth and commitment for us to really benefit from those. Is that a like a few thoughts about the definition like of like stress care and so on. Yeah.

Like looking at the computational and functional aspect of AI I would say like intelligence doesn't necessarily need to be conscious and like even in our like biological system like we have self-organizing loops. Yeah. like for example when there is not enough sugar concentration in our blood our body like releases insulin but we don't have to be conscious of that. So that that's just happening without so like my question is like how do you register like stress and what or who sets the goal like for the like optimal set points in in AI and in biological systems in comparison.

So those are of course profound and important questions. I think generally our approach is to say that we aren't really making a point or trying to make a point about where there is what has consciousness and what cannot have consciousness. Apart from just saying that wherever we can notice and that's then really an empirical issue. Wherever we can notice that something looks like stress and response to stress. that's the definition of an intelligence systems and of an intelligence system. So that doesn't mean that all kinds of intelligence are the same. Far from it.

and that and a cell involved in the produ production of insulin is cognizant in a way that is in any big way beyond this perhaps resemblance of what goes on in a human being with dreams and aspirations, deep fears about the future and so on. not at all, but there's nonetheless something happening there.

just as it happens in a human being and I don't think so we talk about intelligence we talked about stress care and intelligence and not really mind and consciousness but at the end of the day I don't think the if we go with this way of thinking about it the difference is not that profound like we can depends on what we define as consciousness what our framework is for saying such and such is what characterizes being fully conscious. Perhaps it's having a narrative self. Who knows? But that's a different matter. and that can be accommodated with this way of thinking about things.

We can say that such and such system does not have such and such consciousness just as we can say it among human beings that some have such and such consciousness and others don't. But it it's it's a way of thinking about intelligence and also about conscience consciousness which considers the expressions of intelligence and consciousness to be occurring on a continuum. That's also Michael Le's fundamental approach in basal cognition. This is this is how they look at it.

And I think that it makes it makes good sense to to look at intelligence as a continuum rather than a question of where is it and and where is it not or consciousness saying that here there's consciousness or here there's mind and here there is. There are different mutations of consciousness. radically different ones. But the the meaningful question is not so much whether or not but more how. So in other words, stress can be registered by a simple mechanism. Yeah. And yeah, that's very interesting in a way. Yeah.

And I think there we find the common ground between AI and yeah I biological like systems. Yeah. Yeah. Yeah. That's quite convincing. Yeah. That's quite convincing. Yeah. Sorry. like I I should not take all the time. sorry. my question was about you showed the the picture of the heart monitor. Yeah. And you talked about that as if the heart monitor was under stress. But but it's heart and maybe that is what you're trying to give us as a maybe this is a form of stress too. But perhaps the problem is that you don't know what the heart monitor means. Whether that's stress or maybe that's a good thing.

It it takes a a mind to interpret that that is a problem to be solved but by itself it's just a sign but we don't know a sign of what. So I was just wondering yeah what your reflections are on that and whether you do think the heart monitor is under stress in some way. Yes I do think it's it's meaningful to talk about this as a stress situation also in the context of the heart monitor and all the complexity that that entails. Yeah.

in the same way as my feeling thirsty before and not figuring out that there was a cup of water right in front of me was simple situation but involved tremendous complexity and u and it's arguably very similar with human beings. No, when we look at each other sometimes it can be hard to know what's going on in the other person. It may look as if I'm irritated, but perhaps I'm not just very excited and listening very carefully and so on. No. So again, I don't think there's a fundamental difference at play there.

And the basic framework of saying something registers mismatch between what is the case now and what ought to be the case not in a clearly defined way so that you necessarily have this clear set point that you want to get back to. You may, but you may certainly also not. there's just something that is not right about the way things are now. And another thing in this context is that so much of artificial intelligence really aims to appear in a way that is recognizable for for humans. So that that's another challenge but also something to to recognize this context. Thanks for professor.

I've got a questions here and what you just mentioned about in your earlier speech about for your aim main aim of your center is to align the vocabulary of the Buddhists and also the the field of AI and I thought it's very profound because in the scholar field of AI there's a lot of debate from the philosophers and also psychologist is debating about what words to be used because a lot of concepts in terms of very thick concepts they stick with a lot of their meaning in inside in the history and then even there's even more thick in Buddhism I believe just like the consciousness this word in Buddhism and also western is totally different in terms of meaning then is it one of the reason why how you think to tackle this particular problem from the center at first and then the second question is is this also reason why you choose your SCI model to use stress in self-suffering and then see as a care instead of the compassion is this the compassion is this the something related in in this space.

Yeah. now I just the that what you describe is very much what was our immediate reality when getting together. The four of us know that we come with very different understandings about what the seemingly same words mean. And then yeah that that is just a very real challenge but it's also the potential for progress. I think it's bringing people who have a a specialtity or even expertise together so that they can explore together and then suddenly new insights can take place and I think this is an example of what can happen.

a model of this kind which I think is simple like one of the things I'd like to argue for this model is that it actually is applicable to some many different contexts where otherwise we may easily get lost in our own conceptual background and that makes it difficult to have a meaningful discussion.

But I think this one of the virtues that I like to think about for this system is that it enables us to find a framework so that we can actually discuss it's it's interesting to try and I encourage you to try it yourself to discuss a problem in terms of this express I think we slowly have to close like we have a time limit of 9: 15 And well, I'd like to say thank you very much. I I thank you very much. Yeah. For coming here and thank you also for your questions and thank you very much and very happy to stay in touch.

Thank you also to our supporters and to which includes my family, my wife and child who have supported me very patiently and also keep making me see the relevance of this of interdicciplinary work. So thank you very much. ---
