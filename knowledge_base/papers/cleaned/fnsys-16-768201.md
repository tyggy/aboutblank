---
type: paper
source: fnsys-16-768201.pdf
format: pdf
processed: true
---

# published: 24 March 2022

HYPOTHESIS AND THEORY
published: 24 March 2022
doi: 10.3389/fnsys.2022.768201
Edited by:
Eva Jablonka,
Tel Aviv University, Israel
Reviewed by:
Lars Chittka,
Queen Mary University of London,
United Kingdom
Louis Neal Irwin,
The University of Texas at El Paso,
United States
Patrick McGivern,
University of Wollongong, Australia
*Correspondence:
Michael Levin
michael.levin@tufts.edu
Received: 31 August 2021
Accepted: 24 January 2022
Published: 24 March 2022
Citation:
Levin M (2022) Technological
Approach to Mind Everywhere: An
Experimentally-Grounded Framework
for Understanding Diverse Bodies and
Minds.
Front. Syst. Neurosci. 16:768201.
doi: 10.3389/fnsys.2022.768201
Technological Approach to Mind
Everywhere: An
Experimentally-Grounded
Framework for Understanding
Diverse Bodies and Minds
Michael Levin1,2*
1 Allen Discovery Center at Tufts University, Medford, MA, United States, 2 Wyss Institute for Biologically Inspired Engineering
at Harvard University, Cambridge, MA, United States
Synthetic biology and bioengineering provide the opportunity to create novel embodied
cognitive systems (otherwise known as minds) in a very wide variety of chimeric
architectures combining evolved and designed material and software. These advances
are disrupting familiar concepts in the philosophy of mind, and require new ways of
thinking about and comparing truly diverse intelligences, whose composition and origin
are not like any of the available natural model species. In this Perspective, I introduce
TAME—Technological Approach to Mind Everywhere—a framework for understanding
and manipulating cognition in unconventional substrates. TAME formalizes a nonbinary (continuous), empirically-based approach to strongly embodied agency. TAME
provides a natural way to think about animal sentience as an instance of collective
intelligence of cell groups, arising from dynamics that manifest in similar ways in
numerous other substrates. When applied to regenerating/developmental systems,
TAME suggests a perspective on morphogenesis as an example of basal cognition. The
deep symmetry between problem-solving in anatomical, physiological, transcriptional,
and 3D (traditional behavioral) spaces drives speciﬁc hypotheses by which cognitive
capacities can increase during evolution. An important medium exploited by evolution for
joining active subunits into greater agents is developmental bioelectricity, implemented
by pre-neural use of ion channels and gap junctions to scale up cell-level feedback
loops into anatomical homeostasis. This architecture of multi-scale competency of
biological systems has important implications for plasticity of bodies and minds, greatly
potentiating evolvability. Considering classical and recent data from the perspectives of
computational science, evolutionary biology, and basal cognition, reveals a rich research
program with many implications for cognitive science, evolutionary biology, regenerative
medicine, and artiﬁcial intelligence.
Keywords: regeneration, basal cognition, bioelectricity, gap junctions, synthetic morphology, bioengineering
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
INTRODUCTION
All known cognitive agents are collective intelligences, because
we are all made of parts; biological agents in particular are not
just structurally modular, but made of parts that are themselves
agents in important ways. There is no truly monadic, indivisible
yet cognitive being: all known minds reside in physical systems
composed of components of various complexity and active
behavior. However, as human adults, our primary experience
is that of a centralized, coherent Self which controls events in
a top-down manner. That is also how we formulate models of
learning (“the rat learned X”), moral responsibility, decisionmaking, and valence: at the center is a subject which has agency,
serves as the locus of rewards and punishments, possesses (as
a single functional unit) memories, exhibits preferences, and
takes actions. And yet, under the hood, we ﬁnd collections
of cells which follow low-level rules via distributed, parallel
functionality and give rise to emergent system-level dynamics.
Much as single celled organisms transitioned to multicellularity
during evolution, the single cells of an embryo construct de novo,
and then operate, a uniﬁed Self during a single agent’s lifetime.
The compound agent supports memories, goals, and cognition
that belongs to that Self and not to any of the parts alone. Thus,
one of the most profound and far-reaching questions is that of
scaling and uniﬁcation: how do the activities of competent, lowerlevel agents give rise to a multiscale holobiont that is truly more
than the sum of its parts? And, given the myriad of ways that
parts can be assembled and relate to each other, is it possible to
deﬁne ways in which truly diverse intelligences can be recognized,
compared, and understood?
Here, I develop a framework to drive new theory and
experiment in biology, cognition, evolution, and biotechnology
from a multi-scale perspective on the nature and scaling of the
cognitive Self. An important part of this research program is
the need to encompass beings beyond the familiar conventional,
evolved, static model animals with brains. The gaps in existing
frameworks, and thus opportunities for fundamental advances,
are revealed by a focus on plasticity of existing forms, and
the functional diversity enabled by chimeric bioengineering. To
illustrate how this framework can be applied to unconventional
substrates, I explore a deep symmetry between behavior and
morphogenesis, deriving hypotheses for dynamics that upand down-scale Selves within developmental and phylogenetic
timeframes, and at the same time strongly impact the speed
of the evolutionary process itself (Dukas, 1998). I attempt to
show how anatomical homeostasis can be viewed as the result
of the behavior of the swarm intelligence of cells, and provides a
rich example of how an inclusive, forward-looking technological
framework can connect philosophical questions with speciﬁc
empirical research programs.
The philosophical context for the following perspective is
summarized in Table 1 (see also Glossary), and links tightly
to the ﬁeld of basal cognition (Birch et al., 2020) via a
fundamentally gradualist approach. It should be noted that the
speciﬁc proposals for biological mechanisms that scale functional
capacity are synergistic with, but not linearly dependent on,
this conceptual basis. The hypotheses about how bioelectric
TABLE 1 | The core tenets of TAME.
• Continuum of cognitive capacities—no binary categories, no bright line
separating true cognition from “just physics,” as is clear from evolutionary
process and ability to bioengineer chimeras between any two “natural kinds.”
• Mature frameworks must apply to truly diverse intelligences—beyond the
examples from Earth’s phylogenetic tree based on brains, we must be able
to consider and compare agents across the option space of designed and
evolved combinations of living, non-living, and software components at all
scales.
• Selves exist across a continuum of persuadability, and it is an empirical
question as to where on this axis any given system lies (revealed by the ratio
of prediction and control vs. effort and knowledge that needs to be input, for
any given way of relating to that system).
• Selves are not ﬁxed, permanent agents—their substrate can remodel
radically during their lifetime; the owner of memories and preferences, and
the subject that interprets rewards and punishments, is malleable and plastic.
• The core of being a Self is the ability to pursue goals. Selves can be nested
and overlapping, cooperating and competing both laterally and across levels.
Each higher-level self deforms the option space for the lower level Selves,
enabling them to follow energy minimization to achieve outcomes that look
inevitable and simple at one scale, while serving intelligent goals at a higher
scale.
• Intelligence is the degree of competency of navigating any space (not just the
familiar 3D space of motility), including morphospace, transcriptional space,
physiological space, etc., toward desirable regions, while avoiding being
trapped in local minima. Estimates of intelligence of any system are
observer-dependent, and say as much about the observer and their
limitations as they do about the system itself.
networks scale cell computation into anatomical homeostasis,
and the evolutionary dynamics of multi-scale competency,
can be explored without accepting the “minds everywhere”
commitments of the framework. However, together they form a
coherent lens onto the life sciences which helps generate testable
new hypotheses and integrate data from several subﬁelds.
For the purposes of this paper, “cognition” refers not only
to complex, self-reﬂexive advanced cognition or metacognition,
but is used in the less conservative sense that recognizes many
diverse capacities for learning from experience (Ginsburg and
Jablonka, 2021), adaptive responsiveness, self-direction, decisionmaking in light of preferences, problem-solving, active probing of
their environment, and action at diﬀerent levels of sophistication
in conventional (evolved) life forms as well as bioengineered
ones (Rosenblueth et al., 1943; Lyon, 2006; Bayne et al., 2019;
Levin et al., 2021; Lyon et al., 2021; Figure 1). For our purposes,
cognition refers to the functional computations that take place
between perception and action, which allow the agent to span
a wider range of time (via memory and predictive capacity,
however much it may have) than its immediate now, which enable
it to generalize and infer patterns from instances of stimuli—
precursors to more advanced forms of recombining concepts,
language, and logic.
The framework, TAME—Technological Approach to Mind
Everywhere—adopts
a
practical,
constructive
engineering
perspective on the optimal place for a given system on the
continuum of cognitive sophistication. This gives rise to an
axis of persuadability (Figure 2), which is closely related to the
Intentional Stance (Dennett, 1987) but made more explicit in
terms of functional engineering approaches needed to implement
prediction and control in practice. Persuadability refers to the
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 1 | Diverse, multiscale intelligence. (A) Biology is organized in a multi-scale, nested architecture of molecular pathways. (B) These are not merely structural,
but also computational: each level of this holarchy contains subsystems which exhibit some degree of problem-solving (i.e., intelligent) activity, on a continuum such
as the one proposed by Rosenblueth et al. (1943). (C) At each layer of a given biosystem, novel components can be introduced of either biological or engineered
origin, resulting in chimeric forms that have novel bodies and novel cognitive systems distinct from the typical model species on the Earth’s phylogenetic lineage.
Images in panels (A,C) by Jeremy Guay of Peregrine Creative. Image in panel (B) was created after Rosenblueth et al. (1943).
type of conceptual and practical tools that are optimal to
rationally modify a given system’s behavior. The origin story
(designed vs. evolved), composition, and other aspects are not
deﬁnitive guides to the correct level of agency for a living or
non-living system. Instead, one must perform experiments to see
which kind of intervention strategy provides the most eﬃcient
prediction and control (thus, one aim should be generalizing
the human-focused Turing Test and other IQ metrics into a
broader agency detection toolkit, which perhaps could itself be
implemented by a useful algorithm).
Our capacity to ﬁnd new ways to understand and manipulate
complex systems is strongly related to how we categorize
agency in our world. Newton didn’t invent two terms—gravity
(for terrestrial objects falling) and perhaps shmavity (for the
moon)—because it would have lost out on the much more
powerful uniﬁcation. TAME proposes a conceptual uniﬁcation
that would facilitate porting of tools across disciplines and model
systems. We should avoid quotes around mental terms because
there is no absolute, binary distinction between it knows and
it “knows”—only a diﬀerence in the degree to which a model will
be useful that incorporates such components.
Given this perspective, below I develop hypotheses about
invariants that unify otherwise disparate-seeming problems, such
as morphogenesis, behavior, and physiological allostasis. I take
goals (in the cybernetic sense) and stressors (as a system-level
result of distance from one’s goals) as key invariants which allow
us to study and compare agents in truly diverse embodiments.
The processes which scale goals and stressors form a positive
feedback loop with modularity, thus both arising from, and
potentiating the power of, evolution. These hypotheses suggest
a speciﬁc way to understand the scaling of cognitive capacity
through evolution, make interesting predictions, and suggest
novel experimental work. They also provide ways to think about
the impending expansion of the “space of possible bodies and
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 2 | The axis of persuadability. A proposed way to visualize a continuum of agency, which frames the problem in a way that is testable and drives empirical
progress, is via an “axis of persuadability”: to what level of control (ranging from brute force micromanagement to persuasion by rational argument) is any given
system amenable, given the sophistication of its cognitive apparatus? Here are shown only a few representative waypoints. On the far left are the simplest physical
systems, e.g., mechanical clocks (A). These cannot be persuaded, argued with, or even rewarded/punished—only physical hardware-level “rewiring” is possible if
one wants to change their behavior. On the far right (D) are human beings (and perhaps others to be discovered) whose behavior can be radically changed by a
communication that encodes a rational argument that changes the motivation, planning, values, and commitment of the agent receiving this. Between these
extremes lies a rich panoply of intermediate agents, such as simple homeostatic circuits (B) which have setpoints encoding goal states, and more complex systems
such as animals which can be controlled by signals, stimuli, training, etc., (C). They can have some degree of plasticity, memory (change of future behavior caused
by past events), various types of simple or complex learning, anticipation/prediction, etc. Modern “machines” are increasingly occupying right-ward positions on this
continuum (Bongard and Levin, 2021). Some may have preferences, which avails the experimenter of the technique of rewards and punishments—a more
sophisticated control method than rewiring, but not as sophisticated as persuasion (the latter requires the system to be a logical agent, able to comprehend and be
moved by arguments, not merely triggered by signals). Examples of transitions include turning the sensors of state outward, to include others’ stress as part of one’s
action policies, and eventually the meta-goal of committing to enhance one’s agency, intelligence, or compassion (increase the scope of goals one can pursue).
A more negative example is becoming sophisticated enough to be susceptible to a “thought that breaks the thinker” (e.g., existential or skeptical arguments that can
make one depressed or even suicidal, Gödel paradoxes, etc.)—massive changes can be made in those systems by a very low-energy signal because it is treated as
information in the context of a complex host computational machinery. These agents exhibit a degree of multi-scale plasticity that enables informational input to
make strong changes in the structure of the cognitive system itself. The positive ﬂip side of this vulnerability is that it avails those kinds of minds with a long term
version of free will: the ability through practice and repeated effort to change their own thinking patterns, responses to stimuli, and functional cognition. This
continuum is not meant to be a linear scala naturae that aligns with any kind of “direction” of evolutionary progress—evolution is free to move in any direction in this
option space of cognitive capacity; instead, this scheme provides a way to formalize (for a pragmatic, engineering approach) the major transitions in cognitive
capacity that can be exploited for increased insight and control. The goal of the scientist is to ﬁnd the optimal position for a given system. Too far to the right, and
one ends up attributing hopes and dreams to thermostats or simple AIs in a way that does not advance prediction and control. Too far to the left, and one loses the
beneﬁts of top-down control in favor of intractable micromanagement. Note also that this forms a continuum with respect to how much knowledge one has to have
about the system’s details in order to manipulate its function: for systems in class A, one has to know a lot about their workings to modify them. For class B, one has
to know how to read-write the setpoint information, but does not need to know anything about how the system will implement those goals. For class C, one doesn’t
have to know how the system modiﬁes its goal encodings in light of experience, because the system does all of this on its own—one only has to provide rewards
and punishments. Images by Jeremy Guay of Peregrine Creative.
minds” via the eﬀorts of bioengineers, which is sure to disrupt
categories and conclusions that have been formed in the context
of today’s natural biosphere.
What of consciousness? It is likely impossible to understand
sentience without understanding cognition, and the emphasis of
this paper is on testable, empirical impacts of ways to understand
cognition in all of its guises. By enabling the deﬁnition, detection,
and comparison of cognition and intelligence, in diverse
substrates beyond standard animals, we can enhance the range
of embodiments in which sentience may result. In order to move
the ﬁeld forward via empirical progress, the focus of most of the
discussion below is on ways to think about cognitive function, not
on phenomenal or access consciousness [in the sense of the “Hard
Problem” (Chalmers, 2013)]. However, I return to this issue at the
end, discussing TAME’s view of sentience as fundamentally tied to
goal-directed activity, only some aspects of which can be studied
via third person approaches.
The main goal is to help advance and delineate an exciting
emerging ﬁeld at the intersection of biology, philosophy, and
the information sciences. By proposing a new framework and
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
examining it in a broad context of now physically realizable (not
merely logically possible) living structures, it may be possible
to bring conceptual, philosophical thought up to date with
recent advances in science and technology. At stake are current
knowledge gaps in evolutionary, developmental, and cell biology,
a new roadmap for regenerative medicine, lessons that could
be ported to artiﬁcial intelligence and robotics, and broader
implications for ethics.
COGNITION: CHANGING THE SUBJECT
Even
advanced
animals
are
really
collective
intelligences
(Couzin, 2007, 2009; Valentini et al., 2018), exploiting still
poorly-understood scaling and binding features of metazoan
architectures that share a continuum with looser swarms that
have been termed “liquid brains” (Sole et al., 2019). Studies
of “centralized control” focus on a brain, which is in eﬀect
a network of cells performing functions that many cell types,
including bacteria, can do (Koshland, 1983). The embodied
nature of cognition means that the minds of Selves are dependent
on a highly plastic material substrate which changes not only
on evolutionary time scales but also during the lifetime of the
agent itself.
The central consequence of the composite nature of all
intelligences is that the Self is subject to signiﬁcant change in
real-time (Figure 3). This means both slow maturation through
experience (a kind of “software” change that doesn’t disrupt
traditional ways of thinking about agency), as well as radical
changes of the material in which a given mind is implemented
(Levin, 2020). The owner, or subject of memories, preferences,
and in more advanced cases, credit and blame, is very malleable.
At the same time, fascinating mechanisms somehow ensure the
persistence of Self (such as complex memories) despite drastic
alterations of substrate. For example, the massive remodeling
of the caterpillar brain, followed by the morphogenesis of an
entirely diﬀerent brain suitable for the moth or beetle, does not
wipe all the memories of the larva but somehow maps them onto
behavioral capacities in the post-metamorphosis host, despite its
entirely diﬀerent body (Alloway, 1972; Tully et al., 1994; Sheiman
and Tiras, 1996; Armstrong et al., 1998; Ray, 1999; Blackiston
et al., 2008). Not only that, but memories can apparently persist
following the complete regeneration of brains in some organisms
(McConnell et al., 1959; Corning, 1966; Shomrat and Levin,
2013) such as planaria, in which prior knowledge and behavioral
tendencies are somehow transferred onto a newly-constructed
brain. Even in vertebrates, such as ﬁsh (Versteeg et al., 2021) and
mammals (von der Ohe et al., 2006), brain size and structure
can change repeatedly during their lifespan. This is crucial to
understanding agency and intelligence at multiple scales and in
unfamiliar embodiments because observations like this begin to
break down the notion of Selves as monadic, immutable objects
with a privileged scale. Becoming comfortable with biological
cognitive agents that are malleable in terms of form and function
(change radically during the lifetime of an individual) makes it
easier to understand the origins and changes of cognition during
evolution or as the result of bioengineering eﬀort.
This
little-studied
intersection
between
regeneration/
remodeling and cognition highlights the fascinating plasticity of
the body, brain, and mind; traditional model systems in which
cognition is mapped onto a stable, discrete, mature brain are
insuﬃcient to fully understand the relationship between the Self
and its material substrate. Many scientists study the behavioral
properties of caterpillars, and of butterﬂies, but the transition
zone in-between, from the perspective of philosophy of mind
and cognitive science, provides an important opportunity to
study the mind-body relationship by changing the body during
the lifetime of the agent (not just during evolution). Note that
continuity of being across drastic biological remodeling is not
only relevant for unusual cases in the animal kingdom, but is a
fundamental property of most life—even humans change from
a collection of cells to a functional individual, via a gradual
morphogenetic process that constructs an active Self in real time.
This has not been addressed in biology, and likewise not yet in
computer science, where machine learning approaches use static
neural networks (there is not a formalism for altering artiﬁcial
neural networks’ architecture on the ﬂy).
What are the invariants that enable a Self to persist (and be
recognizable by third-person investigations) despite such change?
Memory is a good candidate (Shoemaker, 1959; Ameriks, 1976;
Figure 3). However, at least certain kinds of memories can be
transferred between individuals, by transplants of brain tissue
or molecular engrams (Pietsch and Schneider, 1969; McConnell
and Shelby, 1970; Bisping et al., 1971; Chen et al., 2014;
Bedecarrats et al., 2018; Abraham et al., 2019). Importantly,
the movement of memories across individual animals is only
a special case of the movement of memory in biological
tissue in general. Even when housed in the same “body,”
memories must move between tissues—for example, in a trained
planarian’s tail fragment re-imprinting its learned information
onto the newly regenerated brain, or the movement of memories
onto new brain tissue during metamorphosis. In addition
to the spatial movement and re-mapping of memories onto
new substrates, there is also a temporal component, as each
memory is really an instance of communication between past
and future Selves. The plasticity of biological bodies, made of
cells that die, are born, and signiﬁcantly rearrange their tissue
architecture, suggests that the understanding of cognition is
fundamentally a problem of collective intelligence: to understand
how stable cognitive structures can persist and map onto swarm
dynamics, with preferences and stressors that scale from those of
their components.
This is applicable even to such a “stable” form as the human
brain, which is often spoken of as a single Subject of experience
and thought. First, the gulf between planarian regeneration/insect
metamorphosis and human brains is going to be bridged by
emerging therapeutics. It is inevitable that stem cell therapies
for degenerative brain diseases (Forraz et al., 2013; Rosser and
Svendsen, 2014; Tanna and Sachan, 2014) will confront us
with humans whose brains are partially replaced by the naïve
progeny of cells that were not present during the formation of
memories and personality traits in the patient. Even prior to
these advances, it was clear that phenomena such as dissociative
identity disorder (Miller and Triggiano, 1992), communication
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 3 | Cognitive Selves can change in real-time. (A) Caterpillars metamorphose into butterﬂies, going through a process in which their body, brain, and
cognitive systems are drastically remodeled during the lifetime of a single agent. Importantly, memories remain and persist through this process (Blackiston et al.,
2015). (B) Planaria cut into pieces regenerate, with each piece re-growing and remodeling precisely what is needed to form an entire animal. (C) Planarians derived
from tail fragments of trained worms still retain original information, illustrating the ability of memories to move across tissues and be reimprinted on newly-developing
brains (Corning, 1966, 1967; Shomrat and Levin, 2013). Images by Jeremy Guay of Peregrine Creative.
with non-verbal brain hemispheres in commissurotomy patients
(Nagel, 1971; Montgomery, 2003), conjoined twins with fused
brains (Gazzaniga, 1970; Barilan, 2003), etc., place human
cognition onto a continuous spectrum with respect to the
plasticity of integrated Selves that reside within a particular
biological tissue implementation.
Importantly, animal model systems are now providing the
ability to harness that plasticity for functional investigations
of the body-mind relationship. For example, it is now easy
to radically modify bodies in a time-scale that is much faster
than evolutionary change, to study the inherent plasticity of
minds without eons of selection to shape them to ﬁt speciﬁc
body architectures. When tadpoles are created to have eyes on
their tails, instead of their heads, they are still readily able
to perform visual learning tasks (Blackiston and Levin, 2013;
Blackiston et al., 2017). Planaria can readily be made with two
(or more) brains in the same body (Morgan, 1904; Oviedo
et al., 2010), and human patients are now routinely augmented
with novel inputs [such as sensory substitution (Bach-y-Rita
et al., 1969; Bach-y-Rita, 1981; Danilov and Tyler, 2005;
Ptito et al., 2005)] or novel eﬀectors, such as instrumentized
interfaces allowing thought to control engineered devices such as
wheelchairs in addition to the default muscle-driven peripherals
of their own bodies (Green and Kalaska, 2011; Chamola et al.,
2020; Belwaﬁet al., 2021). The central phenomenon here is
plasticity: minds are not tightly bound to one speciﬁc underlying
architecture (as most of our software is today), but readily
mold to changes of genomic defaults. The logical extension of
this progress is a focus on self-modifying living beings and
the creation of new agents in which the mind:body system is
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
simpliﬁed by entirely replacing one side of the equation with an
engineered construct. The beneﬁt would be that at least one half
of the system is now well-understood.
For example, in hybrots, animal brains are functionally
connected to robotics instead of their normal body (Reger et al.,
2000; Potter et al., 2003; Tsuda et al., 2009; Ando and Kanzaki,
2020). It doesn’t even have to be an entire brain—a plate of
neurons can learn to ﬂy a ﬂight simulator, and it lives in a
new virtual world (DeMarse and Dockendorf, 2005; Manicka
and Harvey, 2008; Beer, 2014), as seen from the development
of closed-loop neurobiological platforms (Demarse et al., 2001;
Potter et al., 2005; Bakkum et al., 2007b; Chao et al., 2008;
Rolston et al., 2009a,b). These kinds of results are reminiscent
of Philosophy 101’s “brain in a vat” experiment (Harman, 1973).
Brains adjust to driving robots and other devices as easily as
they adjust to controlling a typical, or highly altered, living body
because minds are somehow adapted and prepared to deal with
body alterations—throughout development, metamorphosis and
regeneration, and evolutionary change.
The massive plasticity of bodies, brains, and minds means
that a mature cognitive science cannot just concern itself with
understanding standard “model animals” as they exist right now.
The typical “subject,” such as a rat or fruit ﬂy, which remains
constant during the course of one’s studies and is conveniently
abstracted as a singular Self or intelligence, obscures the bigger
picture. The future of this ﬁeld must expand to frameworks
that can handle all of the possible minds across an immense
option space of bodies. Advances in bioengineering and artiﬁcial
intelligence suggest that we or our descendants will be living in
a world in which Darwin’s “endless forms most beautiful” (this
Earth’s N = 1 ecosystem outputs) are just a tiny sample of the true
variety of possible beings. Biobots, hybrots, cyborgs, synthetic
and chimeric animals, genetically and cellularly bioengineered
living forms, humans instrumentized to knowledge platforms,
devices, and each other—these technologies are going to generate
beings whose body architectures are nothing like our familiar
phylogeny. They will be a functional mix of evolved and
designed components; at all levels, smart materials, software-level
systems, and living tissue will be integrated into novel beings
which function in their own exotic Umwelt. Importantly, the
information that is used to specify such beings’ form and function
is no longer only genetic—it is truly “epigenetic” because it comes
not only from the creature’s own genome but also from human
and non-human agents’ minds (and eventually, robotic machinelearning-driven platforms) that use cell-level bioengineering to
generate novel bodies from genetically wild-type cells. In these
cases, the genetics are no guide to the outcome (which highlights
some of the profound reasons that genetics is hard to use to
truly predict cognitive form and function even in traditional
living species).
Now is the time to begin to develop ways of thinking
about truly novel bodies and minds, because the technology is
advancing more rapidly than philosophical progress. Many of
the standard philosophical puzzles concerning brain hemisphere
transplants, moving memories, replacing body/brain parts, etc.
are now eminently doable in practice, while the theory of how
to interpret the results lags. We now have the opportunity to
begin to develop conceptual approaches to (1) understand beings
without convenient evolutionary back-stories as explanations for
their cognitive capacities (whose minds are created de novo,
and not shaped by long selection pressures toward speciﬁc
capabilities), and (2) develop ways to analyze novel Selves that
are not amenable to simple comparisons with related beings,
not informed by their phylogenetic position relative to known
standard species, and not predictable from an analysis of their
genetics. The implications range across insights into evolutionary
developmental biology, advancing bioengineering and artiﬁcial
life research, new roadmaps for regenerative medicine, ability to
recognize exobiological life, and the development of ethics for
relating to novel beings whose composition oﬀers no familiar
phylogenetic touchstone. Thus, here I propose the beginnings
of a framework designed to drive empirical research and
conceptual/philosophical analysis that will be broadly applicable
to minds regardless of their origin story or internal architecture.
TECHNOLOGICAL APPROACH TO MIND
EVERYWHERE: A PROPOSAL FOR A
FRAMEWORK
The Technological Approach to Mind Everywhere (TAME)
framework seeks to establish a way to recognize, study, and
compare truly diverse intelligences in the space of possible agents.
The goal of this project is to identify deep invariants between
cognitive systems of very diﬀerent types of agents, and abstract
away from inessential features such as composition or origin,
which were suﬃcient heuristics with which to recognize agency in
prior decades but will surely be insuﬃcient in the future (Bongard
and Levin, 2021). To ﬂesh out this approach, I ﬁrst make explicit
some of its philosophical foundations, and then discuss speciﬁc
conceptual tools that have been developed to begin the task of
understanding embodied cognition in the space of mind-as-itcan-be (a sister concept to Langton’s motto for the artiﬁcial life
community—“life as it can be”) (Langton, 1995).
Philosophical Foundations of an
Approach to Diverse Intelligences
One key pillar of this research program is the commitment to
gradualism with respect to almost all important cognition-related
properties: advanced minds are in important ways generated in
a continuous manner from much more humble proto-cognitive
systems. On this view, it is hopeless to look for a clear bright line
that demarcates “true” cognition (such as that of humans, great
apes, etc.) from metaphorical “as if cognition” or “just physics.”
Taking evolutionary biology seriously means that there is a
continuous series of forms that connect any cognitive system with
much more humble ones. While phylogenetic history already
refutes views of a magical arrival of “true cognition” in one
generation, from parents that didn’t have it (instead stretching
the process of cognitive expansion over long time scales and
slow modiﬁcation), recent advances in biotechnology make this
completely implausible. For any putative diﬀerence between a
creature that is proposed to have true preferences, memories, and
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
plans and one that supposedly has none, we can now construct
in-between, hybrid forms which then make it impossible to say
whether the resulting being is an Agent or not. Many pseudoproblems evaporate when a binary view of cognition is dissolved
by an appreciation of the plasticity and interoperability of living
material at all scales of organization. A deﬁnitive discussion of
the engineering of preferences and goal-directedness, in terms
of hierarchy requirements and upper-directedness, is given in
McShea (2013, 2016).
For example, one view is that only biological, evolved forms
have intrinsic motivation, while software AI agents are only
faking it via functional performance [but don’t actually care
(Oudeyer and Kaplan, 2007, 2013; Lyon and Kuchling, 2021)].
But which biological systems really care—ﬁsh? Single cells? Do
mitochondria (which used to be independent organisms) have
true preferences about their own or their host cells’ physiological
states? The lack of consensus on this question in classical
(natural) biological systems, and the absence of convincing
criteria that can be used to sort all possible agents to one or
the other side of a sharp line, highlight the futility of truly
binary categories. Moreover, we can now readily construct hybrid
systems that consist of any percentage of robotics tightly coupled
to on-board living cells and tissues, which function together as
one integrated being. How many living cells does a robot need
to contain before the living system’s “true” cognition bleeds over
into the whole? On the continuum between human brains (with
electrodes and a machine learning converter chip) that drive
assistive devices (e.g., 95% human, 5% robotics), and robots with
on-board cultured human brain cells instrumentized to assist
with performance (5% human, 95% robotics), where can one
draw the line—given that any desired percent combination is
possible to make? No quantitative answer is suﬃcient to push a
system “over the line” because there is no such line (at least, no
convincing line has been proposed). Interesting aspects of agency
or cognition are rarely if ever Boolean values.
Instead of a binary dichotomy, which leads to impassable
philosophical
roadblocks,
we
envision
a
continuum
of
advancement
and
diversity
in
information-processing
capacity. Progressively more complex capabilities [such as
unlimited associative learning, counterfactual modeling, symbol
manipulation, etc., (Ginsburg and Jablonka, 2021)] ramp
up, but are nevertheless part of a continuous process that
is not devoid of proto-cognitive capacity before complex
brains appear. Speciﬁcally, while major diﬀerences in cognitive
function of course exist among diverse intelligences, transitions
between them have not been shown to be binary or rapid
relative to the timescale of individual agents. There is no
plausible reason to think that evolution produces parents
that don’t have “true cognition” but give rise to oﬀspring
that suddenly do, or that development starts with an embryo
that has no “true preferences” and sharply transitions into
an animal that does, etc. Moreover, bioengineering and
chimerization can produce a smooth series of transitional
forms between any two forms that are proposed to have,
or not have, any cognitive property. Thus, agents gradually
shift
(during
their
lifetime,
as
result
of
development,
metamorphosis, or interactions with other agents, or during
evolutionary timescales) between great transitions in cognitive
capacity,
expressing
and
experiencing
intermediate
states
of cognitive capacity that must be recognized by empirical
approaches to study them.
A focus on the plasticity of the embodiments of mind strongly
suggests this kind of gradualist view, which has been expounded
in the context of evolutionary forces controlling individuality
(Godfrey-Smith, 2009; Queller and Strassmann, 2009). Here the
additional focus is on events taking place within the lifetime of
individuals and driven by information and control dynamics.
The TAME framework pushes experimenters to ask “how much”
and “what kind of” cognition any given system might manifest
if we interacted with it in the right way, at the right scale of
observation. And of course, the degree of cognition is not a
single parameter that gives rise to a scala naturae but a shorthand
for the shape and size of its cognitive capacities in a rich space
(discussed below).
The second pillar of TAME is that there is no privileged
material substrate for Selves. Alongside familiar materials such
as brains made of neurons, the ﬁeld of basal cognition (Nicolis
et al., 2011; Reid et al., 2012, 2013; Beekman and Latty, 2015;
Baluška and Levin, 2016; Boussard et al., 2019; Dexter et al.,
2019; Gershman et al., 2021; Levin et al., 2021; Lyon et al., 2021)
has been identifying novel kinds of intelligences in single cells,
plants, animal tissues, and swarms. The ﬁelds of active matter,
intelligent materials, swarm robotics, machine learning, and
someday, exobiology, suggest that we cannot rely on a familiar
signature of “big vertebrate brain” as a necessary condition for
mind. Molecular phylogeny shows that the speciﬁc components
of brains pre-date the evolution of neurons per se, and life has
been solving problems long before brains came onto the scene
(Buznikov et al., 2005; Levin et al., 2006; Jekely et al., 2015;
Liebeskind et al., 2015; Moran et al., 2015). Powerful uniﬁcation
and generalization of concepts from cognitive science and other
ﬁelds can be achieved if we develop tools to characterize and
relate to a wide diversity of minds in unconventional material
implementations (Damasio, 2010; Damasio and Carvalho, 2013;
Cook et al., 2014; Ford, 2017; Man and Damasio, 2019; Baluska
et al., 2021; Reber and Baluska, 2021).
Closely related to that is the de-throning of natural evolution
as the only acceptable origin story for a true Agent [many
have proposed a distinction between evolved living forms
vs. the somehow inadequate machines which were merely
designed by man (Bongard and Levin, 2021)]. First, synthetic
evolutionary processes are now being used in the lab to create
“machines” and modify life (Kriegman et al., 2020a; Blackiston
et al., 2021). Second, the whole process of evolution, basically
a hill-climbing search algorithm, results in a set of frozen
accidents and meandering selection among random tweaks to
the micro-level hardware of cells, with impossible to predict
large-scale consequences for the emergent system level structure
and function. If this short-sighted process, constrained by
many forces that have nothing to do with favoring complex
cognition, can give rise to true minds, then so can a rational
engineering approach. There is nothing magical about evolution
(driven by randomizing processes) as a forge for cognition;
surely we can eventually do at least as well, and likely much
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
better, using rational construction principles and an even wider
range of materials.
The third foundational aspect of TAME is that the correct
answer to how much agency a system has cannot be settled by
philosophy—it is an empirical question. The goal is to produce a
framework that drives experimental research programs, not only
philosophical debate about what should or should not be possible
as a matter of deﬁnition. To this end, the productive way to think
about this a variant of Dennett’s Intentional Stance (Dennett,
1987; Mar et al., 2007), which frames properties such as cognition
as observer-dependent, empirically testable, and deﬁned by how
much beneﬁt their recognition oﬀers to science (Figure 2). Thus,
the correct level of agency with which to treat any system must
be determined by experiments that reveal which kind of model
and strategy provides the most eﬃcient predictive and control
capability over the system. In this engineering (understand,
modify, build)-centered view, the optimal position of a system on
the spectrum of agency is determined empirically, based on which
kind of model aﬀords the most eﬃcient way of prediction and
control. Such estimates are, by their empirical nature, subject to
revision by future experimental data and conceptual frameworks,
and are observer-dependent (not absolute).
A standard methodology in science is to avoid attributing
agency to a given system unless absolutely necessary. The
mainstream view (e.g., Morgan’s Canon) is that it’s too easy
to fall into a trap of “anthropomorphizing” systems with
only apparent cognitive powers, when one should only be
looking for models focused on mechanistic, lower levels of
description that eschew any kind of teleology or mental capacity
(Morgan, 1903; Epstein, 1984). However, analysis shows that
this view provides no useful parsimony (Cartmill, 2017). The
rich history of debates on reductionism and mechanism needs
to be complemented with an empirical, engineering approach
that is not inappropriately slanted in one direction on this
continuum. Teleophobia leads to Type 2 errors with respect
to attribution of cognition that carry a huge opportunity cost
for not only practical outcomes like regenerative medicine
(Pezzulo and Levin, 2015) and engineering, but also ethics.
Humans (and many other animals) readily attribute agency to
systems in their environment; scientists should be comfortable
with testing out a theory of mind regarding various complex
systems for the exact same reason—it can often greatly enhance
prediction and control, by recognizing the true features of
the systems with which we interact. This perspective implies
that there is no such thing as “anthropomorphizing” because
human beings have no unique essential property which can
be inappropriately attributed to agents that have none of it.
Aside from the very rare trivial cases (misattributing humanlevel cognition to simpler systems), we must be careful to
avoid the pervasive, implicit remnants of a human-centered
pre-scientiﬁc worldview in which modern, standard humans
are assumed to have some sort of irreducible quality that
cannot be present in degrees in slightly (or greatly) diﬀerent
physical implementations (from early hominids to cyborgs etc.).
Instead, we should seek ways to naturalize human capacities
as elaborations of more fundamental principles that are widely
present in complex systems, in very diﬀerent types and degrees,
and to identify the correct level for any given system. Of
course, this is just one stance, emphasizing experimental,
not philosophical, approaches that avoid deﬁning impassable
absolute diﬀerences that are not explainable by any known binary
transition in body structure or function. Others can certainly
drive empirical work focused speciﬁcally on what kind of humanlevel capacities do and do not exist in detectable quantity
in other agents.
Avoiding philosophical wrangling over privileged levels of
explanation (Ellis, 2008; Ellis et al., 2012; Noble, 2012), TAME
takes an empirical approach to attributing agency, which
increases the toolkit of ways to relate to complex systems, and
also works to reduce proﬂigate attributions of mental qualities.
We do not say that a thermos knows whether to keep something
hot or cold, because no model of thermos cognition does better
than basic thermodynamics to explain its behavior or build better
thermoses. At the same time, we know we cannot simply use
Newton’s laws to predict the motion of a (living) mouse at the
top of a hill, requiring us to construct models of navigation and
goal-directed activity for the controller of the mouse’s behavior
over time (Jennings, 1906).
Under-estimating the capacity of a system for plasticity,
learning, having preferences, representation, and intelligent
problem-solving greatly reduces the toolkit of techniques we can
use to understand and control its behavior. Consider the task
of getting a pigeon to correctly distinguish videos of dance vs.
those of martial arts. If one approaches the system bottom-up,
one has to implement ways to interface to individual neurons in
the animal’s brain to read the visual input, distinguish the videos
correctly, and then control other neurons to force the behavior
of walking up to a button and pressing it. This may someday be
possible, but not in our lifetimes. In contrast, one can simply
train the pigeon (Qadri and Cook, 2017). Humanity has been
training animals for millennia, without knowing anything about
what is in their heads or how brains work. This highly eﬃcient
trick works because we correctly identiﬁed them as learning
agents, which allows us to oﬄoad a lot of the computational
complexity of any task onto the living system itself, without
micromanaging its components.
What other systems might this remarkably powerful strategy
apply to? For example, gene regulatory networks (GRNs) are a
paradigmatic example of “genetic mechanism,” often assumed
to be tractable only by hardware (requiring gene therapy
approaches to alter promoter sequences that control network
connectivity, or adding/removing gene nodes). However, being
open to the possibility that GRNs might actually be on a diﬀerent
place on this continuum suggests an experiment in which
they are trained for new behaviors with speciﬁc combinations
of stimuli (experiences). Indeed, recent analyses of biological
GRN models reveal that they exhibit associative and several
other kinds of learning capacity, as well as pattern completion
and generalization (Watson et al., 2010, 2014; Szilagyi et al.,
2020; Biswas et al., 2021). This is an example in which an
empirical approach to the correct level of agency for even
simple systems not usually thought of as cognitive suggests
new hypotheses which in turn open a path to new practical
applications (biomedical strategies using associative regimes of
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
drug pulsing to exploit memory and address pharmacoresistance
by abrogating habituation, etc.).
We
next
consider
speciﬁc
aspects
of
the
framework,
before diving into speciﬁc examples in which it drives
novel empirical work.
Speciﬁc Conceptual Components of the
Technological Approach to Mind
Everywhere Framework
A useful framework in this emerging ﬁeld should not only
serve as a lens with which to view data and concepts (Manicka
and Levin, 2019b), but also should drive research in several
ways. It needs to ﬁrst specify deﬁnitions for key terms such
as a Self. These are not meant to be exclusively correct—the
deﬁnitions can co-exist with others, but should identify a claim
as to what is an essential invariant for Selves (and what other
aspects can diverge), and how it intersects with experiment.
The fundamental symmetry unifying all possible Selves should
also facilitate direct comparison or even classiﬁcation of truly
diverse intelligences, sketching the markers of Selfhood and the
topology of the option space within which possible agents exist.
The framework should also help scientists derive testable claims
about how borders of a given Self are determined, and how
it interacts with the outside world (and other agents). Finally,
the framework should provide actionable, semi-quantitative
deﬁnitions that have strong implications and constrain theories
about how Selves arise and change. All of this must facilitate
experimental approaches to determine the empirical utility
of this approach.
The TAME framework takes the following as the basic
hallmarks of being a Self: the ability to pursue goals, to own
compound (e.g., associative) memories, and to serve as the locus
for credit assignment (be rewarded or punished), where all of
these are at a scale larger than possible for any of its components
alone. Given the gradualist nature of the framework, the key
question for any agent is “how well,” “how much,” and “what
kind” of capacity it has for each of those key aspects, which
in turn allows agents to be directly compared in an option
space. TAME emphasizes deﬁning a higher scale at which the
(possibly competent) activity of component parts gives rise to
an emergent system. Like a valid mathematical theorem which
has a unique structure and existence over and above any of its
individual statements, a Self can own, for example, associative
memories (that bind into new mental content experiences that
occurred separately to its individual parts), be the subject of
reward or punishment for complex states (as a consequence of
highly diverse actions that its parts have taken), and be stressed
by states of aﬀairs (deviations from goals or setpoints) that are not
deﬁnable at the level of any of its parts (which of course may have
their own distinct types of stresses and goals). These are practical
aspects that suggest ways to recognize, create, and modify Selves.
Selves can be classiﬁed and compared with respect to the scale
of goals they can pursue [Figure 4, described in detail in Levin
(2019)]. In this context, the goal-directed perspective adopted
here builds on the work of Rosenblueth et al. (1943); Nagel (1979);
and Mayr (1992), emphasizing plasticity (ability to reach a goal
state from diﬀerent starting points) and persistence (capacity to
reach a goal (Schlosser, 1998) state despite perturbations).
The ability of a system to exert energy to work toward a
state of aﬀairs, overcoming obstacles (to the degree that its
sophistication allows) to achieve a particular set of substates is
very useful for deﬁning Selves because it grounds the question
in well-established control theory and cybernetics (i.e., systems
“trying to do things” is no longer magical but is well-established in
engineering), and provides a natural way of discovering, deﬁning,
and altering the preferences of a system. A common objection is:
“surely we can’t say that thermostats have goals and preferences?”
The TAME framework holds that whatever true goals and
preferences are, there must exist primitive, minimal versions
from which they evolved and these are, in an important sense,
substrate- and scale-independent; simple homeostatic circuits
are an ideal candidate for the “hydrogen atom” of goal-directed
activity (Rosenblueth et al., 1943; Turner, 2019). A key tool for
thinking about these problems is to ask what a truly minimal
example of any cognitive capacity would be like, and to think
about transitional forms that can be created just below that. It
is logically inevitable that if one follows a complex cognitive
capacity backward through phylogeny, one eventually reaches
precursor versions of that capacity that naturally suggest the
(misguided) question “is that really cognitive, or just physics?”
Indeed, a kind of minimal goal-directedness permeates all of
physics (Feynman, 1942; Georgiev and Georgiev, 2002; Ogborn
et al., 2006; Kaila and Annila, 2008; Ramstead et al., 2019;
Kuchling et al., 2020a), supporting a continuous climb of the scale
and sophistication of goals.
Pursuit of goals is central to composite agency and the “many
to one” problem because it requires distinct mechanisms (for
measurement of states, storing setpoints, and driving activity to
minimize the delta between the former and the latter) to be
bound together into a functional unit that is greater than its
parts. To co-opt a great quote (Dobzhansky, 1973), nothing in
biology makes sense except in light of teleonomy (Pittendrigh,
1958; Nagel, 1979; Mayr, 1992; Schlosser, 1998; Noble, 2010,
2011; Auletta, 2011; Ellis et al., 2012). The degree to which a
system can evaluate possible consequences of various actions, in
pursuit of those goal states, can vary widely, but is essential to
its survival. The expenditure of energy in ways that eﬀectively
reach speciﬁc states despite uncertainty, limitations of capability,
and meddling from outside forces is proposed as a central unifying
invariant for all Selves—a basis for the space of possible agents.
This view suggests a semi-quantitative multi-axis option space
that enables direct comparison of diverse intelligences of all
sorts of material implementation and origins (Levin, 2019, 2020).
Speciﬁcally (Figure 4), a “space-time” diagram can be created
where the spatio-temporal scale of any agent’s goals delineates
that Self and its cognitive boundaries.
Note that the distances on Figure 4D represent not ﬁrstorder capacities such as sensory perception (how far away
can it sense), but second-order capacities of the size of goals
(humble metabolic hunger-satiety loops or grandiose planetaryscale engineering ambitions) which a given cognitive system
is capable of representing and working toward. At any given
time, an Agent is represented by a single shape in this space,
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 4 | Unconventional goal-directed agents and the scaling of the cognitive Self. (A) The minimal component of agency is homeostasis, for example the ability
of a cell to execute the Test-Operate-Exit (Pezzulo and Levin, 2016) loop: a cycle of comparison with setpoint and adjustment via effectors, which allows it to remain
in a particular region of state space. (B) This same capacity is scaled up by cellular networks into anatomical homeostasis: morphogenesis is not simply a
feedforward emergent process but rather the ability of living systems to adjust and remodel to speciﬁc target morphologies. This requires feedback loops at the
transcriptional and biophysical levels, which rely on stored information (e.g., bioelectrical pattern memories) against which to minimize error. (C) This is what underlies
complex regeneration such as salamander limbs, which can be cut at any position and result in just the right amount and type of regenerative growth that stops
when a correct limb is achieved. Such homeostatic systems are examples of simple goal-directed agents. (D) A focus on the size or scale of goals any given system
can pursue allows plotting very diverse intelligences on the same graph, regardless of their origin or composition (Levin, 2019). The scale of their goal-directed
activity is estimated (collapsed onto one axis of space and one of time, as in Relativity diagrams). Importantly, this way of visualizing the sophistication of agency is a
schematic of goal space—it is not meant to represent the spatial extent of sensing or effector range, but rather the scale of events about which they care and the
boundary of states that they can possibly represent or work to change. This deﬁnes a kind of cognitive light cone (a boundary to any agent’s area of concern); the
largest area represents the “now,” with fading efﬁcacy both backward (accessing past events with decreasing reliability) and forward (limited prediction accuracy for
future events). Agents are compound entities, composed of (and comprising) other sub- or super-agents each of which has their own cognitive boundary of various
sizes. Images by Jeremy Guay of Peregrine Creative.
corresponding to the size and complexity of their possible
goal domain. However, genomes (or engineering design specs)
map to an ensemble of such shapes in this space because the
borders between Self and world, and the scope of goals an
agent’s cognitive apparatus can handle, can all shift during the
lifetime of some agents—“in software” (another “great transition”
marker). All regions in this space can potentially deﬁne some
possible agent. Of course, additional subdivisions (dimensions)
can easily be added, such as the Unlimited Associative Learning
marker (Birch et al., 2020) or aspects of Active Inference (Friston
and Ao, 2012; Friston et al., 2015b; Calvo and Friston, 2017;
Peters et al., 2017).
Some
agents,
like
microbes,
have
minimal
memory
(Vladimirov and Sourjik, 2009; Lan and Tu, 2016) and can
concern themselves only with a very short time horizon
and spatial radius—e.g., follow local gradients. Some agents,
e.g., a rat have more memory and some forward planning
ability (Hadj-Chikh et al., 1996; Raby and Clayton, 2009;
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Smith and Litchﬁeld, 2010), but are still precluded from, for
example, eﬀectively caring about what will happen 2 months
hence, in an adjacent town. Some, like human beings, can devote
their lives to causes of enormous scale (future state of the planet,
humanity, etc.). Akin to Special Relativity, this formalization
makes explicit that class of capacities (in terms of representation
of classes of goals) that are forever inaccessible to a given agent
(demarcating the edge of the “light cone” of its cognition).
In general, larger selves (1) are capable of working toward
states of aﬀairs that occur farther into the future (perhaps
outlasting the lifetime of the agent itself—an important great
transition, in the sense of West et al. (2015), along the cognitive
continuum); (2) deploy memories further back in time (their
actions become less “mechanism” and more decision-making
(Balazsi et al., 2011) because they are linked to a network of
functional causes and information with larger diameter); and (3)
they expend eﬀort to manage sensing/eﬀector activity in larger
spaces [from subcellular networks to the extended mind (Clark
and Chalmers, 1998; Turner, 2000; Timsit and Gregoire, 2021)].
Overall, increases of agency are driven by mechanisms that scale
up stress (Box 1)—the scope of states that an agent can possibly
be stressed about (in the sense of pressure to take corrective
action). In this framework, stress (as a system-level response to
distance from setpoint states), preferences, motivation, and the
ability to functionally care about what happens are tightly linked.
Homeostasis, necessary for life, evolves into allostasis (McEwen,
1998; Schulkin and Sterling, 2019) as new architectures allow
tight, local homeostatic loops to be scaled up to measure, cause,
and remember larger and more complex states of aﬀairs (Di
Paulo, 2000; Camley, 2018).
Additional implications of this view are that Selves: are
malleable (the borders and scale of any Self can change over
time); can be created by design or by evolution; and are
multi-scale entities that consist of other, smaller Selves (and
conversely, scale up to make larger Selves). Indeed they are a
patchwork of agents [akin to Theophile Bordeu’s “many little
lives” (Haigh, 1976; Wolfe, 2008)] that overlap with each other,
and compete, communicate, and cooperate both horizontally
(at their own level of organization) and vertically [with their
component subunits and the super-Selves of which they are a part
(Sims, 2020)].
Another
important
invariant
for
comparing
diverse
intelligences is that they are all solving problems, in some
space (Figure 5). It is proposed that the traditional problemsolving behavior we see in standard animals in 3D space is
just a variant of evolutionarily more ancient capacity to solve
problems
in
metabolic,
physiological,
transcriptional,
and
morphogenetic spaces (as one possible sequential timeline
along which evolution pivoted some of the same strategies to
solve problems in new spaces). For example, when planaria are
exposed to barium, a non-speciﬁc potassium channel blocker,
their heads explode. Remarkably, they soon regenerate heads
that are completely insensitive to barium (Emmons-Bell et al.,
2019). Transcriptomic analysis revealed that relatively few
genes out of the entire genome were regulated to enable the
cells to resolve this physiological stressor using transcriptional
eﬀectors to change how ions and neurotransmitters are handled
by the cells. Barium is not something planaria ever encounter
ecologically (so there should not be innate evolved responses to
barium exposure), and cells don’t turn over fast enough for a
selection process (e.g., with bacterial persisters after antibiotic
exposure). The task of determining which genes, out of the
entire genome, can be transcriptionally regulated to return
to an appropriate physiological regime is an example of an
unconventional intelligence navigating a large-dimensional
space to solve problems in real-time (Voskoboynik et al., 2007;
Elgart et al., 2015; Soen et al., 2015; Schreier et al., 2017). Also
interesting is that the actions taken in transcriptional space (a
set of mRNA states) map onto a path in physiological state (the
ability to perform many needed functions despite abrogated K+
channel activity, not just a single state).
The common feature in all such instances is that the agent
must navigate its space(s), preferentially occupying adaptive
regions despite perturbations from the outside world (and from
internal events) that tend to pull it into novel regions. Agents
(and their sub- and super-agents) construct internal models of
BOX 1 | Stress as the glue of agency.
Tell me what you are stressed about and I will know a lot about your cognitive sophistication. Local glucose concentration? Limb too short? Rival is encroaching on
your territory? Your limited lifespan? Global disparities in quality of life on Earth? The scope of states that an agent can possibly be stressed by, in effect, deﬁnes their
degree of cognitive capacity. Stress is a systemic response to a difference between current state and a desired setpoint; it is an essential component to scaling of
Selves because it enables different modules (which sense and act on things at different scales and in distributed locations) to be bound together in one global
homeostatic loop (toward a larger purpose). Systemic stress occurs when one sub-agent is not satisﬁed about its local conditions, and propagates its unhappiness
outward as hard-to-ignore signals. In this process, stress pathways serve the same function as hidden layers in a network, enabling the system to be more adaptive
by connecting diverse modular inputs and outputs to the same basic stress minimization loop. Such networks scale stress, but stress is also what helps the network
scale up its agency—a bidirectional positive feedback loop.
The key is that this stress signal is unpleasant to the other sub-agents, closely mimicking their own stress machinery (genetic conservation: my internal stress
molecule is the same as your stress molecule, which contributes to the same “wiping of ownership” that is implemented by gap junctional connections). By
propagating unhappiness in this way (in effect, turning up the global system “energy” which facilitates tendency for moving in various spaces), this process recruits
distant sub-agents to act, to reduce their own perception of stress. For example, if an organ primordium is in the wrong location and needs to move, the surrounding
cells are more willing to get out of the way if by doing so they reduce the amount of stress signal they receive. It may be a process akin to run-and-tumble for
bacteria, with stress as the indicator of when to move and when to stop moving, in physiological, transcriptional, or morphogenetic space. Another example is
compensatory hypertrophy, in which damage in one organ induces other cells to take up its workload, growing or taking on new functions if need be (Tamori and
Deng, 2014; Fontes et al., 2020). In this way, stress causes other agents to work toward the same goal, serving as an inﬂuence that binds subunits across space
into a coherent higher Self and resists the “struggle of the parts” (Heams, 2012). Interestingly, stress spreads not only horizontally in space (across cell ﬁelds) but also
vertically, in time: effects of stress response is one of the things most easily transferred by transgenerational inheritance (Xue and Acar, 2018).
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 5 | Cognitive agents solve problems in diverse spaces. Intelligence is fundamentally about problem-solving, but this takes place not only in familiar 3D
space as “behavior” (control of muscle effectors for movement) (A), but also in other spaces in which cognitive systems try to navigate, in order to reach better
regions. This includes the transcriptional space of gene expression (B) here schematized for two genes, anatomical morphospace (C) here schematized for two
traits, and physiological space (D) here schematized for two parameters. An example (E) of problem-solving is planaria, which placed in barium (causing their heads
to explode due to general blockade of potassium channels) regenerate new heads that are barium-insensitive (Emmons-Bell et al., 2019). They solve this entirely
novel (not primed by evolutionary experience with barium) stressor by a very efﬁcient traversal in transcriptional space to rapidly up/down regulate a very small
number of genes that allows them to conduct their physiology despite the essential K+ ﬂux blockade. (F) The degree of intelligence of a system can be estimated by
how effectively they navigate to optimal regions without being caught in a local maximum, illustrated as a dog which could achieve its goal on the other side of the
fence, but this would require going around—temporarily getting further from its goal (a measurable degree of patience or foresight of any system in navigating its
space, which can be visualized as a sort of energy barrier in the space, inset). Images by Jeremy Guay of Peregrine Creative.
their spaces (Beer, 2014, 2015; Beer and Williams, 2015; Hoﬀman
et al., 2015; Fields et al., 2017; Hoﬀman, 2017; Prentner, 2019;
Dietrich et al., 2020; Prakash et al., 2020), which may or may
not match the view of their action space developed by their
conspeciﬁcs, parasites, and scientists. Thus, the space one is
navigating is in an important sense virtual (belonging to some
Agent’s self-model), is developed and often modiﬁed “on the ﬂy”
(in addition to that hardwired by the structure of the agent), and
not only faces outward to infer a useful structure of its option
space but also faces inward to map its own body and somatotopic
properties (Bongard et al., 2006). The lower-level subsystems
simplify the search space for the higher-level agent because their
modular competency means that the higher-level system doesn’t
need to manage all the microstates [a strong kind of hierarchical
modularity (Zhao et al., 2006; Lowell and Pollack, 2016)]. In turn,
the higher-level system deforms the option space for the lowerlevel systems so that they do not need to be as clever, and can
simply follow local energy gradients.
The degree of intelligence, or sophistication, of an agent in
any space is roughly proportional to its ability to deploy memory
and prediction (information processing) in order to avoid local
maxima. Intelligence involves being able to temporarily move
away from a simple vector toward one’s goals in a way that
results in bigger improvements down the line; the agent’s internal
complexity has to facilitate some degree of complexity (akin to
hidden layers in an artiﬁcial neural network which introduce
plasticity between stimulus and response) in the goal-directed
activity that enables the buﬀering needed for patience and
indirect paths to the goal. This buﬀering enables the ﬂip side of
homeostatic problem-driven (stress reduction) behavior by cells:
the exploration of the space for novel opportunities (creativity) by
the collective agent, and the ability to acquire more complex goals
[in eﬀect, beginning the climb to Maslow’s hierarchy (Taormina
and Gao, 2013)]. Of course it must be pointed out that this way
of conceiving intelligence is one of many, and is proposed here
as a way to enable the concept to be experimentally ported over
to unfamiliar substrates, while capturing what is essential about it
in a way that does not depend on arbitrary restrictions that will
surely not survive advances in synthetic bioengineering, machine
learning, and exobiology.
Another important aspect of intelligence that is space-agnostic
is the capacity for generalization. For example, in the barium
planaria example discussed above, it is possible that part of the
problem-solving capacity is due to the cells’ ability to generalize in
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
physiological space. Perhaps the cells recognize the physiological
stresses induced by the novel barium stimulus as a member of the
wider class of excitotoxicity induced by evolutionarily-familiar
epileptic triggers, enabling them to deploy similar solutions
(in terms of actions in transcriptional space). Such abilities to
generalize have now been linked to measurement invariance
(Frank, 2018), showing its ancient roots in the continuum of
cognition.
Consistent with the above discussion, complex agents often
consist of components that are themselves competent problemsolvers in their own (usually smaller, local) spaces. The
relationship between wholes and their parts can be as follows.
An agent is an integrated holobiont to the extent that it distorts
the option space, and the geodesics through it, for its subunits
(perhaps akin to how matter and space aﬀect each other in general
relativity) to get closer to a high-level goal in its space. A similar
scheme is seen in neuroscience, where top-down feedback helps
lower layer neurons to choose a response to local features by
informing them about more global features (Krotov, 2021).
At the level of the subunits, which know nothing of the higher
problem space, this simply looks like they are minimizing free
energy and passively doing the only thing they can do as physical
systems: this is why if one zooms in far enough on any act of
decision-making, all one ever sees is dumb mechanism and “just
physics.” The agential perspective (Godfrey-Smith, 2009) looks
diﬀerent at diﬀerent scales of observation (and its degree is in the
eye of a beholder who seeks to control and predict the system,
which includes the Agent itself, and its various partitions). This
view is closely aligned with that of “upper directedness” (McShea,
2012), in which the larger system directs its components’ behavior
by constraints and rewards for coarse-grained outcomes, not
microstates (McShea, 2012).
Note that these diﬀerent competing and cooperating partitions
are not just diverse components of the body (cells, microbiome,
etc.) but also future and past versions of the Self. For example,
one way to achieve the goal of a healthier metabolism is to lock
the refrigerator at night and put the keys somewhere that your
midnight self, which has a shorter cognitive boundary (is willing
to trade long-term health for satiety right now) and less patience,
is too lazy to ﬁnd. Changing the option space, energy barriers,
and reward gradients for your future self is a useful strategy for
reaching complex goals despite the shorter horizons of the other
intelligences that constitute your aﬀordances in action space.
The
most
eﬀective
collective
intelligences
operate
by
simultaneously distorting the space to make it easy for their
subunits to do the right thing with no comprehension of the
larger-scale goals, but themselves beneﬁt from the competency
of the subunits which can often get their local job done even
if the space is not perfectly shaped (because they themselves
are homeostatic agents in their own space). Thus, instances of
communication and control between agents (at the same or
diﬀerent levels) are mappings between diﬀerent spaces. This
suggests that both evolution’s, and engineers’, hard work is to
optimize the appropriate functional mapping toward robustness
and adaptive function.
Next, we consider a practical example of the application of
this framework to an unconventional example of cognition and
ﬂexible problem-solving: morphogenesis, which naturally leads
to speciﬁc hypotheses of the origin of larger biological Selves
(scaling) and its testable empirical (biomedical) predictions
(Dukas, 1998). This is followed with an exploration of the
implications of these concepts for evolution, and a few remarks
on consciousness.
SOMATIC COGNITION: AN EXAMPLE OF
UNCONVENTIONAL AGENCY IN DETAIL
“Again and again terms have been used which point not to
physical but to psychical analogies. It was meant to be more than
a poetical metaphor. . .”
– Spemann (1967)
An example of TAME applied to basal cognition in an
unconventional substrate is that of morphogenesis, in which
the mechanisms of cognitive binding between subunits are now
partially known, and testable hypotheses about cognitive scaling
can be formulated [explored in detail in Friston et al. (2015a)
and Pezzulo and Levin (2015, 2016)]. It is uncontroversial that
morphogenesis is the result of collective activity: individual cells
work together to build very complex structures. Most modern
biologists treat it as clockwork [with a few notable exceptions
around the recent data on cell learning (di Primio et al., 2000;
Brugger et al., 2002; Norman et al., 2013; Yang et al., 2014;
Stockwell et al., 2015; Urrios et al., 2016; Tweedy and Insall, 2020;
Tweedy et al., 2020)], preferring a purely feed-forward approach
founded on the idea of complexity science and emergence.
On this view, there is a privileged level of causation—that of
biochemistry—and all of the outcomes are to be seen as the
emergent consequences of highly parallel execution of local
rules (a cellular automaton in every sense of the term). Of
course, it should be noted that the forefathers of developmental
biology, such as Spemann (1967), were already well-aware of the
possible role of cognitive concepts in this arena and others have
occasionally pointed out detailed homologies (Grossberg, 1978;
Pezzulo and Levin, 2015). This becomes clearer when we step
away from the typical examples seen in developmental biology
textbooks and look at some phenomena that, despite the recent
progress in molecular genetics, remain important knowledge
gaps (Figure 6).
Goal-Directed Activity in Morphogenesis
Morphogenesis (broadly deﬁned) is not only a process that
produces the same robust outcome from the same starting
condition (development from a fertilized egg). In animals such
as salamanders, cells will also re-build complex structures such as
limbs, no matter where along the limb axis they are amputated,
and stop when it is complete. While this regenerative capacity
is not limitless, the basic observation is that the cells cooperate
toward a speciﬁc, invariant endstate (the target morphology),
from diverse starting conditions, and cease their activity when the
correct pattern has been achieved. Thus, the cells do not merely
perform a rote set of steps toward an emergent outcome, but
modify their activity in a context-dependent manner to achieve
a speciﬁc anatomical target morphology. In this, morphogenetic
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 6 | Morphogenesis as an example of collective intelligence and plasticity. The results of complex morphogenesis are the behavior in morphospace of a
collective intelligence of cells. It is essential to understand this collective intelligence because by themselves, progress in molecular genetics is insufﬁcient. For
example, despite genomic information and much pathway data on the behavior of stem cells in planarian regeneration, there are no models predicting what happens
when cells from a ﬂat-headed species are injected into a round-headed species (A): what kind of head will they make, and will regeneration/remodeling ever stop,
since the target morphology can never match what either set of cells expects? Development has the ability to overcome unpredictable perturbations to reach its
goals in morphospace: tadpoles made with scrambled positions of craniofacial organs can make normal frogs (B) because the tissues will move from their abnormal
starting positions in novel ways until a correct frog face is achieved (Vandenberg et al., 2012). This illustrates that the genetics seeds the development of hardware
executing not an invariant set of movements but rather an error minimization (homeostatic) loop with reference to a stored anatomical setpoint (target morphology).
The paths through morphospace are not unique, illustrated by the fact that when frog legs are induced to regenerate (C), the intermediate stages are not like the
developmental path of limb development (forming a paddle and using programmed cell death to separate the digits) but rather like a plant (C′), in which a central
core gives rise to digits growing as offshoots (green arrowheads) which nevertheless ends up being a very normal-looking frog leg (Tseng and Levin, 2013). (D) The
plasticity extends across levels: when newt cells are made very large by induced polyploidy, they not only adjust the number of cells that work together to build
kidney tubules with correct lumen diameter, but can call up a completely different molecular mechanism (cytoskeletal bending instead of cell:cell communication) to
make a tubule consisting in cross-section of just 1 cell wrapped around itself; this illustrates intelligence of the collective, as it creatively deploys diverse lower-level
modules to solve novel problems. The plasticity is not only structural but functional: when tadpoles are created to (E) have eyes on their tails (instead of in their
heads), the animals can see very well (Blackiston and Levin, 2013), as revealed by their performance in visual learning paradigms (F). Such eyes are also competent
modules: they ﬁrst form correctly despite their aberrant neighbors (muscle, instead of brain), then put out optic nerves which they connect to the nearby spinal cord,
and later they ignore the programmed cell death of the tail, riding it backward to end up on the posterior of the frog (G). All of this reveals the remarkable multi-scale
competency of the system which can adapt to novel conﬁgurations on the ﬂy, not requiring evolutionary timescales for adaptive functionality (and providing important
buffering for mutations that make changes whose disruptive consequences are hidden from selection by the ability of modules to get their job done despite changes
in their environment). Panels (A,C’,D) are courtesy of Peregrine Creative. Panel (C) is from Xenbase and Aisun Tseng. Panels (E–G) are courtesy of Douglas
Blackiston. Panel (B) is used with permission from Vandenberg et al. (2012), and courtesy of Erin Switzer.
systems meet James’ test for minimal mentality: “ﬁxed ends with
varying means” (James, 1890).
For example, tadpoles turn into frogs by rearranging their
craniofacial structures: the eyes, nostrils, and jaws move as
needed to turn a tadpole face into a frog face (Figure 6B).
Guided by the hypothesis that this was not a hardwired but
an intelligent process that could reach its goal despite novel
challenges, we made tadpoles in which these organs were in
the wrong positions—so-called Picasso Tadpoles (Vandenberg
et al., 2012). Amazingly, they tend to turn into largely normal
frogs because the craniofacial organs move in novel, abnormal
paths [sometimes overshooting and needing to return a bit
(Pinet et al., 2019)] and stop when they get to the correct frog
face positions. Similarly, frog legs that are artiﬁcially induced to
regenerate create a correct ﬁnal form but not via the normal
developmental steps (Tseng and Levin, 2013). Students who
encounter such phenomena and have not yet been inoculated
with the belief that molecular biology is a privileged level of
explanation (Noble, 2012) ask the obvious (and proper) question:
how does it know what a correct face or leg shape is?
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Examples
of
remodeling,
regulative
development
(e.g.,
embryos that can be cut in half and produce normal monozygotic
twins), and regeneration, ideally illustrate the goal-directed
nature of cellular collectives. They pursue speciﬁc anatomical
states that are much larger than any individual cells and solve
problems in morphospace in a context-sensitive manner—any
swarm of miniature robots that could do this would be called a
triumph of collective intelligence in the engineering ﬁeld. Guided
by the TAME framework, two questions come within reach.
First, how does the collective measure current state and store
the information about the correct target morphology? Second, if
morphogenesis is not at the clockwork level on the continuum
of persuadability but perhaps at that of the thermostat, could it
be possible to re-write the setpoint without rewiring the machine
(i.e., in the context of a wild-type genome)?
Pattern Memory: A Key Component of
Homeostatic Loops
Deer farmers have long known of trophic memory: wounds made
on a branched antler structure in 1 year, will result in ectopic tines
growing at that same location in subsequent years, long after the
original rack of antlers has fallen oﬀ(Bubenik and Pavlansky,
1965; Bubenik, 1966; Lobo et al., 2014). This process requires
cells at the growth plate in the scalp to sense, and remember
for months, the location of a transient damage event within a
stereotypical branched structure, and reproduce it in subsequent
years by over-riding the wild-type stereotypical growth patterns
of cells, instead guiding them to a novel outcome. This is an
example of experience-dependent, re-writable pattern memory,
in which the target morphology (the setpoint for anatomical
homeostasis) is re-written within standard hardware.
Planarian ﬂatworms can be cut into multiple pieces, and
each fragment regenerates precisely what is missing at each
location (and re-scales the remaining tissue as needed) to make a
perfect little worm (Cebrià et al., 2018). Some species of planaria
have an incredibly messy genome—they are mixoploid due to
their method of reproduction: ﬁssion and regeneration, which
propagates any mutations that don’t kill the stem cell and expands
it throughout the lineage [reviewed in Fields et al. (2020)].
Despite the divergence of genomic information, the worms are
champion regenerators, with near 100% ﬁdelity of anatomical
structure. Recent data have identiﬁed one set of mechanisms
mediating the ability of the cells to make, for example, the correct
number of heads: a standing bioelectrical distribution across the
tissue, generated by ion channels and propagated by electrical
synapses known as gap junctions (Figures 7A–D). Manipulation
of the normal voltage pattern by targeting the gap junctions
(Sordillo and Bargmann, 2021) or ion channels can give rise to
planaria with one, two, or 0 heads, or heads with shape (and brain
shape) resembling other extant species of planaria (EmmonsBell et al., 2015; Sullivan et al., 2016). Remarkably, the worms
with abnormal head number are permanently altered to this
pattern, despite their wild-type genetics: cut into pieces with no
further manipulations, the pieces continue to regenerate with
abnormal head number (Oviedo et al., 2010; Durant et al., 2017).
Thus, much like the optogenetic techniques used to incept false
behavioral memories into brains (Vetere et al., 2019), modulation
of transient bioelectric state is a conserved mechanism by which
false pattern memories can be re-written into the geneticallyspeciﬁed electrical circuits of a living animal.
Multi-Scale Competency of Growth and
Form
A key feature of morphogenesis is that diverse underlying
molecular mechanisms can be deployed to reach the same largescale goal. This plasticity and coarse-graining over subunits’ states
is a hallmark of collective cognition, and is also well known
in neuroscience (Prinz et al., 2004; Otopalik et al., 2017). Newt
kidney tubules normally have a lumen of a speciﬁc size and are
made up (in cross section) of 8–10 cells (Fankhauser, 1945a,b).
When the cell size is experimentally enlarged, the same tubules
are made of a smaller number of the bigger cells. Even more
remarkable than the scaling of the cell number to unexpected
size changes (on an ontogenetic, not evolutionary, timescale)
is the fact that if the cells are made really huge, just one cell
wraps around itself and still makes a proper lumen (Figure 6D).
Instead of the typical cell-cell interactions that coordinate tubule
formation, cytoskeletal deformations within one cell can be
deployed to achieve the same end result. As in the brain, the
levels of organization exhibit signiﬁcant autonomy in the details
of their molecular activity but are harnessed toward an invariant
system-level outcome.
Speciﬁc Parallels Between
Morphogenesis and Basal Cognition
The plasticity of morphogenesis is signiﬁcantly isomorphic to
that of brains and behavior because the communication dynamics
that scale individual neural cells into a coherent Self are ones
that evolution honed long before brains appeared, in the context
of morphogenic control (Fields et al., 2020), and before that, in
metabolic control in bacterial bioﬁlms (Prindle et al., 2015; Liu
et al., 2017; Martinez-Corral et al., 2019; Yang et al., 2020). Each
genome speciﬁes cellular hardware that implements signaling
circuits with a robust, reliable default “inborn” morphology—
just as genomes give rise to brain circuits that drive instinctual
behavior in species that can build nests and do other complex
things with no training. However, evolution selected for hardware
that can be reprogrammed by experiences, in addition to its
robust default functional modes—in body structure, as well as
in brain-driven behavior. Many of the brain’s special features are
to be found, unsurprisingly, in other forms outside the central
nervous system. For example, mirror neurons and somatotopic
representation are seen in limbs’ response to injury, where the
type and site of damage to one limb can be read out within 30 s
from imaging the opposite, un-injured limbs (Busse et al., 2018).
Table 2 shows the many parallels between morphogenetic and
cognitive systems.
Not Just Philosophy: Why These
Parallels Matter
The view of anatomical homeostasis as a collective intelligence
is not a neutral philosophical viewpoint—it makes strong
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 7 | Bioelectrical pattern memories. Planarian fragments reliably regenerate whatever is missing, and stop when a correct worm is complete. Normal planaria
(A) have 1 head and 1 tail (A-1), expression of anterior genes in the head (A-2), and a standing pattern of resting potential that depolarized on the end that should
make a head [(A-3), revealed by voltage-reporting ﬂuorescent dye, depolarized region marked with orange arrowhead]. When a middle portion is amputated, it
regenerates to a correct 1-headed worm (A-4). It is possible to edit the information structure which encodes the target morphology (shape to which the fragments
will regenerate). In worms that are anatomically normal (A′-1), with normal gene expression (A′-2), their bioelectric pattern can be altered in place [(A′-3), orange
arrowheads mark the two depolarized ends] using ion channel-targeting drugs or RNAi. The result, after injury, will be a fully viable 2-headed worm (A′-4).
Importantly, the pattern shown in panel (A′-3) is not a voltage map of the ﬁnal 2-headed worm: it’s a map of a 1-headed animal before cutting, which already has the
induced false memory indicating that a correct worm should have 2 heads. In other words, the bioelectrics can diverge from the current state—it is not simply a
readout of what the anatomy is doing now, but an orthogonal information medium that is used to guide future changes of anatomy. This information is latent, only
guiding the cellular collective’s anatomical homeostasis activity after injury. Thus it is also a basal example of counterfactual representation, referring to what should
happen if an injury occurs, not what is happening now. Such changes to the bioelectric target morphology are true memories because they are re-writable but also
long-term stable: if cut again, in water with no more channel-perturbing reagents, multiple rounds of regeneration of a genetically wild-type worm continue to give
rise to 2-headed forms (B), which can be re-set back to normal by a different bioelectric perturbation (Oviedo et al., 2010). The control of morphology by bioelectric
patterns is mediated as in the brain (C) by cells which have ion channels that set resting potential across the membrane (Vmem) and propagate those states in
computational networks to their neighbors, via electrical synapses known as gap junctions. All cells, not just neurons (D) do this, and bioelectric signaling is an
ancient information processing modality that pre-dates neurons and brains (Fields et al., 2020; Levin, 2021a). The ability of voltage states to functionally specify
modular anatomy is seen when an ion channel is used to set membrane voltage in endodermal cells fated to be gut, to an eye-like bioelectric prepattern (E), which
then create an eye on the gut (red arrowhead) (Pai et al., 2012). This phenomenon has 2 levels of instruction (F): in addition to our use of voltage to instruct shape at
the organ level (not micromanaging individual eye components), the ion channel mRNA-injected cells (cyan β-galactose marker) further instruct their neighbors
(brown cells) to participate in forming this ectopic lens. Images in panels (C,D) are courtesy of Peregrine Creative. Images in panels (A,A′) are taken with permission
from Durant et al. (2017). Embryo image in panel (E) is from Xenbase. Panel (F) is used with permission from Zahn et al. (2017).
predictions, some of which have already borne fruit. It led
to the discovery of reprogrammable head number in planaria
(Nogi and Levin, 2005) and of pre-neural roles for serotonin
(Fukumoto et al., 2005a,b). It explains the teratogenicity
for pre-neural exposure to ion channel or neurotransmitter
drugs (Hernandez-Diaz and Levin, 2014), the patterning
defects observed in human channelopathies in addition to the
neurological phenotypes [reviewed in Srivastava et al. (2020)],
and the utility of gap junction blockers as general anesthetics.
Prediction derived from the conservation and scaling
hypotheses
of
TAME
can
be
tested
via
bioinformatics.
Signiﬁcant
and
speciﬁc
overlap
are
predicted
for
genes
involved
in
morphogenesis
and
cognition
(categories
of
memory
and
learning).
This
is
already
known
for
ion
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
TABLE 2 | isomorphism between cognition and pattern formation.
Cognitive concept
Morphogenetic concept
Patterns of activation across neural networks processing
information
Differential patterns of Vmem across tissue formed by propagation of bioelectric states through
gap junction synapses.
Local ﬁeld potential (EEG)
Vmem distribution of cell group
Intrinsic plasticity
Change of ion channel expression based on Vmem levels
Synaptic plasticity
Change of cell:cell connectivity via Vmem’s regulation of gap junctional connectivity
Activity-dependent transcriptional changes
Bioelectric signals’ regulating gene expression during patterning
Neuromodulation, and neurotransmitters controlled by electrical
dynamics to regulate genes in neurons
Developmental (pre-nervous) signaling via the same neurotransmitters (e.g., serotonin) moving
under control of bioelectrical gradients to regulate second messenger pathways and gene
expression.
Direct transmission
Cell:cell sharing of voltage via nanotubes or gap junctions
Volume transmission
Cell:cell communication via ion levels outside the membrane or voltage-dependent
neurotransmitter release
Synaptic Vesicles
Exosomes
Sensitization
Cells become sensitized stimuli, such as for example to BMP antagonists during development
Functional lateralization
Left-right asymmetry of body organs
Taste and olfactory perception
Morphogenetic signaling by diffusible biochemical ligands
Activity-dependent modiﬁcation of CNS
Control of anatomy by bioelectric signaling within those same cells
Critical plasticity periods
Competency windows for developmental induction events
Inborn behaviors (instincts)
Emergent morphogenetic cascades as “default” outcomes of a genetically-speciﬁed bioelectric
hardware—hardwired patterning programs (mosaic development
Voluntary movement
Remodeling, regeneration, metamorphosis
Memory
Short range: epigenetic cell memory
Medium range: Regeneration of speciﬁc body organs. Long range: Morphological homeostasis
over decades as individual cells senesce; altering basic body anatomy in planaria by direct
manipulation of bioelectric circuit
Counterfactual memories
Ability of 1-headed planarian bodies to store bioelectric patterns indicative of 1-headed or
2-headed forms, which are latent memories that become instructive upon damage to the
organism.
Perceptual Bistability
Cryptic Planaria, induced by gap-junctional disruption, fragments of which stochastically
regenerate as 1-headed or 2-headed forms, shifting between two different bioelectrical
representations of a target morphology (pattern memory).
Edge detection in retina
Sharp boundaries between regions of different Vmem induce downstream gene expression and
morphogenetic outcomes
Pattern completion ability of neural networks (e.g., attractor nets)
Regeneration of missing parts in partial fragments (e.g., planaria, salamander appendages, etc.)
Forgetting
Degradation of target morphology setpoint information leading to cancer and loss of
regenerative ability
Addiction
Dependency on cellular signals, such as nerve addiction in limb regeneration and cancer
addiction to speciﬁc molecules.
Encoding
Representation of patterning goal states by bioelectric properties of tissue
Visual system feature detection
Organ-level monitoring of body conﬁguration and detection of speciﬁc boundaries by tissue
(such as the Vmem boundary that drives brain morphogenesis)
Holographic (distributed) storage
Any small piece of a planarian remembers the correct pattern (even if it has been re-written)
Behavioral plasticity
Regulative developmental programs and regenerative capacity
Self-modeling
Representations of current and future morphogenetic states by bioelectric patterns such as the
planarian prepattern or the bioelectric face pattern in vertebrates
Goal-seeking
Embryogenesis and regeneration work toward a speciﬁc target conﬁguration despite
perturbations
Adaptivity and Intelligence
Morphological rearrangements carry out novel, not hardwired, movements to reach the same
anatomical conﬁguration despite unpredictable initial starting state
Age-dependent cognitive decline
Age-dependent loss of regenerative ability
Top-down control
Place conditioning for drug effects—top-down control of signaling pathways
Possible mapping of concepts in cognitive neuroscience to examples in pattern formation.
channels, connexin (gap junction) genes, and neurotransmitter
machinery, but TAME predicts a widespread re-use of the
same
molecular
machinery.
Cell-cell
communication
and
cellular
stress
pathways
should
be
involved
in
internal
conﬂict between psychological modules (Reinders et al., 2019)
and
social
behavior,
while
memory
genes
should
be
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
identiﬁed in genetic investigations of cancer, regeneration,
and embryogenesis.
Another key prediction that remains to be tested (ongoing
in our lab) is trainability of morphogenesis. The collective
intelligence of tissues could be sophisticated enough to be
trainable via reinforcement learning for speciﬁc morphological
outcomes. Learning has been suggested by clinical data in
the heart (Zoghi, 2004), bone (Turner et al., 2002; Spencer
and Genever, 2003), and pancreas (Goel and Mehta, 2013).
It is predicted that using rewards and punishments (with
nutrients/endorphins and shock), not micromanagement of
pathway hardware, could be a path to anatomical control in
clinical settings, whether for morphology or for gene expression
(Biswas et al., 2021). This would have massive implications for
regenerative medicine, because the complexity barrier prevents
advances such as genomic editing from impacting e.g., limb
regeneration in the foreseeable future. The same reasons for
which we would train a rat for a speciﬁc behavior, rather than
control all of the relevant neurons to force it to do it like a puppet,
explain why the direct control of molecular hardware is a far more
diﬃcult biomedical path than understanding the sets of stimuli
that could motivate tissues to build a speciﬁc desired structure.
The key lesson of computer science has been that even with
hardware we understand (if we built it ourselves), it is much more
eﬃcient and powerful to understand the software and evince
desired outcomes by the appropriate stimulation and signaling,
not physical rewiring. If the hardware is reprogrammable (and
it is here argued that much of the biological hardware meets
this transition), one can oﬄoad much of the complexity onto
the system itself, taking advantage of whatever competence the
sub-modules have. Indeed, neuroscience itself may beneﬁt from
cracking a simpler version of the problem, in the sense of neural
decoding, done ﬁrst in non-neural tissues.
Non-neural Bioelectricity: What Bodies
Think About
The hardware of the brain consists of ion channels which set
the cells’ electrical state, and controllable synapses (e.g., gap
junctions) which can propagate those states across the network.
This machinery, including the neurotransmitters that eventually
transduce these computations into transcriptional and other cell
behaviors, is in fact highly conserved and present in all cells,
from the time of fertilization (Figures 7C,D). A major diﬀerence
between neural and non-neural bioelectricity is the time constant
with which it acts [brains speed up the system into millisecond
scales, while developmental voltage changes occur in minutes or
hours (Harris, 2021; Levin, 2021a)]. Key aspects of this system
in any tissue that enable it to support ﬂexible software include
the fact that both ion channels and gap junctions are themselves
voltage sensitive—in eﬀect, they are transistors (voltage-gated
current conductances). This enables evolution to exploit the
laws of physics to rapidly generate very complex circuits with
positive (memory) and negative (robustness) feedback (Law and
Levin, 2015; Cervera et al., 2018, 2019a,b, 2020a). The fact that
a transient voltage state passing through a cell can set oﬀa
cycle of progressive depolarization (like an action potential) or
gap junctional (GJ) closure means that such circuits readily
form dynamical systems memories which can store diﬀerent
information and change their computational behavior without
changing the hardware (i.e., not requiring new channels or gap
junctions) (Pietak and Levin, 2017); this is obvious in the action
potential propagations in neural networks but is rarely thought
about in development. It should be noted that there are many
additional biophysical modalities, such as parahormones, volume
conduction, biomechanics (strain and other forces), cytoskeletal
dynamics, and perhaps even quantum coherence events that
could likewise play interesting roles. These are not discussed here
only due to length limitations; instead, we are focusing on the
bioelectric mechanisms as one particularly illustrative example of
how evolution exploits physics for computation and cognition.
Consistent with its proposed role, slowly-changing resting
potentials serve as instructive patterns guiding embryogenesis,
regeneration, and cancer suppression (Bates, 2015; Levin et al.,
2017; McLaughlin and Levin, 2018). In addition to the pattern
memories encoded electrically in planaria (discussed above),
bioelectric prepatterns have also been shown to dictate the
morphogenesis of the face, limbs, and brain, and function
in determining primary body axes, size, and organ identity
[reviewed in Levin and Martyniuk (2018)]. One of the most
interesting aspects of developmental bioelectricity is its modular
nature: very simple voltage states trigger complex, downstream
patterning cascades. As in the brain, modularity goes handin-hand with pattern completion: the ability of such networks
to provide entire behaviors from partial inputs. For example,
Figure 7F shows how a few cells transduced with an ion channel
that sets them into a “make the eye here” trigger recruit their
neighbors, in any region of the body, to fulﬁll the purpose of
the subroutine call and create an eye. Such modularity makes
it very easy for evolution to develop novel patterns by reusing powerful triggers. Moreover, as do brains, tissues use
bioelectric circuits to implement pattern memories that set the
target morphology for anatomical homeostasis (as seen in the
planarian examples above). This reveals the non-neural material
substrate that stores the information in cellular collectives, which
is a distributed, dynamic, re-writable form of storage that parallels
recent discoveries of how group knowledge is stored in largerscale agents such as animal swarms (Thierry et al., 1995; Couzin
et al., 2002). Finally, bioelectric domains (Pai et al., 2017, 2018;
Pitcairn et al., 2017; McNamara et al., 2019, 2020) set the
borders for groups of cells that are going to complete a speciﬁc
morphogenetic outcome—a system-level process like “make an
eye.” They deﬁne the spatio-temporal borders of the modular
activity, and suggest a powerful model for how Selves scale in
general.
A Bioelectric Model of the Scaling of the
Self
Gap junctional connections between cells provide an interesting
case study for how the borders of the Self can expand or
contract, in the case of a morphogenetic collective intelligence
(Figure 8). Crucially, gap junctions [and gap junctions extended
by tunneling nanotubes (Wang et al., 2010; Ariazi et al., 2017)]
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 8 | Scaling of computation in cells. Individual cells (A) have a degree of computational capacity consisting of the ability to sense local microenvironment,
and some memory and ability to anticipate into the future. When assembling into networks (A′), tissues acquire the ability to sense and act at greater spatial
distance, as well as gain larger capacity for memory and prediction via greater computational capacity. As neural networks use hidden layers to abstract patterns in
data and recognize meso-scale features (B), tissue networks gain the capacity to represent information larger than the molecular and cell level: each cell’s activity
(differentiation, migration, etc.) can be the result of other layers of cells processing information about current and past states, enabling decision-making with respect
to tissue, organ, or whole organism-scale anatomy. (C) Much as some neural networks store individual memories as attractors in their state space, bioelectric
circuits’ attractors function as pattern memories, triggering cells to execute behaviors that implement anatomical outcomes like number and location of heads in
planaria. Images courtesy of Jeremy Guay of Peregrine Creative.
enable a kind of cellular parabiosis—a regulated fusion between
cells that enables lateral inheritance of physiological information,
which speeds up processing in the same way that lateral gene
inheritance potentiates change on evolutionary timescales. The
following is a case study hypothesizing one way in which
evolution solves the many-into-one problem (how competent
smaller Selves bind into an emergent higher Self), and how this
process can break down leading to a reversal (shrinking) of the
Self boundary (summarized in Table 3).
Single cells (e.g., the protozoan Lacrymaria olor) are
very competent in handling morphological, physiological, and
behavioral goals on the scale of one cell. When connected to each
other via gap junctions, as in metazoan embryos, several things
happen (much of which is familiar to neuroscientists and workers
in machine learning in terms of the beneﬁts of neural networks)
that lead to the creation of a Self with a new, larger cognitive
boundary. First, when cells join into an electrochemical network,
they can now sense events, and act, on a much larger physical
“radius of concern” than a single cell. Moreover, the network
can now integrate information coming from spatially disparate
regions in complex ways that result in activity in other spatial
regions. Second, the network has much more computational
power than any of its individual cells (nodes), providing an IQ
boost for the newly formed Self. In such networks, Hebbian
dynamics on the electrical synapse (GJ) can provide association
between action in one location and reward in another, which
enables the system to support credit assignment at the level of
the larger individual.
The third consequence of GJ connectivity is the partial
dissolution of informational boundaries between the subunits.
GJ-mediated signals are unique because they give each cell
immediate
access
to
the
internal
milieu
of
other
cells.
A conventional secreted biochemical signal arrives from the
outside, and when it triggers cell receptors on the surface, the
cell clearly knows that this information originated externally
(and can be attended to, ignored, etc.)—it is easy to maintain
boundary between Self and world. However, imagine a signal
like a calcium spike originating in a cell due to some damage
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
TABLE 3 | An example of the scaling of cognition.
• Each Self has a cognitive capacity deﬁned by the spatial, temporal, and
complexity metrics on the goals it can possibly pursue.
• Biological Selves scale up by cells’ joining into computational networks that
can pursue larger-scale (anatomical, not just metabolic) goals.
• Networks increase the spatial reach of sensing and actuation, and increase
the computational capacity which allows scaling up of goals and of the
states that can induce stress.
• Bodies consist of components which are themselves competent
(goal-seeking modules that navigate their own spaces) and can achieve
speciﬁc outcomes despite perturbations and changing conditions.
• Gap junctions are a unique scaling mechanism which, by linking cells’
internal milieus, wipes ownership information on signaling molecules. This
partially erases the informational identity of the cellular subunits, driving up
cooperation and resulting in novel tissue and organ-level Selves with
morphological-scale goals.
• Bioelectric networks underlie the computations of cell collectives at the
tissue, organ, and organism scale, propagating stress information, state
sensing, and morphogenetic instructive cues over larger areas.
• Selves can dissociate (scale down), as occurs in cancer, by shrinking the
computational boundaries of some subunits that de-couple from
the network.
stimulus for example. When that calcium propagates onto the
GJ-coupled neighbor, there are no metadata on that signal
marking its origin; the recipient cell only knows that a calcium
transient occurred, and cannot tell that this information does not
belong to it. The downstream eﬀects of this second messenger
event are a kind of false memory for the recipient cell, but a
true memory for the collective network of the stimulus that
occurred in one part of the individual. This wiping of ownership
information for GJ signals as they propagate through the network
is critical to enabling a partial “mind meld” between the cells:
keeping identity (in terms of distinct individual history of
physiological states—memory) becomes very diﬃcult, as small
informational molecules propagate and mix within the network.
Thus, this property of GJ coupling promotes the creation of a
larger Self by partially erasing the mnemic boundaries between
the parts which might impair their ability to work toward a
common goal. This is a key part of the scaling of the Self by
enlarging toward common goals—not by micromanagement, but
by bringing multiple subunits into the same goal-directed loop
by tightly coupling the sensing, memory, and action steps in
a syncytium where all activity is bound toward a system-level
teleonomic process. When individual identities are blurred in
favor of longer time-scale, larger computations in tissues, smallhorizon (myopic) action in individual cells (e.g., cancer cells’
temporary gains followed by maladaptive death of the host) leads
to a more adaptive longer-term future as a healthy organism.
In eﬀect, this builds up long-term collective rationality from the
action of short-sighted irrational agents (Sasaki and Biro, 2017;
Berdahl et al., 2018).
It is important to note that part of this story has already
been empirically tested in assays that reveal the shrinking as
well as the expansion of the Self boundary (Figure 9). One
implication of these hypotheses is that the binding process
can break down. Indeed this occurs in cancer, where oncogene
expression and carcinogen exposure leads to a closure of GJs
(Vine and Bertram, 2002; Leithe et al., 2006). The consequence of
this is transformation to cancer, where cells revert to their ancient
unicellular selves (Levin, 2021b)—shrinking their computational
boundaries and treating the rest of the body as external
environment. The cells migrate at will and proliferate as much
as they can, fulﬁlling their cell-level goals—metastasis [but also
sometimes attempting to, poorly, reboot their multicellularity
and make tumors (Egeblad et al., 2010)]. The model implies
that this phenotype can be reverted by artiﬁcially managing
the bioelectric connections between a cell and its neighbors.
Indeed, recent data show that managing this connectivity
can override default genetically-determined states, inducing
metastatic melanoma in a perfectly wild-type background
(Blackiston et al., 2011) or suppressing tumorigenesis induced
by strong oncogenes like p53 or KRAS mutations (Chernet
and Levin, 2013a,b). The focus on physiological connectivity
(information
dynamics)—the
software—is
consistent
with
the observed facts that genetic alterations (hardware) are
not necessary to either induce or revert cancer [reviewed in
Chernet and Levin (2013a)].
All these dynamics lead to a few interesting consequences. GJmediated communications are not merely conversations (in the
way that external signaling is)—they are binding, in the sense
that once a GJ is open, a cell is subject to whatever comes in
from the neighbor. In the same sense, having a synapse makes
one vulnerable to the state of neighbors. GJs spread (dilute)
the pain of depolarization, but at the same time give a cell’s
neighbors the power to change its state. Compatible with the
proposal that the magnitude of a Self is the scale and complexity
of states by which it can be stressed, connections by tunable,
dynamic GJs greatly expand the spatial, temporal, and complexity
of things that can irritate cells; complex events from far away can
now percolate into a cell via non-linear GJ paths through the
network, and enabling the drive to minimize such events now
necessarily involves homeostatic activity of goal states, sensing,
and activity on a much larger scale. Stress signals, propagating
through such networks, incentivize other regions of the tissue
to act cooperatively in response to distant events by harnessing
their selﬁsh drive to reduce their own stress. This facilitates the
coherent, system-level response to perturbations beyond their
local consequences, and gives rise to larger Selves able to react
coherently to stressful departures from more complex, spatiallydistributed allostatic setpoints. For example, whereas a solitary
cell might be stressed (and react to) abnormal local pH, cells that
are part of a transplanted salamander limb will be induced to a
more grandiose activity: they will change the number of ﬁngers
they produce to be correct relative to the limb’s new position in
the host’s body (Ruud, 1929), a decision that involves large-scale
sensing, decision-making, and control.
A fourth consequence of the coupling is that cooperation
in general is greatly enhanced. In the game theory sense,
it is impossible to cheat against your neighbor if you are
physiologically coupled. Any positive or negative eﬀects of
a cell’s actions toward the neighboring cell are immediately
propagated back to it, in eﬀect producing one individual in
which the parts cannot “defect” against each other. This dynamic
suggests an interesting twist on Prisoners’ Dilemma models
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 9 | Gap junctions and the cellular collective. Communication via diffusible and biomechanical signals can be sensed by receptors at the membrane as
messages coming from the outside of a cell (A). In contrast, cells coupled by gap junctions enable signals to pass directly from one cell’s internal milieu into another.
This forms a partial syncytium which helps erase informational boundaries between cells, as memory molecules (results of pathway dynamics) propagate across
such cell groups without metadata on which cell originated them. The versatile gating of GJ synapses allows the formation of multicellular Selves that own memories
of physiological past events at the tissue level (not just individual cells’) and support larger target patterns, enabling them to cooperate to make complex organs (B).
This process can break down: when oncogenes are expressed in tadpoles, voltage dye imaging (C) reveals the abnormal voltage state of cells that are disconnected
bioelectrically from their neighbors, reverting to an ancient unicellular state (metastasis) that treats the rest of the body as external environment and grows out of
control as tumors (D). This process can be prevented (Chernet and Levin, 2013a,b; Chernet et al., 2016) by artiﬁcially regulating their bioelectric state [e.g.,
co-injecting a hyperpolarizing channel with the oncogene, (E)]. In this case the tissue forms normally [(F), green arrow], despite the very strong presence of the
oncogene [(G), red label]. This illustrates the instructive capacity of bioelectric networks to dominate single cell and genetic states to control large-scale tissue
outcomes. Panels (A,A′,B) courtesy of Jeremy Guay of Peregrine Creative. Panels (C–D) are used with permission from Chernet and Levin (2013a). Panels (E–G)
used with permission from Chernet and Levin (2013b).
in which the number of agents is not ﬁxed, because they have
the options of Cooperate, Defect, Merge, and Split (we are
currently analyzing such models). Speciﬁcally, merging with
another agent creates an important dimensionality reduction
(because defection is no longer an option); this not only
changes the calculus of game theory as applied to biological
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
interactions, but also the action space itself. These dynamics
take place on a developmental timescale, complementing
the rich existing literature on game theory in evolution
(Maynard Smith and Szathmáry, 1995; Maynard Smith, 1999;
McEvoy, 2009; Pacheco et al., 2014).
Indeed, the smaller and larger agents’ traversal of their various
spaces provides a way to think about how smaller agents’ (celllevel) simple homeostatic loops can scale up into large, organlevel anatomical homeostatic loops. Prentner recently showed
how agents build up spatial models of their worlds by taking
actions that nullify changes in their experience (Prentner, 2019).
Working to nullify changes to one’s state that would otherwise
be induced by the vagaries of external environment (and other
agents) is the core of homeostasis—the action loops that seek to
preserve important states against intervention and entropy. This
is not only for physical movement (which results in a creature
perceiving itself to be situated in spacetime) but also for other
states in which actuation takes place via turning on/oﬀspeciﬁc
genes, remodeling an anatomy, or opening/closing ion channels
to change physiological state. An agent can notice patterns in
what actions it had to take to keep in homeostasis despite various
perturbations that occur, and based on that reﬁne an internal
model of some space within which it is acting. This is closely
related to the surprise minimization framework (Friston, 2013;
Friston et al., 2013; Friston
K. et al., 2014), and suggests a
straightforward sense in which larger Selves scale up to models
of their world and themselves from evolutionary primitives
such as metabolic homeostasis. Bioelectricity provides examples
where cell-level physiological homeostats form networks that
implement much larger-scale pattern memories as attractors,
akin to Hopﬁeld networks (Figure 10; Hopﬁeld, 1982; Inoue,
2008; Pietak and Levin, 2017; Cervera et al., 2018, 2019a,b,
2020a). This enables all tissues to participate in the kind of pattern
completion seen in neural networks—a critical capability for
regenerative and developmental repair (anatomical homeostasis).
With these pieces in place, it is now possible to mechanistically
visualize one speciﬁc aspect of the progressive scaling that
expands the cognitive light cone. Cells with a chemical receptor
can engage in predictive coding to manage their sensory
experience (Friston
K. et al., 2014; Friston K. J. et al.,
2014; Thornton, 2017). Similarly, individual cells homeostatically
maintain Vmem (cell membrane resting potential voltage) levels.
However, cells can electrically couple via gap junctions to
create bioelectric networks that work as a kind of virtual
governor—coupled oscillators possess emergent dynamics that
now maintain large, spatial patterns of Vmem against perturbation
with greater stability (Pietak and Levin, 2017, 2018; Cervera
et al., 2018, 2019a,b, 2020a,b; Pai et al., 2018; Manicka and
Levin, 2019a). These spatial patterns serve as instructive pattern
memories guiding the activity of a cell collective through
anatomical morphospace toward the correct target morphology
(Sullivan et al., 2016; Levin, 2021a; Pezzulo et al., 2021).
Voltage is especially interesting because each Vmem level in
a single cell is a coarse-grained parameter, subsuming many
distinct combinations of sodium, potassium, chloride, etc., levels,
and many distinct open/closed states of particular ion channel
proteins, which all result in the same resting potential. This can
be seen as the minimal version of generalization—cells learning to
respond to classes of events by transducing not speciﬁc ion levels
or channel protein activity states but the macrovariable “voltage.”
This in turn enables them to repurpose existing responses for
novel combinations of stimuli (e.g., familiar depolarization events
caused by novel ion dynamics).
Moreover, gap junctions propagate voltage states across tissue,
allowing cells to respond to events that are not local in nature
(larger-scale) and to respond en masse. More generally, this
means that the input to any group of cells is produced by the
output of groups of cells—sub-networks, which can be complex
and highly processed over time (not instantaneous), enabling
predictive coding to manage complex states (at a distance in
space and time) and not only purely local, immediate sensory
data. It also means that the system is extremely modular, readily
connecting diverse upstream and downstream events to each
other via the universal adapter of bioelectric states. When this
is applied to the homeostatic TOTE (test-operate-exit) loop,
allowing its measurement, comparison, and action modules to
be independently scaled up (across space, time, and complexity
metrics), this inherently expands the cognitive light cone of a
homeostatic agent to enable progressively more grandiose goals.
Crucially, all of the above-mentioned aspects of the role of
generic bioelectric networks underlying the scaling of Selves are
not only the products of the evolutionary process, but have many
functional implications for evolution itself (forming a positive
feedback loop in which rising multiscale agency potentiates the
evolution of increasingly more complex versions).
EVOLUTIONARY ASPECTS
Developmental bioelectricity works alongside other modalities
such
as
gene-regulatory
networks,
biomechanics,
and
biochemical
systems.
The
TAME
framework
emphasizes
that what makes it special is that it’s not just another
micro-mechanism
that
developmental
biologists
need
to
track.
First,
developmental
bioelectrics
is
a
unique
computational
layer
that
provides
a
tractable
entrypoint
into
the
informational
architecture
and
content
of
the
collective intelligence of morphogenesis. Second, bioelectric
circuits
show
examples
of
modularity,
memory,
spatial
integration, and generalization (abstraction over ion channel
microstates)—critical aspects of understanding basal origins
of cognition. Developmental bioelectricity provides a bridge
between the early problem-solving of body anatomy and
the
more
recent
complexity
of
behavioral
sophistication
via brains. This uniﬁcation of two disciplines suggests a
number of hypotheses about the evolutionary path that
pivoted morphogenetic control mechanisms into the cognitive
capacities of behavior, and thus sheds light on how Selves
arise and expand.
Somatic Bioelectrics Reveals the Origin
of Complex Cognitive Systems
Developmental bioelectrics is an ancient precursor to nervous
systems. Analog bioelectrical dynamics generate patterns in
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 10 | Gap junctions scale homeostatic goals. Gap junctions are a type of connection architecture that facilitates scaling of goal states (and thus expands the
cognitive cone of cellular agents). A single cell’s homeostatic cycle has 3 parts: measurements, comparison to a stored setpoint, and acting via effectors to stay in or
reach the correct region of state space (A). When coupled into gap junctions (B), each of these 3 components expands in size and complexity: the cell group is able
to (1) measure a larger region (reacting to spatially more complex inputs, not just local conditions), (2) store a more complex setpoint pattern, and (3) act (deform,
grow, etc.) at a scale that produces large-scale anatomical change. The goals of such networks readily map on to regeneration and regulative development (C):
dynamical systems pictures of artiﬁcial neural networks as they perform pattern completion based on partial input illustrate an energy landscape with wells
corresponding to stable target morphology memories. The process of completing a correct planarian pattern from a simple fragment can be modeled in this way,
perhaps with overall stress levels instantiating the free energy that the system is trying to minimize (Kuchling et al., 2020b). Such attractors correspond to different
possible morphologies, and indeed the normally robust regeneration toward a single pattern (D) can be modiﬁed in planaria by temporarily disrupting their gap
junctional network, which causes genetically un-modiﬁed worms to nevertheless build heads appropriate to other species’ attractors in morphospace (E)
(Emmons-Bell et al., 2015; Sullivan et al., 2016). Images in panels (A,B) courtesy of Jeremy Guay of Peregrine Creative. Images in panels (C–E) courtesy of Alexis
Pietak.
homogenous cell sheets and coordinate information that
regulates transcription and cell behaviors. Evolution ﬁrst
exploited this to enable cell groups to position the body
conﬁguration in developmental morphospace, long before some
cells specialized to use very fast, digital spiking as neural
networks for control of behavior as movement in 3-dimensional
space (Fields et al., 2020). The function of nervous systems
as spatial organizers operating on data from the external
world (Keijzer et al., 2013) is an adaptation built upon the
prior activity of bioelectric circuits in organizing the internal
morphology by processing data from the internal milieu.
While neural tissues electrically encode spatial information
to guide movement (e.g., memory of a maze in a rat
brain) by controlling muscles, bioelectric prepatterns guide the
behaviors of other cell types, on slower timescales, during
development, regeneration, and remodeling toward invariant,
robust anatomical conﬁgurations.
Developmental bioelectricity illustrates clearly the continuous
nature of properties thought to be important for cognition,
and the lack of a clean line separating brainy creatures from
others. On a single-cell level, even deﬁning a “neuron” is not
trivial, as most cells possess the bioelectrical machinery and a
large percentage of neuronal genes are also expressed in nonneural cells (Bucher and Anderson, 2015), while neural molecular
components are found in cytonemes (Huang et al., 2019). Many
channel families were likely already present in the most recent
unicellular ancestor (Liebeskind et al., 2015). The phylogeny of
ion channels is ancient, and the appearance of context-sensitive
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
channels (enabling new kinds of bioelectrical feedback loops)
tracks well with the appearance of complex body plans at
the emergence of metazoa (Moran et al., 2015), revealing the
remarkable evolutionary continuum that leads from membrane
excitability in single cells to cognitive functions in advanced
organisms, by way of somatic pattern control (Cook et al., 2014).
Fascinating work on bacteria has shown that prokaryotes
also utilize bioelectric state for proliferation control (Stratford
et al., 2019); and, paralleling the developmental data discussed
above, bioelectric phenomena in bacteria scale easily from singlecell properties (Kralj et al., 2011) to the emergence of protobodies as bacterial bioﬁlms. Bacterial communities use brainlike bioelectric dynamics to organize tissue-level distribution of
metabolites and second messenger molecules, illustrating many
of the phenomena observed in complex morphogenetic contexts,
such as encoding stable information in membrane potential
patterns, bistability, and spatial integration (Humphries et al.,
2017; Liu et al., 2017; Larkin et al., 2018; Martinez-Corral et al.,
2018; Yang et al., 2020). Not only animal lineages, but plants
(Baluska and Mancuso, 2012; Volkov et al., 2019; Serre et al.,
2021) use bioelectricity, as evolution frequently exploits the fact
that bioelectric dynamics are a powerful and convenient medium
for the computations needed to solve problems in a variety of
spaces not limited to movement in 3D space.
Developmental bioelectricity helps explain how free-living
cells scaled their cell-level homeostatic pathways to whole bodylevel anatomical homeostasis (Levin, 2019). It has long been
appreciated that evolvability is potentiated by modularity—the
ability to trigger complex morphogenetic cascades by a simple
“master” trigger that can be re-deployed in various contexts
in the body (von Dassow and Munro, 1999). Recent advances
reveal that bioelectric states can form very powerful master
inducers that initiate self-limiting organogenesis. For example,
the action of a single ion channel can induce an eye-speciﬁc
bioelectric state that creates complete eyes in gut endoderm,
spinal cord, and posterior tissues (Pai et al., 2012)—locations
where genetic “master regulators” like the Pax6 transcription
factor are insuﬃcient in vertebrates (Chow et al., 1999). Likewise,
misexpression of a proton pump (or a 1-h ionophore soak) to
trigger bioelectric changes in an amputation wound can induce
an entire 8-day cascade of building a complete tadpole tail
(Adams et al., 2007; Tseng et al., 2010). This is control at the level
of organ, not single cells’ fate speciﬁcation, and does not require
the experimenter to provide all of the information needed to build
the complex appendage. Thus, bioelectric states serve as eﬀective
master regulators that evolution can exploit to make modular,
large-scale changes in anatomy.
Moreover, because the same Vmem dynamics can be produced
by many diﬀerent ion channel combinations, and because
bioelectric states propagate their inﬂuence across tissue distance
during morphogenesis (Chernet and Levin, 2014; Pai et al.,
2020), evolution is free to swap out channels and explore
the bioelectrical state space: simple mutations in electrogenic
genes can exert very long-range, highly coordinated changes in
anatomy. Indeed, the KCNH8 ion channel and a connexin were
identiﬁed in the transcriptomic analysis of the evolutionary shift
between two functionally diﬀerent morphologies of ﬁn structures
in ﬁsh (Kang et al., 2015). The evolutionary signiﬁcance of
bioelectric controls can also be seen across lineages, as some
viruses evolved to carry ion channel and gap junction (Vinnexin)
genes that enable them to hijack bioelectric machinery used by
their target cells (Shimbo et al., 1996; Hover et al., 2017).
The unique computational capabilities of bioelectric circuits
likely enabled the evolution of nervous systems, as specialized
adaptations of the ancient ability of all cell networks to process
electrical information as pre-neural networks (Keijzer, 2015;
Fields et al., 2020). A full understanding of nervous system
function must involve not only its genetics and molecular biology
but also the higher levels of organization comprising dynamic
physiology and computations involved in memory, decisionmaking, and spatio-temporal integration. The same is true for
the rest of the body. For example, the realization that epithelia are
the generators of bioelectric information (Robinson and Messerli,
1996) suggests models in which they act like a retina wrapped
around a whole embryo (and individual organs) to preprocess
electrical signals into larger-scale features and compute contrast
information for downstream processing (Grossberg, 1978). The
investigation of somatic bioelectric states as primitive “pattern
memories” and the expansion of computational science beyond
neurons will enrich the understanding of cell biology at multiple
scales beyond molecular mechanisms, as is currently only done
with respect to the brain (Marr, 1982). Generalizing the deep
concepts of multiscale neuroscience beyond neurons (Grossberg,
1978; Pezzulo and Levin, 2015; Manicka and Levin, 2019b) is
necessary for a better understanding of the tissue-level decisionmaking that drives adaptive development and regeneration.
Conversely, advances in understanding information processing
in a relatively simpler anatomical context will feed back to
enrich important questions in brain science, shedding light
on fundamental mechanisms by which information-processing
agents (cells) work collectively to accomplish uniﬁed, complex
system-level outcomes. The multi-disciplinary opportunity here
is not only to gain insight into the phylogeny of nervous systems
and behavior, but to erase the artiﬁcial boundaries between
scientiﬁc disciplines that focus on neurons vs. the rest of the
body, with the direct consequence that a more inclusive, gradualist
picture emerges of the mechanisms commonly associated with
cognitive Selves.
Ion channels and gap junctions are the hardware interface
to the bioelectric computational layer within living systems.
Like a retina for a brain, or a keyboard for a computer,
they allow transient signals to serve as inputs to memory
and decision-making networks. For any given agent (cell,
tissue, etc.), its bioelectrical interface is accessed by a number
of potential users. First are the neighboring agents, such as
other tissues, which pass on their bioelectric state during
cooperative and competitive interactions in morphogenesis.
There are also commensal and parasitic microbes, which have
evolved to hijack such control systems to manipulate the
anatomy of the host—like the naïve bacteria on planaria that
can determine head number and visual system structure in
ﬂatworm regeneration (Williams et al., 2020). Moreover, the
development of pharmacological, genetic, and optogenetic tools
now allows human bioengineers to access bioelectrical circuits
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
for the control of growth and form in regenerative medicine
and synthetic bioengineering contexts (Adams et al., 2013,
2014, 2016; Chernet et al., 2016; McNamara et al., 2016;
Bonzanni et al., 2020). All of these manipulations can serve
as catalysts, enabling an evolutionary lineage to more easily
travel to regions of option space that might otherwise be
separated by an energy barrier that is diﬃcult for standard
evolution to reach. In this sense, cognitive properties of
developmental mechanisms help us to understand problemsolving on phylogenetic, not just ontogenetic, timescales. We
next look at speciﬁc ways in which the architecture of multiscale
autonomy, especially as implemented by bioelectric network
mechanisms, potentiates evolution.
Multi-Scale Autonomy Potentiates the
Speed of Evolution
Deterministic chaos and complexity theory have made it very
clear why bottom-up control of even simple systems (e.g., 3-body
problem) can be practically impossible. This inverse problem
(Lobo et al., 2014)—what control signals would induce the
desired change—is not only a problem for human engineers but
also for adjacent biological systems such as the microbiome or
a fungus that seeks to control the behavior of an ant (Hughes
et al., 2016), and most of all, for other parts of a complex system
(to help control itself). Evolution tackles this task by exploiting
a multiscale competency architecture (MCA), where subunits
making up each level of organization are themselves homeostatic
agents. It’s built on an extremely powerful design principle: error
correction (Fields and Levin, 2017; Frank, 2019a,b).
The key aspect of biological modularity is not simply that
complex subroutines can be triggered by simple signals, making it
easy to recombine modules in novel ways (Schlosser and Wagner,
2004; Gerhart and Kirschner, 2007), but that these modules are
also themselves sub-agents exhibiting infotaxis and socialtaxis,
and solving problems in their own spaces (Vergassola et al.,
2007; Gottlieb et al., 2013; Karpas et al., 2017). When an eye
primordium appears in the wrong place (e.g., a tadpole tail), it
still forms a correctly patterned, functional organ, manages to get
its data to the brain (via spinal cord connection) to enable vision
(Figure 6E), and (if somewhere in the head) moves to the correct
place during metamorphosis (Vandenberg et al., 2012). When
cells are artiﬁcially made to be very large and have several times
the normal genetic material, morphogenesis adapts to this and
still builds an overall correct animal (Fankhauser, 1945a,b). These
are goal-directed (in the cybernetic sense) processes because the
system can reach a speciﬁc target morphology (and functionality)
state despite perturbations or changes in local/starting conditions
or the basic underlying components. Regeneration is the most
familiar example of this, but is just a special case of the broader
phenomenon of anatomical homeostasis. Homeostatic loops
operating over large-scale anatomical states have several (closely
related) key implications for the power and speed of evolution.
First, it greatly smoothes the ﬁtness landscape. Consider two
types of organisms: one whose subsystems mechanically follow
a hardwired (genetically-speciﬁed) set of steps (A, passive, or
merely structural modularity), and one whose modules optimize
a reward function (B, multi-scale competency of modules).
Mutations that would be detrimental in A (e.g., because they
move the eye out of its optimal position) are neutral in B, because
the competency of the morphogenetic subsystems repositions
the eye even if it starts out somewhere else. Thus, MCA shields
from selection some aspects of mutations’ negative eﬀects (which
inevitably are the bulk of random mutations’ consequences). The
primary reason for the anatomical homeostasis seen in regulative
development and regeneration may be for dealing, not with
damage, but with deviations from target morphology induced by
mutations. This is certainly true at the scale of tissues during the
lifetime of an individual [as in the inverse relationship between
regeneration and cancerous defection from large-scale target
morphology (Levin, 2021b)], but may be true on evolutionary
time scales as well.
Second, MCA reduces apparent pleiotropy—the fact that most
mutations have multiple eﬀects (Boyle et al., 2017). For example, a
change in an important canonical signaling pathway such as Wnt
or BMP (Raible and Ragland, 2005) is going to have numerous
consequences for an organism. Suppose a mutation appears that
moves the mouth oﬀof its optimal position (bad for ﬁtness) but
also has some positive (adaptive) feature elsewhere in the body. In
creatures of type A, the positive aspects of that mutation would
never be seen by selection because the malfunctioning mouth
would reduce the overall ﬁtness or kill the individual outright.
However, in creatures of type B, the mouth could move to its
optimal spot (Vandenberg et al., 2012), enabling selection to
independently evaluate the other consequence of that mutation.
Creatures possessing MCA could reap the beneﬁt of positive
consequences of a mutation while masking its other eﬀects via
local adjustments to new changes that reduce the penalties (an
important kind of buﬀering). In eﬀect, evolution doesn’t have to
solve the very diﬃcult search problem of “how to improve feature
X without touching features Y. Z which already work well,” and
reaps massive eﬃciency (time) savings by not having to wait
until the search process stumbles onto a way to directly encode
an improvement that is either isolated from other features, or
improves them all simultaneously (Wagner et al., 2007; Melo
et al., 2016).
Third, MCA allows systems not only to solve problems,
but also to exploit opportunities. A lineage has the chance to
ﬁnd out what pro-adaptive things a mutation can do, because
competency hides the negative consequences. This gives time
for new mutations to appear that hardwire the compensatory
changes that had to be applied—an analogy to the proposed
Baldwin eﬀect (Hogenson, 2001; Downing, 2004; Robinson and
Barron, 2017). This enables the opportunity to exploit the
possibility space more freely, providing a kind of patience or
reduction of the constraint that evolutionary beneﬁts have to
be immediate in order to propagate—it eﬀectively reduces the
short-sightedness of the evolutionary process. Indeed, multiscale
competency is beneﬁcial not only for natural evolution, but also
for soft robotics and synthetic bioengineering because it helps
cross the sim-to-real gap: models do not have to be 100% realistic
to be predictively useful if the component modules can adaptively
make up for some degree of deﬁciency in the controller design
(Brooks, 1986).
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Fourth, the homeostatic setpoint-seeking architecture makes
the relationship between genotype and anatomical phenotype
more linear (Muller and Schuppert, 2011; Lobo et al., 2014),
improving controllability (Liu et al., 2011; Gao et al., 2014;
Posfai et al., 2016). By using a top-down control layer to encode
the patterns to which competent subunits operate, living systems
do not need to solve the diﬃcult inverse problems of what
signals to send their subsystems to achieve high-level outcomes.
Bioelectric pattern memories (such as the voltage distribution
that tells wild-type planarian cells whether to build 1 head or
2) exploit a separation of data from the machine itself, which
makes it much easier to make changes. Evolution does not need
to ﬁnd changes at the micro level but can also simply change the
information encoded in the setpoints, such as the electric face
prepattern (Vandenberg et al., 2012), which allows it to re-use
the same exact implementation machinery to build something
that can be quite diﬀerent. The ability to rely on a non-zero
IQ for your component modules (thus delegating and oﬄoading
complex regulatory chains) is an important aﬀordance (Watson
et al., 2010; Friston et al., 2012) for the evolutionary process. It
means that the larger system’s evolution is in eﬀect searching
an easier, less convoluted control, signaling, or reward space—
this massive dimensionality reduction oﬀers the same advantages
human engineers have with agents on the right side of the
persuadability scale. It is no accident that learning in the brain,
and behavioral systems, eventually exapted this same architecture
and indeed the exact same bioelectrical machinery to speed up the
beneﬁts of evolution.
A signiﬁcant brake on the eﬃciency of evolution, as on
machine learning (indeed, all learning) is credit assignment:
which change or action led to the improvement or reward?
When a collection of cells known as a “rat” learns to press a
level and get a reward, no individual cell has the experience of
interacting with a lever and receiving the nutrient. What enables
the associative memory in this collective intelligence are the delay
lines (nervous system) between the paws and the intestinal lining
which provide a kind of patience—a tolerance of the temporal
delay between the action and the reward and the ability to
link extremely diverse modules on both ends (diﬀerent kinds
of actions can be linked to arbitrary rewards). MCA does the
same thing for evolutionary learning (Watson et al., 2014, 2016;
Power et al., 2015; Watson and Szathmary, 2016; Kouvaris et al.,
2017), making it easier for systems to reap selection rewards for
arbitrary moves in genotype space. This eﬀectively raises the IQ
of the evolutionary search process. Much as (Figure 5) an agent’s
sophistication can be gauged by how expertly and eﬃciently
it navigates an arbitrary search space and its local optima, the
traversal of the evolutionary search process can be made less
short-sided by homeostatic activity within the physiological layer
that sits between genotype and phenotype.
There is an adaptation tradeoﬀbetween robustness (e.g.,
morphogenesis to the same pattern despite interventions
and changing conditions) and responsiveness to environment
(context sensitivity), perhaps similar to the notion of criticality
(Beggs, 2008; Hankey, 2015). The plasticity and goal-directedness
of modules (as opposed to hardwired patterns) serve to reduce
the sim-to-real gap (Kriegman et al., 2020b): because the
current environment always oﬀers novel challenges compared
to prior experiences which evolution (or human design) uses to
prepare responses, the MCA architecture doesn’t take history too
seriously, relying on plasticity and problem-solving more than on
ﬁne-tuning micromodels of what to do in speciﬁc cases. Biology
reaps the beneﬁts of both types of strategies by implementing
anatomical homeostasis that coarse-grains robustness by making
stability applying to large outcomes, such as overall anatomy,
not to the microdetails of cell states. The scaling of homeostatic
loops makes it possible to achieve both: consistent results and
environmental sensitivity. These dynamics apply in various
degrees to the numerous nested, adjacent, and overlapping subagents that make up any biological system. Cooperation results
not from altruistic actions between Selves, but by the expansion
of the borders of a single Self via scaling of the homeostatic loops.
On this view, cancer cells are not more selﬁsh than tissues—they
are all equally selﬁsh, but maintain goals appropriate to smaller
scales of Selves. Indeed, even the parts of one normal body don’t
perfectly cooperate—this is as true in development (Gawne et al.,
2020) as it is in cognitive science (Dorahy et al., 2014; Reinders
et al., 2018, 2019). A picture is emerging of how evolution exploits
the local competency of modules, competing and cooperating, to
scale these subsystems’ sensing, actuation, and setpoint memories
to give rise to coherent larger-scale Selves. Overall, the TAME
framework addresses functional aspects only, and is compatible
with several views on phenomenal consciousness in compound
Selves (Chalmers, 1996). However, it does have a few implications
for the study of Consciousness.
CONSCIOUSNESS
While the TAME framework focuses on 3rd-person observable
properties, it does make some commitments to ways of thinking
about consciousness. Provisionally, I suggest that consciousness
also comes in degrees and kinds (is not binary) for the same
reasons argued for continuity of cognition: if consciousness is
fundamentally embodied, the plasticity and gradual malleability
of bodies suggests that it is a strong requirement for proponents
of phase transitions to specify what kind of “atomic” (not further
divisible) bodily change makes for a qualitative shift in capacity
consciousness. Another implication of TAME is that while
“embodiment” is critical for consciousness, it is not restricted to
physical bodies acting in 3D space, but also includes perceptionaction systems working in all sorts of spaces. This implies,
counter to many people’s intuitions, that systems that operate
in morphogenetic, transcriptional, and other spaces should also
have some (if very minimal) degree of consciousness. This in
turn suggests that an agent, such as a typical modern human, is
really a patchwork of many diverse consciousnesses, only one of
which is usually capable of verbally reporting its states (and, not
surprisingly, given its limited access and self-boundary, believes
itself to be a unitary, sole owner of the body).
What is necessary for consciousness? TAME’s perspective
is fundamentally that of the primacy of goal-directed activity.
Thus, consciousness accompanies speciﬁc types of cognitive
processes which exert energy toward goals, but as described
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
above, those processes can take forms very divergent from our
typical brain-centered view. Unlike other panpsychist views,
TAME does not claim that mind is inevitably baked in regardless
of physical implementation or structure. Causal structure and
cybernetic properties of the embodiment are key determinants
of consciousness capacity. However, as the minimal degree of
internal self-determination and goal-directedness is apparently
present even in particles (Feynman, 1942; Georgiev and Georgiev,
2002; Ogborn et al., 2006; Kaila and Annila, 2008; Ramstead et al.,
2019; Kuchling et al., 2020a), there may be no true “0” on the scale
of consciousness in the universe. While simple accretion does not
magnify the nano-goal-directed activity and indeterminate action
of particles (e.g., rocks are not more conscious, and probably less,
than particles in speciﬁc contexts), biological organization does
amplify it, resulting in scaling up of sentience.
Of course, these implications will be unpalatable conclusions
for many. It should be kept in mind that TAME is compatible
with several diﬀerent views on consciousness, and does not need
to commit to one speciﬁc philosophy. It is fundamentally a
framework for enabling empirical experiments, and its practical
utility remains, regardless of the above speculations. Moreover,
I remain skeptical about being able to say anything deﬁnitive
about consciousness per se (as distinct from correlates of
consciousness) from a 3rd-person, objective perspective. Thus,
however unappealing the above view may be, I see no way of
rigorously showing why any other claim about consciousness and
what it requires is demonstrably better.
An emphasis on somatic plasticity has additional practical
implications, being focused on the functional splitting and
joining of agents’ parts. For example, the ancient question of
“where does it all come together?” in the brain, with respect to
the uniﬁed character of consciousness, is one of those pseudoproblems that is dispelled by a framework like TAME that focuses
on multi-scale architecture. How big should a place where it all
comes together be? If it can be ∼140 mm wide, then the answer
is, the whole brain. One could decide that it should be smaller
(the human pineal gland is ∼7 mm wide), but then the question
is, why not smaller still—given the cellular components of the
pineal (or any piece of the brain) and the molecular organelles
inside a pineal gland cell, one would always need to ask “but
where does it all come together inside there?” of whatever piece
of the brain is taken to be the seat of consciousness. The multiscale nature of biology means that there is no privileged size scale
for any homunculus.
Another important idea with respect to consciousness is
“What is it like to be” a given agent (Nagel, 1974). Sensory
augmentation, neural link technologies, and bioengineering
produce tractable model systems in novel cognitive architectures,
such as 2-headed planaria where the brains are connected by a
central nervous system (Figure 7B), to help study the functional
aspects of this cognitive re-shuﬄing. TAME’s focus on the
fact that all cognitive architectures are inevitably composites
emphasizes that the parts can be rearranged; thus, the Subject of
cognition can change “on the ﬂy,” not merely during evolutionary
timescales. Thus, the basic question of philosophy of mind—
what’s it like to be animal X (Nagel, 1974)—is just a ﬁrst-order
step on a much longer journey. The second-order question
is, what’s it like to be a caterpillar, slowly changing into a
butterﬂy as its brain is largely dissolved and reassembled into
a diﬀerent architecture for an animal whose sense organs,
eﬀectors, and perhaps overall Umwelt is completely diﬀerent.
All of this raises fascinating issues of ﬁrst person experience
not only in purely biological metamorphoses (such as human
patients undergoing stem cell implants into their brains), but also
technological hybrids such as brains instrumentized with novel
sensory arrays, robotic bodies, software information systems,
or brains functionally linked to other brains (Warwick et al.,
1998; Demarse et al., 2001; Potter et al., 2003; Bakkum et al.,
2007a,b; Tsuda et al., 2009; Cohen-Karni et al., 2012; Giselbrecht
et al., 2013; Aaser et al., 2017; Ricotti et al., 2017; Ding et al.,
2018; Mehrali et al., 2018; Anderson et al., 2020; Ando and
Kanzaki, 2020; Merritt et al., 2020; Orive et al., 2020; Saha et al.,
2020; Dong et al., 2021; Li et al., 2021; Pio-Lopez, 2021). The
developmental approach to the emergence of consciousness on
short, ontogenetic timescales complements the related question
on phylogenetic timescales, and is likely to be a key component
of mature theories in this ﬁeld.
Most
surprisingly,
the
plasticity
and
capacity
for
bioengineering and chimerization (recombination of biological
and engineered parts in novel conﬁgurations) erases the sharp
divide between ﬁrst person and third person perspectives.
This has been a fundamental, discrete distinction ever since
Descartes, but the capacity for understanding and creating new
combinations shows a continuum even in this basic distinction
(Figure 11). The fact that Selves are not monadic means we
can share parts with our subject of inquiry. If one has to be a
system in order to truly know what it’s like to be that system
(1st person perspective), this is now possible, to various degrees,
by physically merging one’s cognitive architecture with that
of another system. Of course, by strongly coupling to another
agent, one doesn’t remain the same and experience the other’s
consciousness; instead, a new Self is created that is a composite
of the two prior individuals and has composite cognition. This
is why consciousness research is distinct in strong degree from
other scientiﬁc topics. One can observe gauges and instruments
for 3rd-person science and remain the same Self (largely; the
results of the observation may introduce small alterations in the
cognitive structure). However, data on 1st person experiential
consciousness cannot be taken in without fundamentally
changing the Self (being an eﬀective homunculus by watching
the neuroscience data corresponding to the movies inside the
heads of other people is impossible for the same reason that
there is no homunculus in each of our heads). The study of
consciousness, whether done via scientiﬁc tools or via the mind’s
own capacity to change itself, inevitably alters the Subject. Thus,
standard (3rd-person) investigations of this process leave open
the ancient question as to whether speciﬁc upgrades to cognition
induce truly discontinuous jumps in consciousness. The TAME
framework is not incompatible with novel discoveries about
sharp phase transitions, but it takes the null hypothesis to be
continuity, and it remains to be seen whether contrary evidence
for truly sharp upgrades in consciousness can be provided.
Future, radical brain-computer interfaces in human patients are
perhaps one avenue where a subject undergoing such a change
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
FIGURE 11 | Technology reveals gradualism in Descartes’ cut. The apparent fundamental gulf between ﬁrst person perspective (what is it like to be a speciﬁc Self)
and third person perspective (external scientiﬁc study of that cognitive system) can be seen to also be a gradual continuum, when modern technology is used to
expand heterophenomenology (Dennett, 1991). On the left side of the continuum (A) is a traditional 3-rd person scenario of an agent studying another by measuring
its physical states: cognitive states can be inferred but not directly experienced (correlates of consciousness), giving rise to the problem of other minds, and a ﬁrm
distinction between “you” and “me.” However, sensory substitution and augmentation technology now enables the plugging of various peripherals and sensors
directly into the nervous system of subjects, and thus it is possible to connect the output of electrophysiology equipment directly into the subject’s brain (B). For
example, if the output of a multielectrode array recording neural activity of subject #1 is connected directly to the brainport device (Danilov and Tyler, 2005) of subject
#2 (e.g., a scientist), this allows #1’s mental states to more directly provide input into #2’s sensory stream. This can be made even more direct by fusing portions of
two brains directly, during embryogenesis, illustrating that the strength of boundaries between “you” and “me” is variable; this conﬁguration may seem far-fetched,
but note that it can be readily produced today in animal model systems, and the only barrier to such conﬁgurations is ethical, not empirical or logical (C). It’s critical to
note that these fusion experiments are not just aberrant corner cases, because all brains are already fusions of neural modules. Single subjects’ brains consist of two
hemispheres which must communicate to give rise to a coherent, centralized perception of “me” despite being made of communicating parts, and can be
dissociated by commissurotomy (D). Indeed, beyond the two hemispheres, any brain is a collective of smaller active subunits (E) that must all communicate as a
collection of cells (each neuron is part of the neighboring neural cell’s “external environment”). This gradient of diverse connections, whether electronic or biological,
between and within brains and brain components can be reproduced or expanded upon to whatever degree necessary by biological or technological fusion among
subjects. The technological aspect of TAME is that we must develop frameworks that deal not only with standard embodiments of mind as happened to be
produced by the path evolution took through life on Earth, but all logically and empirically possible conﬁgurations that could evolve, be designed, or both, whether on
Earth or in exobiological contexts. The hierarchical, not monadic, structure of cognitive substrates means that the relationship between the parts of one Self and that
between a Self and an object of external study is a continuum, not a discrete natural kind. This suggests a key way that actual Consciousness can be studied—by
becoming inherently a participant in the experiment, so as to study it from a ﬁrst-person perspective. Importantly however, what happens when one fuses cognitive
systems with their subject of study is that a new Self appears (a composite cognitive system), showing that the Self can remain invariant while pursuing scientiﬁc
study of functional cognition and behavior (the left of the spectrum), but essentially must change in order to gain ﬁrst-hand knowledge of consciousness in other
cognitive systems. Images are courtesy of Jeremy Guay of Peregrine Creative.
can convince themselves, and perhaps others, that a qualitative,
not continuous, change in their consciousness had occurred.
With respect to the question of consciousness per se, as opposed
to neural or behavioral correlates of consciousness, we have one
major functional tool: general anesthesia. It is remarkable that we
can readily induce a state in which all the individual cells are ﬁne
and healthy, but the larger Self is simply gone [although, some of
the parts can continue to learn during this time (Ghoneim and
Block, 1997)]. Interestingly, general anesthetics are gap junction
blockers (Wentlandt et al., 2006): consistent with the cognitive
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
scaling example above, shutting down electrical communication
among the cells leads to a disappearance of the higher-level
computational layer while the cellular network is disrupted. GJ
blockers are used to anesthetize living beings ranging across
plants, Hydra, and human subjects (Gremiaux et al., 2014).
It is amazing that the same Self (with memories and other
properties) returns, when the anesthetic is removed. Of course,
the Self does not return immediately, as shown by the many
hallucinatory (Saniova et al., 2009; Kelz et al., 2019) experiences
of people coming out of general anesthesia—it takes some time
for the brain to return to the correct global bioelectric state
once the network connections are allowed again (meta-stability)
(Rabinovich et al., 2008). Interestingly, and in line with the
proposed isomorphism between cognition and morphogenesis,
gap junction blockade has exactly this eﬀect in regeneration:
planaria brieﬂy treated with GJ blocker regenerate heads of other
species, but eventually snap out of it and remodel back to their
correct target morphology (Emmons-Bell et al., 2015). It is no
accident that the same reagents cause drastic changes in the
high-level Selves in both behavioral and morphogenetic contexts:
evolution uses the same scheme (GJ-mediated bioelectrical
networks) to implement both.
The epistemic problem of Other Minds has been framed to
imply that we cannot directly ever be sure how much or what
kind of consciousness exists in any particular system under study.
The TAME framework reminds us that this is true even for
components of ourselves (like the non-verbal brain hemisphere).
Perhaps the confabulation system enables one part of our mind to
estimate the agency of other parts (the feelings of consciousness
and free will) and develop models useful for prediction and
control, applying in eﬀect the empirical criteria for persuadability
internally. The ability to develop a “theory of mind” about
external agents can readily be turned inward, in a composite Self.
Are all cognitive systems conscious? The TAME framework
is compatible with several views on the nature of consciousness.
However, the evolutionary conservation of mechanisms between
brains and their non-neural precursors has an important
consequence for the question of where consciousness could
be found. To the extent that one believes that mechanisms
in the brain enable consciousness, all of the same machinery
and many similar functional aspects are found in many other
places in the body and in other constructs. TAME emphasizes
that there is no principled way to restrict consciousness to
“human-like, full-blown sophisticated brains,” which means one
has to seriously consider degrees of consciousness in other
organs, tissues, and synthetic constructs that have the same
features neurons and their networks do (Trewavas and Baluska,
2011; Baluska et al., 2016, 2021; Baluska and Reber, 2019).
The fundamental gradualism of this framework suggests that
whatever consciousness is, some variant and degree thereof
has to be present very widely across autopoietic systems.
TAME is deﬁnitely incompatible with binary views that cut oﬀ
consciousness at a particular sharp line and it suggests no obvious
way to deﬁne cognitive systems that have no consciousness
whatsoever. A big open question is whether the continuum
of cognition (and consciousness) contains a true “0” or only
inﬁnitesimal levels for very modest agents. One is tempted to
imagine what properties a truly minimal agent would have to
have; not being fully constrained by local forces, and ability to
pursue goals, both seem key, and both of these are present to a
degree in even single particles (via quantum indeterminacy and
least action behavior). The type and degree of scaling (or lack
thereof) of these capacities in bulk inorganic matter vs. highlyorganized living forms is a fertile area for future development of
TAME and will be explored in forthcoming work.
CONCLUSION
A More Inclusive Framework for
Cognition
Regenerating, physiological, and behaving systems use eﬀort
(energy) to achieve deﬁned, adaptive outcomes despite novel
circumstances and unpredictable perturbations. That is a key
invariant for cognition; diﬀerences in substrate, scale, or origin
story among living systems are not fundamental, and obscure
an important way to unify key properties of life: the ability
to deploy intelligence for problem-solving in diverse domains.
Modern theories of Mind must eventually handle the entire
option space for intelligent agents, which not only contains
the familiar advanced animals we see on Earth, but can also
subsume ones consisting of radically diﬀerent materials, ones
created by synthetic bioengineering or combinations of evolution
and rational design in the lab, and ones of exobiological as
well as possible terrestrial origins. The advances of engineering
conﬁrm and put into practice an idea that was already entailed
by evolution: that cognitive traits, like all other traits, evolved
from humbler variants, forming a continuum. There are no
biologically-valid binary categories in this space. Take the
prevalent legal deﬁnition of human “adults,” who snap into being
at the age of 18; such binary views on cognitive properties are
ﬁctitious coarse-grainings useful for our legal system to operate,
but no more than that. There is no bright line between “truly
cognitive” and “pseudo cognitive” that can ever be drawn between
two successive members of an evolutionary lineage. The error
of “committing Anthropomorphism” is a pseudo-scientiﬁc “folk”
notion useful for only the most trivial examples of failure to
scale down complex claims proportionally to simpler systems;
engineering requires us to determine what level of cognitive
model enables the most fruitful prediction and control.
Every intelligence is a collective intelligence, and the modular,
multi-scale architecture of life means that we are a holobiont
in more than just the sense of having a microbiome (Chiu and
Gilbert, 2015)—we are all patchworks of overlapping, nested,
competing, and cooperating agents that have homeostatic (goaldirected) activity within their self-constructed virtual space at
a scale that determines their cognitive sophistication. A highly
tractable model system for unconventional cognition, in which
these processes and the scaling of Selves can not only be seen
but can also be manipulated, is morphogenetic homeostasis.
The process of construction and remodeling (toward anatomical
features) of cellular collectives shows crucial isomorphism to
cognitive aspects of the many-into-one binding like credit
assignment, learning, stress reduction, etc. The partial wiping
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
of ownership information on permanent signals makes gap
junctional coupling an excellent minimal model system for
thinking about biological mechanisms that scale cognition while
enabling co-existence of subunits with local goals (multiple levels
of overlapping Selves, whose scale and borders are porous and can
change during the lifetime of the agent). However, many other
substrates can no doubt fulﬁll the same functions.
Next Steps: Conceptual and Empirical
Research Programs
The TAME framework is conceptually incomplete in important
ways. On-going development is proceeding along lines including
merging with other frameworks such as Active Inference (Friston,
2013; Badcock et al., 2019; Ramstead et al., 2019), Rosen’s (M,R)
and Anticipatory Systems (Rosen, 1973, 1979, 1985; Nasuto
and Hayashi, 2016), and recent advances in information theory
as applied to individuality and scaling of causal power (Hoel
et al., 2013, 2016; Krakauer et al., 2014; Daniels et al., 2016).
It will be critical to more rigorously develop the waypoints
along the Persuadability Continuum, including understanding
of what an “increased capacity” human (or non-human) would
be like, in contrast to the “diminished capacity” with which we
are well familiar from legal proceedings [the right side of the
continuum, corresponding to radically expanded cognitive light
cones (´S¯antideva Bstan ’dzin rgya m and Comité de traduction
Padmakara, 2006)].
The TAME framework suggests numerous practical research
directions immediately within reach (some of which are already
pursued in our group), including developing biomedicallyactionable models of morphogenetic plasticity and robustness
as meta-cognitive error correction mechanisms, tissue training
paradigms for anatomical and physiological outcomes, exploiting
learning properties of pathway models for regenerative medicine
(Herrera-Delgado et al., 2018; Biswas et al., 2021), and creation
of AI platforms based on multi-scale agency architectures that do
not rely on neuromorphic principles.
Beyond Basic Science: Up-to-Date
Ethics
The TAME framework also has implications for ethics in
several ways. The current emphasis for ethics is on whether
bioengineered constructs (e.g., neural cell organoids) are
suﬃciently like a human brain or not (Hyun et al., 2020), as
a criterion for acceptability. Likewise, existing eﬀorts to extend
ethics focus on natural, conventional evolutionary products such
as invertebrates (Mikhalevich and Powell, 2020). TAME suggests
that this is insuﬃcient, because many diﬀerent architectures
for cognition are possible (and will be realized)—similarity to
human brains is too parochial and limiting a marker for entities
deserving of protection and other moral considerations. We must
develop a new ethics that recognizes the diversity of possible
minds and bodies, especially since combinations of biological,
engineered, and software systems are, and increasingly will be,
developed. What something looks like and how it originated
(Levin et al., 2020; Bongard and Levin, 2021) will no longer be a
good guide when we are confronted with a myriad of creatures
that cannot be comfortably placed within the familiar Earth’s
phylogenetic tree.
Bioengineering of novel Selves raises our moral responsibility.
For eons, humans have been creating and releasing into the world
advanced, autonomous intelligences—via pregnancy and birth of
other humans. This, in Dennett’s phrase, has been achieved until
now via high levels of “competency without comprehension”
(Dennett, 2017); however, we are now moving into a phase
in which we create beings via comprehension—with rational
control over their structure and cognitive capacities, which brings
additional responsibility. A new ethical framework will have
to be formed without reliance on binary folk notions such
as “machine,” “robot,” “evolved,” “designed,” etc., because these
categories are now seen to not be crisp natural kinds. Instead,
wider approaches (such as Buddhist concern for all sentient
beings) may be needed to act ethically with respect to agents
that have preferences, goals, concerns, and cognitive capacity
in very unfamiliar guises. TAME seeks to break through the
biases around contingent properties that drive our estimates of
who or what deserves proper treatment, to develop a rational,
empirically-based mechanism for recognizing Selves around us.
Another aspect of ethics is the discussion of limits on
technology. Much of it is often driven by a mindset of making
sure we don’t run afoul of the risks of negative uses of
speciﬁc technologies (e.g., genetically-modiﬁed organisms in
ecosystems). This is of course critical with respect to the new
bioengineering capabilities. However, such discussions often are
one-sided, framed as if the status quo was excellent, and our main
goal is simply to not make things worse. This is a fundamental
error which neglects the opportunity cost of failing to fully
exploit the technologies which could drive advances in the
control of biology. The status quo is not perfect—society faces
numerous problems including disparities of quality of life across
the globe, incredible suﬀering from unsolved medical needs,
climate change, etc. It must be kept in mind that along with the
need to limit negative consequences of scientiﬁc research, there is
a moral imperative to advance aspects of research programs that
will (for example) enable the cracking of the morphogenetic code
to revolutionize regenerative medicine far beyond what genomic
editing and stem cell biology can do alone (Levin, 2011).
The focus on risk arises from a feeling that we should not
“mess with nature,” as if the existing structures (from anatomical
order to ecosystems) are ideal, and our fumbling attempts will
disrupt their delicate balance. While being very careful with
powerful advances, it must also be kept in mind that existing
balance (i.e., the homeostatic goals of systems from cells to species
in the food web) was not achieved by optimizing happiness or
any other quality commensurate with modern values: it is the
result of dynamical systems properties shaped by the frozen
accidents of the meanderings of the evolutionary process and
the harsh process of selection for survival capacity. We have the
opportunity to use rational design to do better than the basic
mechanisms of evolution allow.
Importantly, current technologies are forcing us to confront
an existential risk. Swarm robotics, Internet of Things, AI, and
similar engineering eﬀorts are going to be creating numerous
complex, goal-driven systems made up of competent parts. We
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
currently have no mature science of where the goals of such
novel Selves come from. TAME reminds us that it is essential to
understand how goals of composite entities arise and how they
can be predicted and controlled. To avoid the Skynet scenario
(Bostrom, 2015), it is imperative to study the scaling of cognition
in diverse substrates, so that we can ensure that the goals of
powerful, distributed novel beings align with ours.
Given the ability of human subunits to merge into even larger
(social) structures, how do we construct higher-order Selves that
promote ﬂourishing for all? The multicellularity-cancer dynamic
(Figure 9) suggests that tight functional connections that blur
cognitive boundaries among subunits is a way to increase
cooperation and cognitive capacity. However, simply maximizing
loss of identity into massive collectivism is a well-known failure
at the social level, always resulting in the same dynamic: the
goals of the whole diverge sharply from those of the parts, which
become as disposable to the larger social Self as shed skin cells
are to us. Thus, the goal of this research program beyond biology
is the search for optimal binding policies between subunits,
which optimize the tradeoﬀs needed to maximize individual goals
and well-being (preserving freedom or empowerment) while
reaping the beneﬁts of a scaled-up Self at the level of groups
and entire societies. While the speciﬁc binding mechanisms used
by evolution are not guaranteed to be the policies we want
at the social level, the study of these are critical for jumpstarting a rigorous program of research into possible ways of
scaling that could have social relevance. These issues have been
previously addressed in the context of evolutionary dynamics
and game theory (Maynard Smith and Szathmáry, 1995; Michod
and Nedelcu, 2003; Van Baalen, 2013), but can be signiﬁcantly
expanded using the TAME framework.
In the end, important ethical questions around novel agents
made of combinations of hardware, software, evolved, and
designed components always come back to the nature of
the Self. The coherence of a mind, along with its ability to
pursue goal-directed activity, is central to our notions of moral
responsibility in the legal sense: diminished capacity, and soon,
enhanced capacity, to make choices is a pillar for social structures.
Mechanist views of cause and eﬀect in the neuroscience of
behavior have been said to erode these classical notions. Rather
than reduce Selves (to 0, in some eliminativist approaches),
TAME (Levin, 2022) ﬁnds novel Selves all around us. We see
more agency, not less, when evolution and cell biology are taken
seriously (Levin and Dennett, 2020). The cognitive Self is not an
illusion; what is an illusion is that there is only one, permanent,
privileged Self that has to arise entirely bottom-up through the
hill-climbing process of evolution. Our goal, at the biomedical,
personal, and social levels should not be to destroy or minimize
the Self but to recognize it in all its guises, understand its
transitions, and enlarge its cognitive capacity toward the wellbeing of other Selves.
DATA AVAILABILITY STATEMENT
The original contributions presented in the study are included
in the article/supplementary material, further inquiries can be
directed to the corresponding author.
AUTHOR CONTRIBUTIONS
ML developed all the ideas and wrote the entire manuscript.
FUNDING
I gratefully acknowledge support by the Paul G. Allen Frontiers
Group (via an Allen Discovery Center Award 12171), the
Templeton World Charity Foundation (WCF0089/AB55 and
TWCF0140), and John Templeton Fund (Grant 62212 from
the John Templeton Foundation). The funders had no role in
determining the content of this manuscript.
ACKNOWLEDGMENTS
I would like to thank Dora Biro, Joshua Bongard, Avery Caulﬁeld,
Anna Ciaunica, Pranab Das, Daniel Dennett, Thomas Doctor,
Bill Duane, Christopher Fields, Adam Goldstein, EJ, Aysja
Johnson, Jeantine Lunshof, Santosh Manicka, Patrick McMillen,
Aniruddh Patel, Giovanni Pezzulo, Andrew Reynolds, Elizaveta
Solomonova, Matthew Simms, Richard Watson, Olaf Witkowski,
Rafael Yuste, and numerous others from the Levin Lab and the
Diverse Intelligences community for helpful conversations and
discussions, as well as comments on versions of this manuscript. I
would also like to thank the three reviewers of the manuscript for
important critiques that led to improvement. This manuscript is
dedicated to my mother, Luba Levin, who while not having been
a scientist, always modeled a deep understanding of, and care for,
the multi-scale agency abundant in the world.
REFERENCES
Aaser, P., Knudsen, M., Ramstad, O. H., van de Wijdeven, R., Nichele, S., Sandvig,
I., et al. (2017). “Towards making a cyborg: a closed-loop reservoir-neuro
system,” in ECAL 2017: The 14th European Conference on Artiﬁcial Life (Lyon:
MIT Press), 430–437.
Abraham, W. C., Jones, O. D., and Glanzman, D. L. (2019). Is plasticity of synapses
the mechanism of long-term memory storage? NPJ Sci. Learn. 4:9. doi: 10.1038/
s41539-019-0048-y
Adams, D. S., Lemire, J. M., Kramer, R. H., and Levin, M. (2014). Optogenetics
in developmental biology: using light to control ion ﬂux-dependent signals
in Xenopus embryos. Int. J. Dev. Biol. 58, 851–861. doi: 10.1387/ijdb.140
207ml
Adams, D. S., Masi, A., and Levin, M. H. (2007). H+ pump-dependent changes in
membrane voltage are an early mechanism necessary and suﬃcient to induce
Xenopus tail regeneration. Development 134, 1323–1335. doi: 10.1242/dev.
Adams,
D.
S.,
Tseng,
A.
S.,
and
Levin,
M.
(2013).
Lightactivation
of
the
Archaerhodopsin
H(+)-pump
reverses
agedependent
loss
of
vertebrate
regeneration:
sparking
system-level
controls
in
vivo.
Biol.
Open
2,
306–313.
doi:
10.1242/bio.2013
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Adams, D. S., Uzel, S. G., Akagi, J., Wlodkowic, D., Andreeva, V., Yelick, P. C.,
et al. (2016). Bioelectric signalling via potassium channels: a mechanism
for craniofacial dysmorphogenesis in KCNJ2-associated Andersen-Tawil
Syndrome. J. Physiol. 594, 3245–3270. doi: 10.1113/JP271930
Alloway, T. M. (1972). Retention of learning through metamorphosis in grain
beetle (Tenebrio-Molitor). Am. Zool. 12, 471–472.
Ameriks, K. (1976). Personal identity and memory transfer. Southern J. Phil. 14,
385–391. doi: 10.1111/j.2041-6962.1976.tb01295.x
Anderson, M. J., Sullivan, J. G., Horiuchi, T., Fuller, S. B., and Daniel, T. L. (2020). A
bio-hybrid odor-guided autonomous palm-sized air vehicle. Bioinspir. Biomim.
16:026002. doi: 10.1088/1748-3190/abbd81
Ando, N., and Kanzaki, R. (2020). Insect-machine hybrid robot. Curr. Opin. Insect.
Sci. 42, 61–69. doi: 10.1016/j.cois.2020.09.006
Ariazi, J., Benowitz, A., De Biasi, V., Den Boer, M. L., Cherqui, S., Cui,
H., et al. (2017). Tunneling nanotubes and gap junctions-their role in
long-range intercellular communication during development, health, and
disease conditions. Front. Mol. Neurosci. 10:333. doi: 10.3389/fnmol.2017.
Armstrong, J. D., de Belle, J. S., Wang, Z., and Kaiser, K. (1998). Metamorphosis of
the mushroom bodies; large-scale rearrangements of the neural substrates for
associative learning and memory in Drosophila. Learn. Mem. 5, 102–114.
Auletta, G. (2011). Teleonomy: the feedback circuit involving information and
thermodynamic processes. J. Mod. Phys. 2, 136–145. doi: 10.4236/jmp.2011.
Bach-y-Rita, P. (1981). Brain plasticity as a basis of the development of
rehabilitation procedures for hemiplegia. Scand. J. Rehabil. Med. 13, 73–83.
Bach-y-Rita, P., Collins, C. C., Saunders, F. A., White, B., and Scadden, L. (1969).
Vision substitution by tactile image projection. Nature 221, 963–964. doi: 10.
1038/221963a0
Badcock, P. B., Friston, K. J., and Ramstead, M. J. D. (2019). The hierarchically
mechanistic mind: a free-energy formulation of the human psyche. Phys. Life
Rev. 31:104–121. doi: 10.1016/j.plrev.2018.10.002
Bakkum, D. J., Gamblen, P. M., Ben-Ary, G., Chao, Z. C., and Potter,
S. M. (2007b). MEART: the semi-living artist. Front. Neurorobot. 1:5. doi:
10.3389/neuro.12.005.2007
Bakkum, D. J., Chao, Z. C., Gamblen, P., Ben-Ary, G., Shkolnik, A. G., DeMarse,
T. B., et al. (2007a). “Embodying cultured networks with a robotic drawing arm,”
in Proceedings of the Annual International Conference of the IEEE Engineering
in Medicine and Biology Society, Vol. 2007 (Lyon), 2996–2999. doi: 10.1109/
IEMBS.2007.4352959.
Balazsi, G., van Oudenaarden, A., and Collins, J. J. (2011). Cellular decision
making and biological noise: from microbes to mammals. Cell 144, 910–925.
doi: 10.1016/j.cell.2011.01.030
Baluška, F., and Levin, M. (2016). On having no head: cognition throughout
biological systems. Front. Psychol. 7:902. doi: 10.3389/fpsyg.2016.00902
Baluska, F., and Mancuso, S. (2012). Ion channels in plants: from bioelectricity, via
signaling, to behavioral actions. Plant Signal. Behav. 8:e23009. doi: 10.4161/psb.
Baluska, F., and Reber, A. (2019). Sentience and consciousness in single cells:
how the ﬁrst minds emerged in unicellular species. BioEssays 41:e1800229.
doi: 10.1002/bies.201800229
Baluska, F., Miller, W. B. Jr., and Reber, A. S. (2021). Biomolecular basis of cellular
consciousness via subcellular nanobrains. Int. J. Mol. Sci. 22:2545. doi: 10.3390/
ijms22052545
Baluska, F., Yokawa, K., Mancuso, S., and Baverstock, K. (2016). Understanding
of anesthesia - Why consciousness is essential for life and not based on
genes. Commun. Integr. Biol. 9:e1238118. doi: 10.1080/19420889.2016.123
Barilan, Y. M. (2003). One or two: an examination of the recent case of the
conjoined twins from Malta. J. Med. Philos. 28, 27–44. doi: 10.1076/jmep.28.
1.27.14176
Bates, E. (2015). Ion channels in development and cancer. Annu. Rev. Cell Dev.
Biol. 31, 231–247. doi: 10.1146/annurev-cellbio-100814-125338
Batterman, R. (2015). “Autonomy and scales,” in Front Collection, eds B.
Falkenburg and M. Morrison (Berlin: Springer), 115–135. doi: 10.1007/978-3662-43911-1_7
Batterman, R. W., and Rice, C. C. (2014). Minimal model explanations. Philos. Sci.
81, 349–376. doi: 10.1086/676677
Bayne, T., Brainard, D., Byrne, R. W., Chittka, L., Clayton, N., Heyes, C., et al.
(2019). What is cognition? Curr. Biol. 29, R608–R615. doi: 10.1016/j.cub.2019.
05.044
Bedecarrats, A., Chen, S., Pearce, K., Cai, D., and Glanzman, D. L. (2018).
RNA from trained aplysia can induce an epigenetic engram for long-term
sensitization in untrained aplysia. eNeuro 5:ENEURO.0038-18.2018. doi: 10.
1523/ENEURO.0038-18.2018
Beekman, M., and Latty, T. (2015). Brainless but multi-headed: decision making by
the acellular slime mould Physarum polycephalum. J. Mol. Biol. 427, 3734–3743.
doi: 10.1016/j.jmb.2015.07.007
Beer, R. D. (2014). The cognitive domain of a glider in the game of life. Artif. Life
20, 183–206. doi: 10.1162/ARTL_a_00125
Beer, R. D. (2015). Characterizing autopoiesis in the game of life. Artif. Life 21,
1–19. doi: 10.1162/ARTL_a_00143
Beer, R. D., and Williams, P. L. (2015). Information processing and dynamics in
minimally cognitive agents. Cogn. Sci. 39, 1–38. doi: 10.1111/cogs.12142
Beggs, J. M. (2008). The criticality hypothesis: how local cortical networks might
optimize information processing. Philos. Trans. A Math. Phys. Eng. Sci. 366,
329–343. doi: 10.1098/rsta.2007.2092
Belwaﬁ, K., Gannouni, S., and Aboalsamh, H. (2021). Embedded brain computer
interface: state-of-the-art in research. Sensors 21:4293. doi: 10.3390/s21134293
Berdahl, A. M., Kao, A. B., Flack, A., Westley, P. A. H., Codling, E. A., Couzin,
I. D., et al. (2018). Collective animal navigation and migratory culture: from
theoretical models to empirical evidence. Philos. Transac. R. Soc. B Biol. Sci.
373:20170009. doi: 10.1098/rstb.2017.0009
Birch, J., Ginsburg, S., and Jablonka, E. (2020). Unlimited associative learning and
the origins of consciousness: a primer and some predictions. Biol. Philos. 35:56.
doi: 10.1007/s10539-020-09772-0
Bisping, R., Oehlert, U., Reinauer, H., and Longo, N. (1971). Negative and positive
memory transfer through RNA in instrumentally conditioned goldﬁsh. Stud.
Psychol. 13, 181–190.
Biswas, S., Manicka, S., Hoel, E., and Levin, M. (2021). Gene regulatory networks
exhibit several kinds of memory: quantiﬁcation of memory in biological and
random transcriptional networks. iScience 24:102131. doi: 10.1016/j.isci.2021.
Blackiston, D. J., and Levin, M. (2013). Ectopic eyes outside the head in Xenopus
tadpoles provide sensory data for light-mediated learning. J. Exp. Biol. 216(Pt.
6), 1031–1040. doi: 10.1242/jeb.074963
Blackiston, D. J., Silva Casey, E., and Weiss, M. R. (2008). Retention of memory
through metamorphosis: can a moth remember what it learned as a caterpillar?
PLoS One 3:e1736. doi: 10.1371/journal.pone.0001736
Blackiston, D. J., Vien, K., and Levin, M. (2017). Serotonergic stimulation induces
nerve growth and promotes visual learning via posterior eye grafts in a
vertebrate model of induced sensory plasticity. NPJ Regen. Med. 2:8. doi: 10.
1038/s41536-017-0012-5
Blackiston, D., Adams, D. S., Lemire, J. M., Lobikin, M., and Levin, M. (2011).
Transmembrane potential of GlyCl-expressing instructor cells induces a
neoplastic-like conversion of melanocytes via a serotonergic pathway. Dis.
Models Mech. 4, 67–85. doi: 10.1242/dmm.005561
Blackiston, D., Lederer, E. K., Kriegman, S., Garnier, S., Bongard, J., and Levin, M.
(2021). A cellular platform for the development of synthetic living machines.
Sci. Robot 6:eabf1571. doi: 10.1126/scirobotics.abf1571
Blackiston, D., Shomrat, T., and Levin, M. (2015). The stability of memories
during brain remodeling: a perspective. Commun. Integr. Biol. 8:e1073424.
doi: 10.1080/19420889.2015.1073424
Bongard, J., and Levin, M. (2021). Living things are not (20th Century) machines:
updating mechanism metaphors in light of the modern science of machine
behavior. Front. Ecol. Evol. 9:650726. doi: 10.3389/fevo.2021.650726
Bongard, J., Zykov, V., and Lipson, H. (2006). Resilient machines through
continuous self-modeling. Science 314, 1118–1121. doi: 10.1126/science.
Bonzanni, M., Rouleau, N., Levin, M., and Kaplan, D. L. (2020). Optogenetically
induced cellular habituation in non-neuronal cells. PLoS One 15:e0227230.
doi: 10.1371/journal.pone.0227230
Bostrom, N. (2015). Superintelligence: Paths, Dangers, Strategies. Oxford: Oxford
University Press.
Boussard, A., Delescluse, J., Perez-Escudero, A., and Dussutour, A. (2019).
Memory inception and preservation in slime moulds: the quest for a common
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
mechanism. Philos. Trans. R. Soc. Lond. B Biol. Sci. 374:20180368. doi: 10.1098/
rstb.2018.0368
Boyle, E. A., Li, Y. I., and Pritchard, J. K. (2017). An expanded view of complex
traits: from polygenic to omnigenic. Cell 169, 1177–1186. doi: 10.1016/j.cell.
2017.05.038
Brooks, R. A. (1986). A robust layer control system for a mobile robot. IEEE J.
Robot. Automation 2, 14–23.
Brugger, P., Macas, E., and Ihlemann, J. (2002). Do sperm cells remember? Behav.
Brain Res. 136, 325–328. doi: 10.1016/s0166-4328(02)00127-4
Bubenik, A. (1966). Das Geweih. Hamburg: Paul Parey Verlag.
Bubenik, A. B., and Pavlansky, R. (1965). Trophic responses to trauma in growing
antlers. J. Exp. Zool. 159, 289–302. doi: 10.1002/jez.1401590302
Bucher, D., and Anderson, P. A. V. (2015). Evolution of the ﬁrst nervous systems –
what can we surmise? J. Exp. Biol. 218, 501–503. doi: 10.1242/jeb.111799
Busse, S. M., McMillen, P. T., and Levin, M. (2018). Cross-limb communication
during Xenopus hindlimb regenerative response: non-local bioelectric injury
signals. Development 145:dev164210. doi: 10.1242/dev.164210
Buznikov, G. A., Peterson, R. E., Nikitina, L. A., Bezuglov, V. V., and Lauder, J. M.
(2005). The pre-nervous serotonergic system of developing sea urchin embryos
and larvae: pharmacologic and immunocytochemical evidence. Neurochem.
Res. 30, 825–837. doi: 10.1007/s11064-005-6876-6
Calvo, P., and Friston, K. (2017). Predicting green: really radical (plant) predictive
processing. J. R. Soc. Interface 14:20170096. doi: 10.1098/rsif.2017.0096
Camley, B. A. (2018). Collective gradient sensing and chemotaxis: modeling and
recent developments. J. Phys. Condens. Matter 30:223001. doi: 10.1088/1361648X/aabd9f
Cartmill, M. (2017). Convergent? Minds? Some questions about mental evolution.
Interface Focus 7:20160125. doi: 10.1098/rsfs.2016.0125
Cebrià, F., Adell, T., and Saló, E. (2018). Rebuilding a planarian: from early
signaling to ﬁnal shape. Int. J. Dev. Biol. 62, 537–550. doi: 10.1387/ijdb.180042es
Cervera, J., Levin, M., and Mafe, S. (2020a). Bioelectrical coupling of single-cell
states in multicellular systems. J. Phys. Chem. Lett. 3234–3241. doi: 10.1021/acs.
jpclett.0c00641
Cervera, J., Meseguer, S., Levin, M., and Mafe, S. (2020b). Bioelectrical model of
head-tail patterning based on cell ion channels and intercellular gap junctions.
Bioelectrochemistry 132:107410. doi: 10.1016/j.bioelechem.2019.107410
Cervera, J., Pai, V. P., Levin, M., and Mafe, S. (2019b). From non-excitable singlecell to multicellular bioelectrical states supported by ion channels and gap
junction proteins: Electrical potentials as distributed controllers. Prog. Biophys.
Mol. Biol. 149, 39–53. doi: 10.1016/j.pbiomolbio.2019.06.004
Cervera, J., Manzanares, J. A., Mafe, S., and Levin, M. (2019a). Synchronization
of bioelectric oscillations in networks of nonexcitable cells: from single-cell
to multicellular states. J. Phys. Chem. B 123, 3924–3934. doi: 10.1021/acs.jpcb.
9b01717
Cervera, J., Pietak, A., Levin, M., and Mafe, S. (2018). Bioelectrical coupling
in multicellular domains regulated by gap junctions: a conceptual approach.
Bioelectrochemistry 123, 45–61. doi: 10.1016/j.bioelechem.2018.04.013
Chalmers, D. (1996). The Conscious Mind. New York, NY: Oxford University Press.
Chalmers, D. (2013). Panpsychism and panprotopsychism. Amherst Lecture
Philosophy 8.
Chamola, V., Vineet, A., Nayyar, A., and Hossain, E. (2020). Brain-computer
interface-based humanoid control: a review. Sensors 20:3620. doi: 10.3390/
s20133620
Chao, Z. C., Bakkum, D. J., and Potter, S. M. (2008). Shaping embodied neural
networks for adaptive goal-directed behavior. PLoS Comput. Biol. 4:e1000042.
doi: 10.1371/journal.pcbi.1000042
Chen, S., Cai, D., Pearce, K., Sun, P. Y., Roberts, A. C., and Glanzman, D. L. (2014).
Reinstatement of long-term memory following erasure of its behavioral and
synaptic expression in Aplysia. Elife 3:e03896. doi: 10.7554/eLife.03896
Chernet, B. T., Adams, D. S., Lobikin, M., and Levin, M. (2016). Use of genetically
encoded, light-gated ion translocators to control tumorigenesis. Oncotarget 7,
19575–19588. doi: 10.18632/oncotarget.8036
Chernet, B. T., and Levin, M. (2013a). Endogenous voltage potentials and the
microenvironment: bioelectric signals that reveal, induce and normalize cancer.
J. Clin. Exp. Oncol. Suppl. 1, S1-002. doi: 10.4172/2324-9110.S1-002
Chernet, B. T., and Levin, M. (2013b). Transmembrane voltage potential is an
essential cellular parameter for the detection and control of tumor development
in a Xenopus model. Dis. Models Mech. 6, 595–607. doi: 10.1242/dmm.010835
Chernet, B. T., and Levin, M. (2014). Transmembrane voltage potential of somatic
cells controls oncogene-mediated tumorigenesis at long-range. Oncotarget 5,
3287–3306. doi: 10.18632/oncotarget.1935
Chiu, L., and Gilbert, S. F. (2015). The birth of the holobiont: multi-species birthing
through mutual scaﬀolding and niche construction. Biosemiotics 8, 191–210.
doi: 10.1007/s12304-015-9232-5
Chow, R. L., Altmann, C. R., Lang, R. A., and Hemmati-Brivanlou, A. (1999).
Pax6 induces ectopic eyes in a vertebrate. Dev. Suppl. 126, 4213–4222. doi:
10.1242/dev.126.19.4213
Clark, A., and Chalmers, D. (1998). The extended mind. Analysis 58, 7–19.
Cohen-Karni, T., Langer, R., and Kohane, D. S. (2012). The smartest materials: the
future of nanoelectronics in medicine. ACS Nano 6, 6541–6545. doi: 10.1021/
nn302915s
Cook, N. D., Carvalho, G. B., and Damasio, A. (2014). From membrane excitability
to metazoan psychology. Trends Neurosci. 37, 698–705. doi: 10.1016/j.tins.2014.
07.011
Corning, W. C. (1966). Retention of a position discrimination after regeneration in
planarians. Psychanom. Sci. 5, 17–18.
Corning, W. C. (1967). Regeneration and Retention of Acquired Information.
Washington, DC: NASA. .
Couzin, I. (2007). Collective minds. Nature 445:715. doi: 10.1038/445715a
Couzin, I. D. (2009). Collective cognition in animal groups. Trends Cogn. Sci. 13,
36–43. doi: 10.1016/j.tics.2008.10.002
Couzin, I. D., Krause, J., James, R., Ruxton, G. D., and Franks, N. R. (2002).
Collective memory and spatial sorting in animal groups. J. Theor. Biol. 218,
1–11. doi: 10.1006/jtbi.2002.3065
Damasio, A. R. (2010). Self Comes to Mind : Constructing the Conscious Brain, 1st
Edn. New York, NY: Pantheon Books, 367.
Damasio, A., and Carvalho, G. B. (2013). The nature of feelings: evolutionary and
neurobiological origins. Nat. Rev. Neurosci. 14, 143–152. doi: 10.1038/nrn3403
Daniels, B. C., Ellison, C. J., Krakauer, D. C., and Flack, J. C. (2016). Quantifying
collectivity. Curr. Opin. Neurobiol. 37, 106–113. doi: 10.1016/j.conb.2016.01.
Danilov, Y., and Tyler, M. (2005). Brainport: an alternative input to the brain.
J. Integr. Neurosci. 4, 537–550. doi: 10.1142/s0219635205000914
DeMarse, T. B., and Dockendorf, K. P. (2005). “Adaptive ﬂight control with
living neuronal networks on microelectrode arrays,” in Proceedings. 2005
IEEE International Joint Conference on Neural Networks, (Montreal, QC),
1548–1551.
Demarse, T. B., Wagenaar, D. A., Blau, A. W., and Potter, S. M. (2001). The neurally
controlled animat: biological brains acting with simulated bodies. Auton. Robots
11, 305–310. doi: 10.1023/a:1012407611130
Dennett, D. C. (1987). The Intentional Stance. Cambridge, MA: MIT Press,
388.
Dennett, D. C. (1991). Consciousness Explained. Boston, MA: Little, Brown and Co.
Dennett, D. C. (2017). From Bacteria to Bach and Back : The Evolution of Minds,
First Edn. New York, NY: W.W. Norton & Company, 476.
Dexter, J. P., Prabakaran, S., and Gunawardena, J. (2019). A complex hierarchy
of avoidance behaviors in a single-cell eukaryote. Curr. Biol. 29, 4323–4329.e2.
doi: 10.1016/j.cub.2019.10.059
Di Paulo, E. A. (2000). “Homeostatic adaptation to inversion of the visual ﬁeld
and other sensorimotor disruptions,” in Proceedings of the SAB2000 Sixth
International Conference on Simulation of Adaptive Behavior : From Animals
to Animats, eds J.-A. Meyer, A. Berthoz, D. Floreano, H. L. Roitblat, and S. W.
Wilson, Paris.
di Primio, F., Muller, B. S., and Lengeler, J. W. (2000). “Minimal cognition
in unicellular organisms,” in Proceedings of the SAB2000 Sixth International
Conference on Simulation of Adaptive Behavior : From Animals to Animats, eds
J.-A. Meyer, A. Berthoz, D. Floreano, H. L. Roitblat, and S. W. Wilson (Paris).
Dietrich,
E.,
Fields,
C.,
Hoﬀman,
D.
D.,
and
Prentner,
R.
(2020).
Editorial:
epistemic
feelings:
phenomenology,
implementation,
and
role
in
cognition.
Front.
Psychol.
11:606046.
doi:
10.3389/fpsyg.2020.
Ding, S., O’Banion, C. P., Welfare, J. G., and Lawrence, D. S. (2018). Cellular
cyborgs: on the precipice of a drug delivery revolution. Cell Chem. Biol. 25,
648–658. doi: 10.1016/j.chembiol.2018.03.003
Dobzhansky, T. (1973). Nothing in biology makes sense except in the light of
evolution. Am. Biol. Teach. 35, 125–129.
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Dong, X., Kheiri, S., Lu, Y., Xu, Z., Zhen, M., and Liu, X. (2021). Toward a living soft
microrobot through optogenetic locomotion control of Caenorhabditis elegans.
Sci. Robot. 6:eabe3950. doi: 10.1126/scirobotics.abe3950
Dorahy, M. J., Brand, B. L., ¸Sar, V., Krüger, C., Stavropoulos, P., Martínez-Taboas,
A., et al. (2014). Dissociative identity disorder: an empirical overview. Aust.
N. Z. J. Psychiatry 48, 402–417. doi: 10.1177/0004867414527523
Downing, K. L. (2004). Development and the Baldwin eﬀect. Artif. Life 10, 39–63.
doi: 10.1162/106454604322875904
Dukas, R. (1998). Cognitive Ecology: The Evolutionary Ecology of Information
Processing and Decision Making. Chicago, IL: Chicago University Press.
Durant, F., Morokuma, J., Fields, C., Williams, K., Adams, D. S., and Levin, M.
(2017). Long-term, stochastic editing of regenerative anatomy via targeting
endogenous bioelectric gradients. Biophys. J. 112, 2231–2243. doi: 10.1016/j.bpj.
2017.04.011
Egeblad, M., Nakasone, E. S., and Werb, Z. (2010). Tumors as organs: complex
tissues that interface with the entire organism. Dev. Cell 18, 884–901. doi:
10.1016/j.devcel.2010.05.012
Elgart, M., Snir, O., and Soen, Y. (2015). Stress-mediated tuning of developmental
robustness and plasticity in ﬂies. Biochim. Biophys. Acta 1849, 462–466. doi:
10.1016/j.bbagrm.2014.08.004
Ellis, G. F. R. (2008). On the nature of causation in complex systems. Transac. R.
Soc. South Afr. 63, 69–84. doi: 10.1080/00359190809519211
Ellis, G. F. R., Noble, D., and O’Connor, T. (2012). Top-down causation: an
integrating theme within and across the sciences? Introduction. Interface Focus
2, 1–3. doi: 10.1098/Rsfs.2011.0110
Emmons-Bell, M., Durant, F., Hammelman, J., Bessonov, N., Volpert, V.,
Morokuma, J., et al. (2015). Gap junctional blockade stochastically induces
diﬀerent species-speciﬁc head anatomies in genetically wild-type girardia
dorotocephala ﬂatworms. Int. J. Mol. Sci. 16, 27865–27896. doi: 10.3390/
ijms161126065
Emmons-Bell, M., Durant, F., Tung, A., Pietak, A., Miller, K., Kane, A., et al.
(2019). Regenerative adaptation to electrochemical perturbation in planaria: a
molecular analysis of physiological plasticity. iScience 22, 147–165. doi: 10.1016/
j.isci.2019.11.014
Epstein, R. (1984). The principle of parsimony and some applications in
psychology. J. Mind. Behav. 5, 119–130.
Fankhauser, G. (1945a). Maintenance of normal structure in heteroploid
salamander larvae, through compensation of changes in cell size by adjustment
of cell number and cell shape. J. Exp. Zool. 100, 445–455. doi: 10.1002/jez.
Fankhauser, G. (1945b). The eﬀects of changes in chromosome number on
amphibian development. Q. Rev. Biol. 20, 20–78. doi: 10.2307/2809003
Feynman, R. (1942). The Principle of Least Action in Quantum Mechanics. Ph.D
Thesis. Princeton, NJ: Princeton University.
Fields, C., and Levin, M. (2017). Multiscale memory and bioelectric error
correction in the cytoplasm–cytoskeleton-membrane system. Wiley Interdiscip.
Rev. Syst. Biol. Med. 10, e1410. doi: 10.1002/wsbm.1410
Fields, C., Bischof, J., and Levin, M. (2020). Morphological coordination:
a common ancestral function unifying neural and non-neural signaling.
Physiology 35, 16–30. doi: 10.1152/physiol.00027.2019
Fields, C., Hoﬀman, D. D., Prakash, C., and Singh, M. (2017). Conscious agent
networks: formal analysis and application to cognition. 10. Cogn. Syst. Res.
Flack, J. C. (2017). Coarse-graining as a downward causation mechanism. Philos.
Trans. A Math. Phys. Eng. Sci. 375:20160338. doi: 10.1098/rsta.2016.0338
Fontes, P., Komori, J., Lopez, R., Marsh, W., and Lagasse, E. (2020). Development
of ectopic livers by hepatocyte transplantation into swine lymph nodes. Liver
Transpl. 26, 1629–1643. doi: 10.1002/lt.25872
Ford, B. J. (2017). Cellular intelligence: microphenomenology and the realities of
being. Prog. Biophys. Mol. Biol. 131, 273–287. doi: 10.1016/j.pbiomolbio.2017.
08.012
Forraz, N., Wright, K. E., Jurga, M., and McGuckin, C. P. (2013). Experimental
therapies for repair of the central nervous system: stem cells and tissue
engineering. J. Tissue Eng. Regen. Med. 7, 523–536. doi: 10.1002/term.552
Frank, S. A. (2018). Measurement invariance explains the universal law of
generalization for psychological perception. Proc. Natl. Acad. Sci. U.S.A. 115,
9803–9806. doi: 10.1073/pnas.1809787115
Frank, S. A. (2019a). Evolutionary design of regulatory control. I. A robust control
theory analysis of tradeoﬀs. J. Theor. Biol. 463, 121–137. doi: 10.1016/j.jtbi.2018.
12.023
Frank, S. A. (2019b). Evolutionary design of regulatory control. II. Robust errorcorrecting feedback increases genetic and phenotypic variability. J. Theor. Biol.
468, 72–81. doi: 10.1016/j.jtbi.2019.02.012
Friston, K. (2013). Life as we know it. J. R. Soc. Interface 10:20130475. doi: 10.1098/
rsif.2013.0475
Friston,
K.
J.,
Shiner,
T.,
FitzGerald,
T.,
Galea,
J.
M.,
Adams,
R.,
Brown, H., et al. (2012). Dopamine, aﬀordance and active inference.
PLoS
Comput.
Biol.
8:e1002327.
doi:
10.1371/journal.pcbi.100
Friston, K. J., Stephan, K. E., Montague, R., and Dolan, R. J. (2014). Computational
psychiatry: the brain as a phantastic organ. Lancet Psychiatry 1, 148–158. doi:
10.1016/S2215-0366(14)70275-5
Friston, K., and Ao, P. (2012). Free energy, value, and attractors. Comput. Math.
Methods Med. 2012:937860. doi: 10.1155/2012/937860
Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., and Pezzulo, G.
(2015b). Active inference and epistemic value. Cogn. Neurosci. 6, 187–214.
doi: 10.1080/17588928.2015.1020053
Friston, K., Levin, M., Sengupta, B., and Pezzulo, G. (2015a). Knowing one’s place:
a free-energy approach to pattern regulation. J. R. Soc. Interface 12:20141383.
doi: 10.1098/rsif.2014.1383
Friston, K., Schwartenbeck, P., Fitzgerald, T., Moutoussis, M., Behrens, T., and
Dolan, R. J. (2013). The anatomy of choice: active inference and agency. Front.
Hum. Neurosci. 7:598. doi: 10.3389/fnhum.2013.00598
Friston, K., Sengupta, B., and Auletta, G. (2014). Cognitive dynamics: from
attractors to active inference. Proc. IEEE 102, 427–445. doi: 10.1109/Jproc.2014.
Fukumoto, T., Kema, I. P., and Levin, M. (2005b). Serotonin signaling
is a very early step in patterning of the left-right axis in chick and
frog
embryos.
Curr.
Biol.
15,
794–803.
doi:
10.1016/j.cub.2005.03.
Fukumoto, T., Blakely, R., and Levin, M. (2005a). Serotonin transporter function is
an early step in left-right patterning in chick and frog embryos. Dev. Neurosci.
27, 349–363. doi: 10.1159/000088451
Gao, J., Liu, Y. Y., D’Souza, R. M., and Barabasi, A. L. (2014). Target
control of complex networks. Nat. Commun. 5:5415. doi: 10.1038/ncomms
Gawne, R., McKenna, K. Z., and Levin, M. (2020). Competitive and coordinative
interactions between body parts produce adaptive developmental outcomes.
BioEssays 42:e1900245. doi: 10.1002/bies.201900245
Gazzaniga, M. S. (1970). The Bisected Brain. New York, NY: Appleton-CenturyCrofts.
Georgiev, G., and Georgiev, I. (2002). The least action and the metric of
an organized system. Open Syst. Inf. Dyn. 9, 371–380. doi: 10.1023/A:
Gerhart, J., and Kirschner, M. (2007). The theory of facilitated variation. Proc. Natl.
Acad. Sci. U.S.A. 104(Suppl. 1), 8582–8589. doi: 10.1073/pnas.0701035104
Gershman, S. J., Balbi, P. E., Gallistel, C. R., and Gunawardena, J. (2021).
Reconsidering the evidence for learning in single cells. Elife 10:e61907. doi:
10.7554/eLife.61907.
Ghoneim, M. M., and Block, R. I. (1997). Learning and memory during general
anesthesia: an update. Anesthesiology 87, 387–410. doi: 10.1097/00000542199708000-00027
Ginsburg, S., and Jablonka, E. (2021). Evolutionary transitions in learning and
cognition. Philos. Trans. R. Soc. Lond. B Biol. Sci. 376:20190766. doi: 10.1098/
rstb.2019.0766
Giselbrecht, S., Rapp, B. E., and Niemeyer, C. M. (2013). The chemistry of cyborgs–
interfacing technical devices with organisms. Angew. Chem. Int. Ed. Engl. 52,
13942–13957. doi: 10.1002/anie.201307495
Godfrey-Smith, P. (2009). Darwinian Populations and Natural Selection. Oxford:
Oxford University Press, 207.
Goel, P., and Mehta, A. (2013). Learning theories reveal loss of pancreatic electrical
connectivity in diabetes as an adaptive response. PLoS One 8:e70366. doi: 10.
1371/journal.pone.0070366
Gottlieb,
J.,
Oudeyer,
P.
Y.,
Lopes,
M.,
and
Baranes,
A.
(2013).
Information-seeking, curiosity, and attention: computational and neural
mechanisms.
Trends
Cogn.
Sci.
17,
585–593.
doi:
10.1016/j.tics.2013.
09.001
Green, A. M., and Kalaska, J. F. (2011). Learning to move machines with the mind.
Trends Neurosci. 34, 61–75. doi: 10.1016/j.tins.2010.11.003
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Gremiaux, A., Yokawa, K., Mancuso, S., and Baluska, F. (2014). Plant anesthesia
supports similarities between animals and plants: claude Bernard’s forgotten
studies. Plant Signal. Behav. 9:e27886. doi: 10.4161/psb.27886
Grossberg, S. (1978). “Communication, memory, and development,” in Progress in
Theoretical Biology, Vol. 5, eds R. Rosen and F. Snell (New York, NY: Academic
Press).
Hadj-Chikh, L. Z., Steele, M. A., and Smallwood, P. D. (1996). Caching decisions
by grey squirrels: a test of the handling time and perishability hypotheses. Anim.
Behav. 52, 941–948. doi: 10.1006/anbe.1996.0242
Haigh, E. L. (1976). Vitalism, the soul, and sensibility: the physiology of
Theophile Bordeu. J. Hist. Med. Allied Sci. 31, 30–41. doi: 10.1093/jhmas/xxxi.
1.30
Hankey, A. (2015). A complexity basis for phenomenology: how information states
at criticality oﬀer a new approach to understanding experience of self, being and
time. Prog. Biophys. Mol. Biol. 119, 288–302. doi: 10.1016/j.pbiomolbio.2015.07.
Harman, G. (1973). Thought. New Jersey, NJ: Princeton.
Harris, M. P. (2021). Bioelectric signaling as a unique regulator of development and
regeneration. Development 148:dev180794. doi: 10.1242/dev.180794
Heams, T. (2012). Selection within organisms in the nineteenth century: Wilhelm
Roux’s complex legacy. Prog. Biophys. Mol. Biol. 110, 24–33. doi: 10.1016/j.
pbiomolbio.2012.04.004
Hernandez-Diaz, S., and Levin, M. (2014). Alteration of bioelectrically-controlled
processes in the embryo: a teratogenic mechanism for anticonvulsants. Reprod.
Toxicol. 47, 111–114. doi: 10.1016/j.reprotox.2014.04.008
Herrera-Delgado, E., Perez-Carrasco, R., Briscoe, J., and Sollich, P. (2018).
Memory
functions
reveal
structural
properties
of
gene
regulatory
networks. PLoS Comput. Biol. 14:e1006003. doi: 10.1371/journal.pcbi.100
Hoel, E. P., Albantakis, L., and Tononi, G. (2013). Quantifying causal emergence
shows that macro can beat micro. Proc. Natl. Acad. U.S.A. 110, 19790–19795.
doi: 10.1073/pnas.1314922110
Hoel, E. P., Albantakis, L., Marshall, W., and Tononi, G. (2016). Can the macro
beat the micro? Integrated information across spatiotemporal scales. Neurosci.
Conscious. 2016:niw012. doi: 10.1093/nc/niw012
Hoﬀman, D. D. (2017). “The interface theory of perception,” in Stevens’ Handbook
of Experimental Psychology and Cognitive Neuroscience, ed. J. T. Wixted
(Hoboken, NJ: Wiley).
Hoﬀman, D. D., Singh, M., and Prakash, C. (2015). The interface theory of
perception. Psychon. Bull. Rev. 22, 1480–1506. doi: 10.3758/s13423-015-0890-8
Hogenson, G. B. (2001). The Baldwin eﬀect: a neglected inﬂuence on C. G. Jung’s
evolutionary thinking. J. Anal. Psychol. 46, 591–611. doi: 10.1111/1465-5922.
Hopﬁeld, J. J. (1982). Neural networks and physical systems with emergent
collective computational abilities. Proc. Natl. Acad. Sci. U.S.A. 79, 2554–2558.
doi: 10.1073/pnas.79.8.2554
Hover, S., Foster, B., Barr, J. N., and Mankouri, J. (2017). Viral dependence on
cellular ion channels - an emerging anti-viral target? J. Gen. Virol. 98, 345–351.
doi: 10.1099/jgv.0.000712
Huang, H., Liu, S., and Kornberg, T. B. (2019). Glutamate signaling at cytoneme
synapses. Science 363, 948–955. doi: 10.1126/science.aat5053
Hughes, D. P., Araujo, J. P., Loreto, R. G., Quevillon, L., de Bekker, C., and
Evans, H. C. (2016). From so simple a beginning: the evolution of behavioral
manipulation by fungi. Adv Genet 94, 437–469. doi: 10.1016/bs.adgen.2016.01.
Humphries, J., Xiong, L., Liu, J., Prindle, A., Yuan, F., Arjes, H. A., et al. (2017).
Species-independent attraction to bioﬁlms through electrical signaling. Cell
168, 200–209.e12. doi: 10.1016/j.cell.2016.12.014
Hyun, I., Scharf-Deering, J. C., and Lunshof, J. E. (2020). Ethical issues related to
brain organoid research. Brain Res. 1732:146653. doi: 10.1016/j.brainres.2020.
Inoue, J. (2008). A simple Hopﬁeld-like cellular network model of plant
intelligence. Prog. Brain Res. 168, 169–174. doi: 10.1016/S0079-6123(07)68
014-5
James, W. (1890). Principles of Psychology. New York, NY: Henry Holt and Co.
Jekely, G., Keijzer, F., and Godfrey-Smith, P. (2015). An option space for early
neural evolution. Philos. Trans. R. Soc. Lond. B Biol. Sci. 370:20150181. doi:
10.1098/rstb.2015.0181
Jennings, H. S. (1906). Behavior of the Lower Organisms. New York, NY: The
Columbia university press, 366.
Kaila, V. R. I., and Annila, A. (2008). Natural selection for least action. Proc. R. Soc
A 464, 3055–3070. doi: 10.1098/Rspa.2008.0178
Kang, J. H., Manousaki, T., Franchini, P., Kneitz, S., Schartl, M., and Meyer, A.
(2015). Transcriptomics of two evolutionary novelties: how to make a spermtransfer organ out of an anal ﬁn and a sexually selected "sword" out of a caudal
ﬁn. Ecol. Evol. 5, 848–864. doi: 10.1002/ece3.1390
Karpas, E. D., Shklarsh, A., and Schneidman, E. (2017). Information socialtaxis and
eﬃcient collective behavior emerging in groups of information-seeking agents.
Proc. Natl. Acad. Sci. U.S.A. 114, 5589–5594. doi: 10.1073/pnas.1618055114
Keijzer, F. (2015). Moving and sensing without input and output: early nervous
systems and the origins of the animal sensorimotor organization. Biol. Philos.
30, 311–331. doi: 10.1007/s10539-015-9483-1
Keijzer, F., van Duijn, M., and Lyon, P. (2013). What nervous systems do: early
evolution, input-output, and the skin brain thesis. Adapt Behav. 21, 67–85.
doi: 10.1177/1059712312465330
Kelz, M. B., Garcia, P. S., Mashour, G. A., and Solt, K. (2019). Escape from oblivion:
neural mechanisms of emergence from general Anesthesia. Anesth. Analg. 128,
726–736. doi: 10.1213/ANE.0000000000004006
Koshland, D. E. (1983). The bacterium as a model neuron. Trends Neurosci. 6,
133–137. doi: 10.1016/0166-2236(83)90066-8
Kouvaris, K., Clune, J., Kounios, L., Brede, M., and Watson, R. A. (2017). How
evolution learns to generalise: using the principles of learning theory to
understand the evolution of developmental organisation. PLoS Comput. Biol.
13:e1005358. doi: 10.1371/journal.pcbi.1005358
Krakauer, D., Bertschinger, N., Olbrich, E., Ay, N., and Flack, J. C. (2014).
The Information Theory of Individuality. arXiv [Preprint]. Available online at:
https://arxiv.org/abs/1412.2447 (accessed February 2, 2022).
Kralj, J. M., Hochbaum, D. R., Douglass, A. D., and Cohen, A. E. (2011). Electrical
spiking in Escherichia coli probed with a ﬂuorescent voltage-indicating protein.
Science 333, 345–348. doi: 10.1126/science.1204763
Kriegman, S., Blackiston, D., Levin, M., and Bongard, J. (2020a). A scalable
pipeline for designing reconﬁgurable organisms. Proc. Natl. Acad. Sci. U.S.A.
117, 1853–1859. doi: 10.1073/pnas.1910837117
Kriegman, S., Nasab, A. M., Shah, D., Steele, H., Branin, G., Levin, M., et al. (2020b).
“Scalable sim-to-real transfer of soft robot designs,” in Proceedings of the 2020
3rd IEEE International Conference on Soft Robotics (Robosoft), (New Haven,
CT), 359–366.
Krotov, D. (2021). Hierarchical Associative Memory. Available online at:
https://ui.adsabs.harvard.edu/abs/2021arXiv210706446K (accessed July 01,
2021).
Kuchling, F., Friston, K., Georgiev, G., and Levin, M. (2020a). Integrating
variational approaches to pattern formation into a deeper physics: reply to
comments on "Morphogenesis as Bayesian inference: a variational approach to
pattern formation and manipulation in complex biological systems". Phys. Life
Rev. 33, 125–128. doi: 10.1016/j.plrev.2020.07.001
Kuchling, F., Friston, K., Georgiev, G., and Levin, M. (2020b). Morphogenesis as
Bayesian inference: a variational approach to pattern formation and control
in complex biological systems. Phys. Life Rev. 33, 88–108. doi: 10.1016/j.plrev.
2019.06.001
Lan, G., and Tu, Y. (2016). Information processing in bacteria: memory,
computation, and statistical physics: a key issues review. Rep. Prog. Phys.
79:052601. doi: 10.1088/0034-4885/79/5/052601
Langton,
C.
G.
(1995).
Artiﬁcial
Life:
An
Overview.
Cambridge,
MA:
MIT Press.
Larkin, J. W., Zhai, X., Kikuchi, K., Redford, S. E., Prindle, A., Liu, J., et al.
(2018). Signal percolation within a bacterial community. Cell Syst 7, 137–145.e3.
doi: 10.1016/j.cels.2018.06.005
Law, R., and Levin, M. (2015). Bioelectric memory: modeling resting potential
bistability in amphibian embryos and mammalian cells. Theor. Biol. Med. Model
12:22. doi: 10.1186/s12976-015-0019-9
Leithe, E., Sirnes, S., Omori, Y., and Rivedal, E. (2006). Downregulation of
gap junctions in cancer cells. Crit. Rev. Oncog. 12, 225–256. doi: 10.1615/
critrevoncog.v12.i3-4.30
Levin, M. (2011). The wisdom of the body: future techniques and approaches
to morphogenetic ﬁelds in regenerative medicine, developmental biology and
cancer. Regen. Med. 6, 667–673. doi: 10.2217/rme.11.69
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Levin, M. (2019). The computational boundary of a “Self”: developmental
bioelectricity drives multicellularity and scale-free cognition. Front. Psychol.
10:2688. doi: 10.3389/fpsyg.2019.02688
Levin, M. (2020). Life, death, and self: fundamental questions of primitive
cognition viewed through the lens of body plasticity and synthetic organisms.
Biochem. Biophys. Res. Commun. 564, 114–133. doi: 10.1016/j.bbrc.2020.1
0.077
Levin, M. (2021a). Bioelectric signaling: reprogrammable circuits underlying
embryogenesis, regeneration, and cancer. Cell 184, 1971–1989. doi: 10.1016/j.
cell.2021.02.034
Levin, M. (2021b). Bioelectrical approaches to cancer as a problem of the scaling
of the cellular self. Prog. Biophys. Mol. Biol. 165, 102–113. doi: 10.1016/j.
pbiomolbio.2021.04.007
Levin, M. (2022). TAME: technological approach to mind everywhere. PsyArXiv
[Preprint] doi: 10.31234/osf.io/t6e8p
Levin, M., and Dennett, D. C. (2020). Cognition All the Way Down. Melbourne:
Aeon.
Levin, M., and Martyniuk, C. J. (2018). The bioelectric code: an ancient
computational medium for dynamic control of growth and form. Biosystems
164, 76–93. doi: 10.1016/j.biosystems.2017.08.009
Levin, M., Bongard, J., and Lunshof, J. E. (2020). Applications and ethics of
computer-designed organisms. Nat. Rev. Mol. Cell Biol. 21, 655–656. doi: 10.
1038/s41580-020-00284-z
Levin, M., Buznikov, G. A., and Lauder, J. M. (2006). Of minds and embryos: leftright asymmetry and the serotonergic controls of pre-neural morphogenesis.
Dev. Neurosci. 28, 171–185. doi: 10.1159/000091915
Levin, M., Keijzer, F., Lyon, P., and Arendt, D. (2021). Uncovering cognitive
similarities and diﬀerences, conservation and innovation. Philos. Trans. R. Soc.
Lond. B Biol. Sci. 376:20200458. doi: 10.1098/rstb.2020.0458
Levin, M., Pezzulo, G., and Finkelstein, J. M. (2017). Endogenous bioelectric
signaling networks: exploiting voltage gradients for control of growth and form.
Annu. Rev. Biomed. Eng. 19, 353–387. doi: 10.1146/annurev-bioeng-071114040647
Li, W. L., Matsuhisa, N., Liu, Z. Y., Wang, M., Luo, Y. F., Cai, P. Q., et al. (2021).
An on-demand plant-based actuator created using conformable electrodes. Nat.
Electron. 4, 134–142. doi: 10.1038/s41928-020-00530-4
Liebeskind, B. J., Hillis, D. M., and Zakon, H. H. (2015). Convergence of ion
channel genome content in early animal evolution. Proc. Natl. Acad. Sci. U.S.A.
112, E846–E851. doi: 10.1073/pnas.1501195112
Liu, J., Martinez-Corral, R., Prindle, A., Lee, D. D., Larkin, J., GabaldaSagarra, M., et al. (2017). Coupling between distant bioﬁlms and emergence
of nutrient time-sharing. Science 356, 638–642. doi: 10.1126/science.aah
Liu, Y. Y., Slotine, J. J., and Barabasi, A. L. (2011). Controllability of complex
networks. Nature 473, 167–173. doi: 10.1038/nature10011
Lobo, D., Solano, M., Bubenik, G. A., and Levin, M. (2014). A linear-encoding
model explains the variability of the target morphology in regeneration. J. R.
Soc. 11:20130918. doi: 10.1098/rsif.2013.0918
Lowell, J., and Pollack, J. (eds) (2016). “Developmental encodings promote the
emergence of hierarchical modularity,” in Proceedings of the Artiﬁcial Life
Conference 2016, (Cancun: MIT Press).
Lyon, P. (2006). The biogenic approach to cognition. Cogn. Process. 7, 11–29.
doi: 10.1007/s10339-005-0016-8
Lyon, P., and Kuchling, F. (2021). Valuing what happens: a biogenic approach
to valence and (potentially) aﬀect. Philos. Trans. R. Soc. Lond. B Biol. Sci.
376:20190752. doi: 10.1098/rstb.2019.0752
Lyon, P., Keijzer, F., Arendt, D., and Levin, M. (2021). Reframing cognition: getting
down to biological basics. Philos. Trans. R. Soc. Lond. B Biol. Sci. 376:20190750.
doi: 10.1098/rstb.2019.0750
Man, K., and Damasio, A. (2019). Homeostasis and soft robotics in the design
of feeling machines. Nat. Mach. Intell. 1, 446–452. doi: 10.1038/s42256-0190103-7
Manicka, S., and Harvey, I. (eds) (2008). ‘Psychoanalysis’ of a Minimal Agent.
Artiﬁcial Life XI; Winchester, UK.
Manicka, S., and Levin, M. (2019b). The cognitive lens: a primer on conceptual
tools for analysing information processing in developmental and regenerative
morphogenesis. Philos. Trans. R. Soc. Lond. B Biol. Sci. 374:20180369. doi:
10.1098/rstb.2018.0369
Manicka, S., and Levin, M. (2019a). Modeling somatic computation with
non-neural bioelectric networks. Sci. Re.p 9:18612. doi: 10.1038/s41598-01954859-8
Mar, R. A., Kelley, W. M., Heatherton, T. F., and Macrae, C. N. (2007). Detecting
agency from the biological motion of veridical vs animated agents. Soc. Cogn.
Aﬀect. Neurosci. 2, 199–205. doi: 10.1093/scan/nsm011
Marr, D. (1982). Vision : A Computational Investigation into the Human
Representation and Processing of Visual Information. San Francisco, CA: W.H.
Freeman, 397.
Martinez-Corral, R., Liu, J., Prindle, A., Suel, G. M., and Garcia-Ojalvo, J. (2019).
Metabolic basis of brain-like electrical signalling in bacterial communities.
Philos. Trans. R. Soc. Lond. B Biol. Sci. 374:20180382. doi: 10.1098/rstb.2018.
Martinez-Corral, R., Liu, J., Suel, G. M., and Garcia-Ojalvo, J. (2018). Bistable
emergence of oscillations in growing Bacillus subtilis bioﬁlms. Proc. Natl. Acad.
Sci. U.S.A. 115, E8333–E8340. doi: 10.1073/pnas.1805004115
Maslow, A. H. (1943). A theory of human motivation. Psychol. Rev. 50, 370–396.
Maturana, H. R., and Varela, F. J. (1980). Autopoiesis and Cognition : The
Realization of the Living. Dordrecht: D. Reidel Pub. Co, 141.
Maynard Smith, J. (1999). Shaping Life : Genes, Embryos, and Evolution. New
Haven, CT: Yale University Press, 50.
Maynard Smith, J., and Szathmáry, E. (1995). The Major Transitions in Evolution.
New York, NY: W.H. Freeman Spektrum, 346.
Mayr, E. (1992). The idea of teleology. J. Hist. Ideas 53, 117–135. doi: 10.2307/
McConnell, J. V., and Shelby, J. M. (1970). “Memory transfer experiments in
invertebrates,” in Molecular Mechanisms in Memory and Learning, ed. G. Ungar
(New York, NY: Plenum Press), 71–101.
McConnell, J. V., Jacobson, A. L., and Kimble, D. P. (1959). The eﬀects of
regeneration upon retention of a conditioned response in the planarian.
J. Comp. Physiol. Psychol. 52, 1–5. doi: 10.1037/h0048028
McEvoy, J. W. (2009). Evolutionary game theory: lessons and limitations, a cancer
perspective. Br. J. Cancer 101, 2060–1;author reply 2062–3. doi: 10.1038/sj.bjc.
McEwen, B. S. (1998). Stress, adaptation, and disease. allostasis and allostatic
load. Ann. N.Y. Acad. Sci. 840, 33–44. doi: 10.1111/j.1749-6632.1998.tb09
546.x
McLaughlin, K. A., and Levin, M. (2018). Bioelectric signaling in regeneration:
mechanisms of ionic controls of growth and form. Dev. Biol. 433, 177–189.
doi: 10.1016/j.ydbio.2017.08.032
McNamara, H. M., Salegame, R., Tanoury, Z. A., Xu, H., Begum, S., Ortiz, G.,
et al. (2020). Bioelectrical domain walls in homogeneous tissues. Nat. Phys. 16,
357–364. doi: 10.1038/s41567-019-0765-4
McNamara, H. M., Salegame, R., Tanoury, Z. A., Xu, H., Begum, S., Ortiz, G., et al.
(2019). Bioelectrical signaling via domain wall migration. bioRxiv [Preprint]
570440. doi: 10.1101/570440
McNamara, H. M., Zhang, H., Werley, C. A., and Cohen, A. E. (2016).
Optically controlled oscillators in an engineered bioelectric tissue. Phys. Rev. X
6:031001.
McShea, D. W. (2012). Upper-directed systems: a new approach to teleology in
biology. Biol. Philos. 27, 663–684. doi: 10.1007/s10539-012-9326-2
McShea, D. W. (2013). Machine wanting. Stud. Hist. Philos. Biol. Biomed. Sci. 44(4
Pt. B), 679–687. doi: 10.1016/j.shpsc.2013.05.015
McShea, D. W. (2016). Freedom and purpose in biology. Stud. Hist. Philos. Biol.
Biomed. Sci. 58, 64–72. doi: 10.1016/j.shpsc.2015.12.002
Mehrali, M., Bagherifard, S., Akbari, M., Thakur, A., Mirani, B., Mehrali,
M., et al. (2018). Blending electronics with the human body: a pathway
toward a cybernetic future. Adv. Sci. 5:1700931. doi: 10.1002/advs.20170
Melo, D., Porto, A., Cheverud, J. M., and Marroig, G. (2016). Modularity: genes,
development and evolution. Annu. Rev. Ecol. Evol. Syst. 47, 463–486. doi: 10.
1146/annurev-ecolsys-121415-032409
Merritt, T., Hamidi, F., Alistar, M., and DeMenezes, M. (2020). Living media
interfaces: a multi-perspective analysis of biological materials for interaction.
Digit Creat. 31, 1–21. doi: 10.1080/14626268.2019.1707231
Michod, R. E., and Nedelcu, A. M. (2003). On the reorganization of ﬁtness during
evolutionary transitions in individuality. Integr. Comp. Biol. 43, 64–73. doi:
10.1093/icb/43.1.64
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Mikhalevich, I., and Powell, R. (eds) (2020). Minds without spines: evolutionarily
inclusive animal ethics. Anim. Sentience 29:2020.
Miller, S. D., and Triggiano, P. J. (1992). The psychophysiological investigation of
multiple personality disorder: review and update. Am. J. Clin. Hypn. 35, 47–61.
doi: 10.1080/00029157.1992.10402982
Montgomery, B. A. (2003). Consciousness and Personhood in Split-Brain Patients:
Dissertation. Oklahoma: The University of Oklahoma, 1–231.
Moran, Y., Barzilai, M. G., Liebeskind, B. J., and Zakon, H. H. (2015). Evolution of
voltage-gated ion channels at the emergence of Metazoa. J. Exp. Biol. 218(Pt. 4),
515–525. doi: 10.1242/jeb.110270
Morgan, C. L. (1903). “Other minds than ours,” in An Introduction to Comparative
Psychology, ed. W. Scott (London: Walter Scott Publishing), 36–59.
Morgan, T. H. (1904). The control of heteromorphosis in Planaria maculata. Arch.
Für Entw. Mech. 17, 683–694.
Muller, F. J., and Schuppert, A. (2011). Few inputs can reprogram biological
networks. Nature 478, E4;discussion E4–5. doi: 10.1038/nature10543
Nagel, E. (1979). Teleology Revisited and Other Essays in the Philosophy and History
of Science. New York, NY: Columbia University Press, 352.
Nagel, T. (1971). Brain bisection and the unity of consciousness. Synthese 22,
396–413.
Nagel, T. (1974). What is it like to be a bat? Philos. Rev. 83, 435–450. doi: 10.1111/
1468-5930.00141
Nasuto, S. J., and Hayashi, Y. (2016). Anticipation: beyond synthetic biology and
cognitive robotics. Biosystems 148, 22–31. doi: 10.1016/j.biosystems.2016.07.
Nicolis, S. C., Zabzina, N., Latty, T., and Sumpter, D. J. (2011). Collective
irrationality and positive feedback. PLoS One 6:e18901. doi: 10.1371/journal.
pone.0018901
Noble, D. (2010). Biophysics and systems biology. Philos. Trans. A Math. Phys. Eng.
Sci. 368, 1125–1139. doi: 10.1098/rsta.2009.0245
Noble, D. (2011). The aims of systems biology: between molecules and organisms.
Pharmacopsychiatry 44(Suppl. 1), S9–S14. doi: 10.1055/s-0031-1271703
Noble, D. (2012). A theory of biological relativity: no privileged level of causation.
Interface Focus 2, 55–64. doi: 10.1098/Rsfs.2011.0067
Nogi, T., and Levin, M. (2005). Characterization of innexin gene expression and
functional roles of gap-junctional communication in planarian regeneration.
Dev. Biol. 287, 314–335. doi: 10.1016/j.ydbio.2005.09.002
Norman, T. M., Lord, N. D., Paulsson, J., and Losick, R. (2013). Memory and
modularity in cell-fate decision making. Nature 503, 481–486. doi: 10.1038/
nature12804
Ogborn, J., Hanc, J., and Taylor, E. (eds) (2006). “Action on stage: historical
introduction,” in Proceedings of the GIREP Conference, Modeling in Physics and
Physics Education, (Amsterdam: AMSTEL Institute).
Orive, G., Taebnia, N., and Dolatshahi-Pirouz, A. A. (2020). New era for cyborg
science is emerging: the promise of cyborganic beings. Adv. Healthc. Mater.
9:e1901023. doi: 10.1002/adhm.201901023
Otopalik, A. G., Sutton, A. C., Banghart, M., and Marder, E. (2017). When complex
neuronal structures may not matter. Elife 6:e23508. doi: 10.7554/eLife.23508
Oudeyer, P. Y., and Kaplan, F. (2007). What is intrinsic motivation? A typology of
computational approaches. Front. Neurorobot. 1:6. doi: 10.3389/neuro.12.006.
Oudeyer, P.-Y., and Kaplan, F. (2013). How Can We Deﬁne Intrinsic Motivation.
Available online at: http://www.pyoudeyer.com/epirob08OudeyerKaplan.pdf
Oviedo, N. J., Morokuma, J., Walentek, P., Kema, I. P., Gu, M. B., Ahn, J. M.,
et al. (2010). Long-range neural and gap junction protein-mediated cues control
polarity during planarian regeneration. Dev. Biol. 339, 188–199. doi: 10.1016/j.
ydbio.2009.12.012
Pacheco, J. M., Santos, F. C., and Dingli, D. (2014). The ecology of cancer from an
evolutionary game theory perspective. Interface Focus 4:20140019. doi: 10.1098/
rsfs.2014.0019
Pai, V. P., Aw, S., Shomrat, T., Lemire, J. M., and Levin, M. (2012).
Transmembrane
voltage
potential
controls
embryonic
eye
patterning
in
Xenopus
laevis.
Development
139,
313–323.
doi:
10.1242/dev.07
Pai, V. P., Cervera, J., Mafe, S., Willocq, V., Lederer, E. K., and Levin, M.
(2020). HCN2 channel-induced rescue of brain teratogenesis via local and longrange bioelectric repair. Front. Cell Neurosci. 14:136. doi: 10.3389/fncel.2020.
Pai, V. P., Pietak, A., Willocq, V., Ye, B., Shi, N. Q., and Levin, M. (2018).
HCN2 rescues brain defects by enforcing endogenous voltage pre-patterns. Nat.
Commun. 9:998. doi: 10.1038/s41467-018-03334-5
Pai, V. P., Willocq, V., Pitcairn, E. J., Lemire, J. M., Pare, J. F., Shi, N. Q.,
et al. (2017). HCN4 ion channel function is required for early events that
regulate anatomical left-right patterning in a nodal and lefty asymmetric gene
expression-independent manner. Biol. Open 6, 1445–1457. doi: 10.1242/bio.
Peters, A., McEwen, B. S., and Friston, K. (2017). Uncertainty and stress: why
it causes diseases and how it is mastered by the brain. Prog. Neurobiol. 156,
164–188. doi: 10.1016/j.pneurobio.2017.05.004
Pezzulo, G., and Levin, M. (2015). Re-membering the body: applications of
computational neuroscience to the top-down control of regeneration of limbs
and other complex organs. Integr. Biol. 7, 1487–1517. doi: 10.1039/c5ib00221d
Pezzulo, G., and Levin, M. (2016). Top-down models in biology: explanation and
control of complex living systems above the molecular level. J. R. Soc. Interface
13:20160555. doi: 10.1098/rsif.2016.0555
Pezzulo, G., Lapalme, J., Durant, F., and Levin, M. (2021). Bistability of somatic
pattern memories: stochastic outcomes in bioelectric circuits underlying
regeneration. Philos. Proc. R. Soc. B 376:20190765. doi: 10.1098/rstb.2019.0765
Pietak, A., and Levin, M. (2017). Bioelectric gene and reaction networks:
computational modelling of genetic, biochemical and bioelectrical dynamics in
pattern regulation. J. R. Soc. Interface 14:20170425. doi: 10.1098/rsif.2017.0425
Pietak, A., and Levin, M. (2018). Bioelectrical control of positional information
in development and regeneration: a review of conceptual and computational
advances. Prog. Biophys. Mol. Biol. 137, 52–68. doi: 10.1016/j.pbiomolbio.2018.
03.008
Pietsch, P., and Schneider, C. W. (1969). Brain transplantation in salamanders -
an approach to memory transfer. Brain Res. 14, 707–715. doi: 10.1016/00068993(69)90210-8
Pinet, K., Deolankar, M., Leung, B., and McLaughlin, K. A. (2019). Adaptive
correction of craniofacial defects in pre-metamorphic Xenopus laevis tadpoles
involves thyroid hormone-independent tissue remodeling. Development
146:dev175893. doi: 10.1242/dev.175893
Pio-Lopez, L. (2021). The rise of the biocyborg: synthetic biology, artiﬁcial
chimerism and human enhancement. N. Genet. Soc. 40, 599–619. doi: 10.1080/
14636778.2021.2007064
Pitcairn, E., Harris, H., Epiney, J., Pai, V. P., Lemire, J. M., Ye, B., et al.
(2017). Coordinating heart morphogenesis: a novel role for Hyperpolarizationactivated cyclic nucleotide-gated (HCN) channels during cardiogenesis in
Xenopus laevis. Commun. Integr. Biol. 10:e1309488. doi: 10.1080/19420889.
2017.1309488
Pittendrigh, C. S. (1958). “Adaptation, natural selection, and behavior,” in Behavior
and Evolution, eds A. Roe and G. G. Simpson (New Haven, CT: Yale University
Press), 390–416.
Posfai, M., Gao, J., Cornelius, S. P., Barabasi, A. L., and D’Souza, R. M. (2016).
Controllability of multiplex, multi-time-scale networks. Phys. Rev. E 94:032316.
doi: 10.1103/PhysRevE.94.032316
Potter, S. M., Wagenaar, D. A., and DeMarse, T. B. (eds) (2005). “Closing the
loop: stimulation feedback systems for embodied MEA cultures,” in Advances
in Network Electrophysiology Using Multi-Electrode Arrays, eds M. Taketani and
M. Baudry (New York, NY: Springer). doi: 10.3389/neuro.12.005.2007
Potter, S. M., Wagenaar, D. A., Madhavan, R., and DeMarse, T. B. (2003). “Longterm bidirectional neuron interfaces for robotic control, and in vitro learning
studies,” in Annual International Conference of the IEEE Engineering in Medicine
and Biology Society, Vol. 25, (Piscataway, NJ: IEEE), 3690–3693. doi: 10.1109/
Iembs.2003.1280959
Power, D. A., Watson, R. A., Szathmary, E., Mills, R., Powers, S. T., Doncaster,
C. P., et al. (2015). What can ecosystems learn? Expanding evolutionary
ecology with learning theory. Biol. Direct. 10:69. doi: 10.1186/s13062-015-0
094-1
Prakash, C., Fields, C., Hoﬀman, D. D., Prentner, R., and Singh, M. (2020). Fact,
ﬁction, and ﬁtness. Entropy 22:514. doi: 10.3390/e22050514
Prentner, R. (2019). Consciousness and topologically structured phenomenal
spaces. Conscious. Cogn. 70, 25–38. doi: 10.1016/j.concog.2019.02.002
Prindle, A., Liu, J., Asally, M., Ly, S., Garcia-Ojalvo, J., and Suel, G. M. (2015).
Ion channels enable electrical communication in bacterial communities. Nature
527, 59–63. doi: 10.1038/nature15709
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Prinz, A. A., Bucher, D., and Marder, E. (2004). Similar network activity from
disparate circuit parameters. Nat. Neurosci. 7, 1345–1352. doi: 10.1038/nn
Ptito, M., Moesgaard, S. M., Gjedde, A., and Kupers, R. (2005). Cross-modal
plasticity revealed by electrotactile stimulation of the tongue in the congenitally
blind. Brain 128(Pt. 3), 606–614. doi: 10.1093/brain/awh380
Qadri, M. A., and Cook, R. G. (2017). Pigeons and humans use action and pose
information to categorize complex human behaviors. Vision Res. 131, 16–25.
doi: 10.1016/j.visres.2016.09.011
Queller, D. C., and Strassmann, J. E. (2009). Beyond society: the evolution of
organismality. Philos Trans R Soc Lond B Biol Sci 364, 3143–3155. doi: 10.1098/
rstb.2009.0095
Rabinovich, M. I., Huerta, R., Varona, P., and Afraimovich, V. S. (2008). Transient
cognitive dynamics, metastability, and decision making. PLoS Comput. Biol.
4:e1000072. doi: 10.1371/journal.pcbi.1000072
Raby, C. R., and Clayton, N. S. (2009). Prospective cognition in animals. Behav.
Process. 80, 314–324. doi: 10.1016/j.beproc.2008.12.005
Raible, D. W., and Ragland, J. W. (2005). Reiterated Wnt and BMP signals in neural
crest development. Semin. Cell Dev. Biol. 16, 673–682. doi: 10.1016/j.semcdb.
2005.06.008
Ramstead, M. J. D., Constant, A., Badcock, P. B., and Friston, K. J. (2019).
Variational ecology and the physics of sentient systems. Phys. Life Rev. 31,
188–205. doi: 10.1016/j.plrev.2018.12.002
Ray, S. (1999). Survival of olfactory memory through metamorphosis in the
ﬂy Musca domestica. Neurosci. Lett. 259, 37–40. doi: 10.1016/s0304-3940(98)
00892-1
Reber, A. S., and Baluska, F. (2021). Cognition in some surprising places. Biochem.
Biophys. Res. Commun. 564, 150–157. doi: 10.1016/j.bbrc.2020.08.115
Reger, B. D., Fleming, K. M., Sanguineti, V., Alford, S., and Mussa-Ivaldi,
F. A. (2000). Connecting brains to robots: an artiﬁcial body for studying the
computational properties of neural tissues. Artif. Life 6, 307–324. doi: 10.1162/
Reid, C. R., Beekman, M., Latty, T., and Dussutour, A. (2013). Amoeboid organism
uses extracellular secretions to make smart foraging decisions. Behav. Ecol. 24,
812–818. doi: 10.1093/beheco/art032
Reid, C. R., Latty, T., Dussutour, A., and Beekman, M. (2012). Slime mold uses
an externalized spatial "memory" to navigate in complex environments. Proce.
Natl. Acad. Sci. U.S.A. 109, 17490–17494. doi: 10.1073/pnas.1215037109
Reinders, A. A. T. S., Chalavi, S., Schlumpf, Y. R., Vissia, E. M., Nijenhuis,
E. R. S., Jäncke, L., et al. (2018). Neurodevelopmental origins of abnormal
cortical morphology in dissociative identity disorder. Acta Psychiatr. Scand. 137,
157–170. doi: 10.1111/acps.12839
Reinders, A. A. T. S., Marquand, A. F., Schlumpf, Y. R., Chalavi, S., Vissia, E. M.,
Nijenhuis, E. R. S., et al. (2019). Aiding the diagnosis of dissociative identity
disorder: pattern recognition study of brain biomarkers. Br. J. Psychiatry 215,
536–544. doi: 10.1192/bjp.2018.255
Ricotti, L., Trimmer, B., Feinberg, A. W., Raman, R., Parker, K. K., Bashir, R., et al.
(2017). Biohybrid actuators for robotics: A review of devices actuated by living
cells. Sci Robot. 2:eaaq0495. doi: 10.1126/scirobotics.aaq0495
Robinson, G. E., and Barron, A. B. (2017). Epigenetics and the evolution of
instincts. Science 356, 26–27. doi: 10.1126/science.aam6142
Robinson, K. R., and Messerli, M. A. (1996). “Electric embryos: the embryonic
epithelium
as
a
generator
of
developmental
information,”
in
Nerve
Growth and Guidance, ed. C. D. McCaig (London: Portland Press),
131–150.
Rolston, J. D., Gross, R. E., and Potter, S. M. (2009a). A low-cost multielectrode
system for data acquisition enabling real-time closed-loop processing with rapid
recovery from stimulation artifacts. Front. Neuroeng. 2:12. doi: 10.3389/neuro.
16.012.2009
Rolston, J. D., Gross, R. E., and Potter, S. M. (2009b). “NeuroRighter: closed-loop
multielectrode stimulation and recording for freely moving animals and cell
cultures,” in Proceedings of the Annual International Conference of the IEEE
Engineering in Medicine and Biology Society IEEE Engineering in Medicine
and Biology Society Conference, Vol. 2009, (Minneapolis, MN), 6489–6492.
doi: 10.1109/IEMBS.2009.5333589.
Rosen, R. (1973). Dynamical realization of (M,R)-Systems. Bull. Math. Biol. 35, 1–9.
doi: 10.1007/BF02558788
Rosen, R. (1979). Anticipatory systems in retrospect and prospect. Gen. Syst. 24,
11–23.
Rosen, R. (1985). Anticipatory Systems : Philosophical, Mathematical, and
Methodological Foundations, 1st Edn. New York, NY: Pergamon Press, 436.
Rosenblueth, A., Wiener, N., and Bigelow, J. (1943). Behavior, purpose, and
teleology. Philos. Sci. 10, 18–24.
Rosser, A., and Svendsen, C. N. (2014). Stem cells for cell replacement therapy:
a therapeutic strategy for HD? Mov. Disord. 29, 1446–1454. doi: 10.1002/mds.
Ruud,
G.
(1929).
Heteronom-orthotopische
transplantationen
von
extremitätenanlagen bei axolotlembryonen. Wilhelm. Roux Arch. Entwickl.
Mech. Org. 118, 308–351.
Sadoc, J. F., and Mosseri, R. (2007). Geometrical Frustration. Cambridge, MA:
Cambridge University Press.
Saha, D., Mehta, D., Altan, E., Chandak, R., Traner, M., Lo, R., et al. (2020).
Explosive sensing with insect-based biorobots. Biosens. Bioelectronics: X
6:100050. doi: 10.1016/j.biosx.2020.100050
Saniova, B., Drobny, M., and Sulaj, M. (2009). Delirium and postoperative
cognitive dysfunction after general anesthesia. Med. Sci. Monit. 15, CS81–CS87.
´S¯antideva Bstan ’dzin rgya m, and Comité de traduction Padmakara (2006). The
Way of the Bodhisattva : a Translation of the Bodhichary¯avat¯ara, 2nd Edn.
Boston, MA: Shambhala, 222. Distributed in the United States by Random
House.
Sasaki,
T.,
and Biro, D.
(2017). Cumulative culture can emerge
from
collective intelligence in animal groups. Nat. Commun. 8:15049. doi: 10.1038/
ncomms15049
Schlosser, G. (1998). Self-re-production and functionality - A systems-theoretical
approach to teleological explanation. Synthese 116, 303–354. doi: 10.1023/A:
Schlosser, G., and Wagner, G. P. (2004). Modularity in Development and Evolution.
Chicago, IL: University of Chicago Press, 600.
Schreier, H. I., Soen, Y., and Brenner, N. (2017). Exploratory adaptation in large
random networks. Nat. Commun. 8:14826. doi: 10.1038/ncomms14826
Schulkin, J., and Sterling, P. (2019). Allostasis: a brain-centered, predictive mode of
physiological regulation. Trends Neurosci. 42, 740–752. doi: 10.1016/j.tins.2019.
07.010
Schwitzgebel, E. (2015). If materialism is true, the United States is probably
conscious. Philos. Stud. 172, 1697–1721. doi: 10.1007/s11098-014-0387-8
Serre, N. B. C., Kralik, D., Yun, P., Slouka, Z., Shabala, S., and Fendrych, M.
(2021). AFB1 controls rapid auxin signalling through membrane depolarization
in Arabidopsis thaliana root. Nat. Plants 7, 1229–1238. doi: 10.1038/s41477021-00969-z
Sheiman, I. M., and Tiras, K. L. (1996). “Memory and morphogenesis in planaria
and beetle,” in Russian Contributions to Invertebrate Behavior, eds C. I.
Abramson, Z. P. Shuranova, and Y. M. Burmistrov (Westport, CT: Praeger),
43–76.
Shimbo, K., Brassard, D. L., Lamb, R. A., and Pinto, L. H. (1996). Ion selectivity and
activation of the M2 ion channel of inﬂuenza virus. Biophys. J. 70, 1335–1346.
doi: 10.1016/S0006-3495(96)79690-X
Shoemaker, S. S. (1959). Personal identity and memory. J. Philosophy 56, 868–882.
doi: 10.2307/2022317
Shomrat,
T.,
and
Levin,
M.
(2013).
An
automated
training
paradigm
reveals long-term memory in planarians and its persistence through
head regeneration. J. Exp. Biol. 216(Pt. 20), 3799–3810. doi: 10.1242/jeb.
Sims, M. (2020). How to count biological minds: symbiosis, the free energy
principle, and reciprocal multiscale integration. Synthese 199, 2157–2179. doi:
10.1007/s11229-020-02876-w
Smith, B. P., and Litchﬁeld, C. A. (2010). How well do dingoes, Canis dingo,
perform on the detour task? Anim. Behav. 80, 155–162. doi: 10.1016/j.anbehav.
2010.04.017
Soen, Y., Knafo, M., and Elgart, M. (2015). A principle of organization which
facilitates broad Lamarckian-like adaptations by improvisation. Biol. Direct.
10:68. doi: 10.1186/s13062-015-0097-y
Sole, R., Moses, M., and Forrest, S. (2019). Liquid brains, solid brains. Philos.
Trans. R. Soc. Lond. B Biol. Sci. 374:20190040. doi: 10.1098/rstb.2019.
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
Sordillo, A., and Bargmann, C. I. (2021). Behavioral control by depolarized and
hyperpolarized states of an integrating neuron. Elife 10:e67723. doi: 10.7554/
eLife.67723
Spemann, H. (1967). Embryonic Development and Induction. New Haven, CT: Yale
University Press.
Spencer, G. J., and Genever, P. G. (2003). Long-term potentiation in bone–a role
for glutamate in strain-induced cellular memory? BMC Cell Biol. 4:9. doi: 10.
1186/1471-2121-4-9
Srivastava, P., Kane, A., Harrison, C., and Levin, M. A. (2020). Meta-analysis of
bioelectric data in cancer, embryogenesis, and regeneration. Bioelectricity 3,
42–67. doi: 10.1089/bioe.2019.0034
Stockwell, S. R., Landry, C. R., and Rifkin, S. A. (2015). The yeast galactose
network as a quantitative model for cellular memory. Mol. Biosyst. 11, 28–37.
doi: 10.1039/c4mb00448e
Stratford, J. P., Edwards, C. L. A., Ghanshyam, M. J., Malyshev, D., Delise, M. A.,
Hayashi, Y., et al. (2019). Electrically induced bacterial membrane-potential
dynamics correspond to cellular proliferation capacity. Proc. Natl. Acad. Sci.
U.S.A. 116, 9552–9557. doi: 10.1073/pnas.1901788116
Sullivan, K. G., Emmons-Bell, M., and Levin, M. (2016). Physiological
inputs
regulate
species-speciﬁc
anatomy
during
embryogenesis
and
regeneration. Commun. Integr. Biol. 9:e1192733. doi: 10.1080/19420889.2016.
Szilagyi, A., Szabo, P., Santos, M., and Szathmary, E. (2020). Phenotypes to
remember: evolutionary developmental memory capacity and robustness. PLoS
Comput. Biol. 16:e1008425. doi: 10.1371/journal.pcbi.1008425
Tamori, Y., and Deng, W. M. (2014). Compensatory cellular hypertrophy: the other
strategy for tissue homeostasis. Trends Cell Biol. 24, 230–237. doi: 10.1016/j.tcb.
2013.10.005
Tanna, T., and Sachan, V. (2014). Mesenchymal stem cells: potential in treatment
of neurodegenerative diseases. Curr. Stem Cell Res. Ther. 9, 513–521. doi: 10.
2174/1574888x09666140923101110
Taormina, R. J., and Gao, J. H. (2013). Maslow and the motivation hierarchy:
measuring satisfaction of the needs. Am. J. Psychol. 126, 155–177. doi: 10.5406/
amerjpsyc.126.2.0155
Thierry, B., Theraulaz, G., Gautier, J. Y., and Stiegler, B. (1995). Joint memory.
Behav. Process. 35, 127–140. doi: 10.1016/0376-6357(95)00039-9
Thornton, C. (2017). Predictive processing simpliﬁed: the infotropic machine.
Brain Cogn. 112, 13–24. doi: 10.1016/j.bandc.2016.03.004
Timsit, Y., and Gregoire, S. P. (2021). Towards the idea of molecular brains. Int. J.
Mol. Sci. 22:11868. doi: 10.3390/ijms222111868
Trewavas, A. J., and Baluska, F. (2011). The ubiquity of consciousness. EMBO Rep.
12, 1221–1225. doi: 10.1038/embor.2011.218
Tseng, A. S., Beane, W. S., Lemire, J. M., Masi, A., and Levin, M. (2010). Induction
of vertebrate regeneration by a transient sodium current. J. Neurosci. 30,
13192–13200. doi: 10.1523/JNEUROSCI.3315-10.2010
Tseng, A., and Levin, M. (2013). Cracking the bioelectric code: Probing endogenous
ionic controls of pattern formation. Commun. Integr. Biol. 6:e22595. doi: 10.
4161/cib.22595
Tsuda, S., Artmann, S., and Zauner, K.-P. (2009). “The phi-bot: a robot controlled
by a slime mould,” in Artiﬁcial Life Models in Hardware, eds A. Adamatzky and
M. Komosinski (London: Springer), 213–232.
Tully, T., Cambiazo, V., and Kruse, L. (1994). Memory through metamorphosis
in normal and mutant Drosophila. J. Neurosci. 14, 68–74. doi: 10.1523/
JNEUROSCI.14-01-00068.1994
Turner, C. H., Robling, A. G., Duncan, R. L., and Burr, D. B. (2002). Do bone cells
behave like a neuronal network? Calcif. Tissue Int. 70, 435–442. doi: 10.1007/
s00223-001-1024-z
Turner, J. S. (2000). The Extended Organism : The Physiology of Animal-Built
Structures. Cambridge, MA: Harvard University Press, 235.
Turner, J. S. (2019). Homeostasis as a fundamental principle for a coherent theory
of brains. Philos. Trans. R. Soc. Lond. B Biol. Sci. 374:20180373. doi: 10.1098/
rstb.2018.0373
Tweedy, L., and Insall, R. H. (2020). Self-generated gradients yield exceptionally
robust steering cues. Front. Cell Dev. Biol. 8:133. doi: 10.3389/fcell.2020.00133
Tweedy, L., Thomason, P. A., Paschke, P. I., Martin, K., Machesky, L. M., Zagnoni,
M., et al. (2020). Seeing around corners: cells solve mazes and respond at
a distance using attractant breakdown. Science 369:eaay9792. doi: 10.1126/
science.aay9792
Urrios, A., Macia, J., Manzoni, R., Conde, N., Bonforti, A., de Nadal, E., et al.
(2016). A synthetic multicellular memory device. ACS Synth. Biol. 5, 862–873.
doi: 10.1021/acssynbio.5b00252
Valentini, G., Moore, D. G., Hanson, J. R., Pavlic, T. P., Pratt, S. C., and Walker,
S. I. (2018). “Transfer of information in collective decisions by artiﬁcial agents,”
in Proceedings of the the 2018 Conference on Artiﬁcial life: A Hybrid of the
European Conference on Artiﬁcial life (ECAL) and the International Conference
on the Synthesis and Simulation of Living Systems (ALIFE), (Cambridge, MA:
MIT Press), 641–648. doi: 10.1371/journal.pone.0168876
Van Baalen, M. (2013). “The unit of adaptation, the emergence of individuality,
and the loss of sovereignty,” in Vienna Ser Theor Bio, ed. F. B. A. P. Huneman
(Cambridge, MA: MIT Press), 117–140.
Vandenberg, L. N., Adams, D. S., and Levin, M. (2012). Normalized shape and
location of perturbed craniofacial structures in the Xenopus tadpole reveal
an innate ability to achieve correct morphology. Dev. Dyn. 241, 863–878. doi:
10.1002/dvdy.23770
Vergassola, M., Villermaux, E., and Shraiman, B. I. (2007). ‘Infotaxis’ as a strategy
for searching without gradients. Nature 445, 406–409. doi: 10.1038/nature05464
Versteeg, E. J., Fernandes, T., Guzzo, M. M., Laberge, F., Middel, T., Ridgway, M.,
et al. (2021). Seasonal variation of behavior and brain size in a freshwater ﬁsh.
Ecol. Evol. 11, 14950–14959. doi: 10.1002/ece3.8179
Vetere, G., Tran, L. M., Moberg, S., Steadman, P. E., Restivo, L., Morrison, F. G.,
et al. (2019). Memory formation in the absence of experience. Nat. Neurosci. 22,
933–940. doi: 10.1038/s41593-019-0389-0
Vine,
A.
L.,
and
Bertram,
J.
S.
(2002).
Cancer
chemoprevention
by
connexins. Cancer Metastasis Rev. 21, 199–216. doi: 10.1023/a:102125062
Vladimirov, N., and Sourjik, V. (2009). Chemotaxis: how bacteria use memory.
Biol. Chem. 390, 1097–1104. doi: 10.1515/BC.2009.130
Volkov, A. G., Toole, S., and WaMaina, M. (2019). Electrical signal transmission in
the plant-wide web. Bioelectrochemistry 129, 70–78. doi: 10.1016/j.bioelechem.
2019.05.003
von Dassow, G., and Munro, E. (1999). Modularity in animal development and
evolution: elements of a conceptual framework for EvoDevo. J. Exp. Zool.
285, 307–325. doi: 10.1002/(sici)1097-010x(19991215)285:4<307::aid-jez2>3.0.
co;2-v
von der Ohe, C. G., Darian-Smith, C., Garner, C. C., and Heller, H. C.
(2006).
Ubiquitous
and
temperature-dependent
neural
plasticity
in
hibernators. J. Neurosci. 26, 10590–10598. doi: 10.1523/JNEUROSCI.2874-06.
Voskoboynik, A., Simon-Blecher, N., Soen, Y., Rinkevich, B., De Tomaso, A. W.,
Ishizuka, K. J., et al. (2007). Striving for normality: whole body regeneration
through a series of abnormal generations. FASEB J. 21, 1335–1344. doi: 10.1096/
fj.06-7337com
Wagner, G. P., Pavlicev, M., and Cheverud, J. M. (2007). The road to modularity.
Nat. Rev. Genet. 8, 921–931. doi: 10.1038/nrg2267
Wang, X., Veruki, M. L., Bukoreshtliev, N. V., Hartveit, E., and Gerdes, H. H.
(2010). Animal cells connected by nanotubes can be electrically coupled
through interposed gap-junction channels. Proc. Natl. Acad. Sci. U.S.A. 107,
17194–17199. doi: 10.1073/pnas.1006785107
Warwick, K., Nasuto, S. J., Becerra, V. M., and Whalley, B. J. (1998). “Experiments
with an in-vitro robot brain,” in Computing with Instinct. LNAI 5897, ed. Y. Cai
(Berlin: Springer).
Watson, R. A., and Szathmary, E. (2016). How can evolution learn? Trends Ecol.
Evol. 31, 147–157. doi: 10.1016/j.tree.2015.11.009
Watson, R. A., Buckley, C. L., Mills, R., and Davies, A. (eds) (2010). “Associative
memory in gene regulation networks,” in Proceedings of the Artiﬁcial Life
Conference XII, (Odense).
Watson, R. A., Mills, R., Buckley, C. L., Kouvaris, K., Jackson, A., Powers,
S. T., et al. (2016). Evolutionary connectionism: algorithmic principles
underlying the evolution of biological organisation in evo-devo, evo-eco and
evolutionary transitions. Evol. Biol. 43, 553–581. doi: 10.1007/s11692-015-9
358-z
Watson, R. A., Wagner, G. P., Pavlicev, M., Weinreich, D. M., and Mills, R.
(2014). The evolution of phenotypic correlations and "developmental memory".
Evolution 68, 1124–1138. doi: 10.1111/evo.12337
Wentlandt, K., Samoilova, M., Carlen, P. L., and El Beheiry, H. (2006). General
anesthetics inhibit gap junction communication in cultured organotypic
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
hippocampal slices. Anesth. Analg. 102, 1692–1698. doi: 10.1213/01.ane.
0000202472.41103.78
West, S. A., Fisher, R. M., Gardner, A., and Kiers, E. T. (2015). Major evolutionary
transitions in individuality. Proc. Natl. Acad. Sci. U.S.A. 112, 10112–10119.
doi: 10.1073/pnas.1421402112
Williams, K., Bischof, J., Lee, F., Miller, K., LaPalme, J., Wolfe, B., et al. (2020).
Regulation of axial and head patterning during planarian regeneration by
a commensal bacterium. Mech. Dev. 163:103614. doi: 10.1016/j.mod.2020.10
Wolfe, C. T. (2008). Introduction: vitalism without metaphysics? Medical
vitalism in the enlightenment. Sci. Context 21, 461–463. doi: 10.1017/
s0269889708001919
Xue, Y., and Acar, M. (2018). Mechanisms for the epigenetic inheritance of stress
response in single cells. Curr. Genet. 64, 1221–1228. doi: 10.1007/s00294-0180849-1
Yang, C. Y., Bialecka-Fornal, M., Weatherwax, C., Larkin, J. W., Prindle, A.,
Liu, J., et al. (2020). Encoding membrane-potential-based memory within
a microbial community. Cell Syst. 10, 417–423.e3. doi: 10.1016/j.cels.2020.
04.002
Yang, C., Tibbitt, M. W., Basta, L., and Anseth, K. S. (2014). Mechanical memory
and dosing inﬂuence stem cell fate. Nat. Mater. 13, 645–652. doi: 10.1038/
nmat3889
Zahn,
N.,
Levin,
M.,
and
Adams,
D.
S.
(2017).
The
Zahn
drawings:
new illustrations of Xenopus embryo and tadpole stages for studies of
craniofacial development. Development 144, 2708–2713. doi: 10.1242/dev.15
Zhao, J., Yu, H., Luo, J. H., Cao, Z. W., and Li, Y. X. (2006). Hierarchical modularity
of nested bow-ties in metabolic networks. BMC Bioinformatics 7:386. doi: 10.
1186/1471-2105-7-386
Zoghi, M. (2004). Cardiac memory: do the heart and the brain remember the same?
J. Interv. Card Electrophysiol. 11, 177–182.
Author Disclaimer: The opinions expressed in this publication are those
of the author(s) and do not necessarily reﬂect the views of the John
Templeton Foundation.
Conﬂict of Interest: The author declares that the research was conducted in the
absence of any commercial or ﬁnancial relationships that could be construed as a
potential conﬂict of interest.
Publisher’s Note: All claims expressed in this article are solely those of the authors
and do not necessarily represent those of their aﬃliated organizations, or those of
the publisher, the editors and the reviewers. Any product that may be evaluated in
this article, or claim that may be made by its manufacturer, is not guaranteed or
endorsed by the publisher.
Copyright © 2022 Levin. This is an open-access article distributed under the terms
of the Creative Commons Attribution License (CC BY). The use, distribution or
reproduction in other forums is permitted, provided the original author(s) and the
copyright owner(s) are credited and that the original publication in this journal
is cited, in accordance with accepted academic practice. No use, distribution or
reproduction is permitted which does not comply with these terms.
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
GLOSSARY
The following deﬁnitions of terms used in this paper (in alphabetical order) represent ways of thinking about speciﬁc terminology in
the context of the proposed TAME framework. These terms have many deﬁnitions in other frameworks and are tightly interwoven,
and it is likely impossible to do them full justice at this point in time (or provide uncontroversial deﬁnitions that everyone will agree
capture everything of importance). Moreover, much like a theorem and its component statements, the utility of these highly-related
concepts is maximized by the entire set taken together, not by crisp demarcations of any one term. The below deﬁnitions are not
claimed to be uniquely correct, but merely useful; this ﬁeld is still suﬃciently young with respect to very basic questions, which
excessively sharp deﬁnitions can limit more than they enable.
• Agency—a set of properties closely related to decision-making and adaptive action which determine the degree to which optimal
ways to relate to the system (in terms of communication, prediction, and control) require progressively higher-level models
speciﬁed in terms of scale of goals, stresses, capabilities, and preferences of that System as an embodied Self acting in various
problem spaces. This view of agency is related to those of autopoiesis (Maturana and Varela, 1980) and anticipatory systems
(Rosen, 1985).
• Consciousness—the ﬁrst-person phenomenal experience of any Self—that which makes my toothache irreducibly diﬀerent to me
than anyone else’s toothache or third-person descriptions of toothaches. The degree and content of consciousness is “what it is
like” to be that Self, as opposed to studying it from the outside, whether or not the Self is advanced enough to be able to verbalize
it or to think about it (Nagel, 1974). Consciousness here is not meant to necessarily indicate advanced, reﬂexive, verbal selfconsciousness but rather the basal sentience (sense-process-respond loop) which is taken to be a continuum. Moreover, because
all cognitive agents are inevitably made of parts, we are all collective intelligences in a strong sense (Schwitzgebel, 2015)—what
it is like to be you is exactly what it’s like to be a (particularly organized) collection of cells.
• Cognition—all of the activities undertaken by a Self, at whatever scale and of whatever material implementation, that underlie
its gathering, processing, and acting on information for the purposes of adaptive action and perdurance against dissipation.
Components include active inference, learning, and basal goal-directed activity, as well as complex cognitive skills such as
symbolic reasoning, composition of concepts, language, and meta-cognition.
• Decision—an event during the traversal of some relevant space by a system’s state which is eﬃciently modeled as a choice
between diverse options. The degree of “decision-making” of any given system is proportional to the spatio-temporal and
complexity distance between the events that eventually gave rise to a speciﬁc outcome and the outcome itself. Advanced Selves
have inputs to their decision-making machinery that are counterfactual future states. The scale at which one deﬁnes appropriate
inputs (stimuli) to a system is whatever scale is most eﬃcient for understanding the resulting decisions (Noble, 2012; Pezzulo
and Levin, 2016; Flack, 2017).
• Mind—the functional, dynamic aspect of a Self that results from all of its cognitive and somatic activities, which represents the
propensities for certain types of actions and possesses some degree of sentience as a ﬁrst-person perspective that perdures across
changes in the material components of the body.
• Intelligence—the functional ability to solve problems in various spaces (not necessarily in 3D space), not tied to speciﬁc
implementations, anatomical structures, or time scales. The degree of intelligence (IQ) is proportional to competency in
navigating these spaces, including especially the ability to identify paths that temporarily lead further from the goal state but
eventually enable better results. Advanced intelligence exploits additional levels of self-modeling which enables multiple levels
of virtual modeling of the Self and its outside world (counterfactual thought), anxiety, and creativity (identifying opportunities,
as opposed to only solving problems existing right now). In particular, by focusing on the functional aspects of intelligence, and
by recognizing that there is no intelligent agent that is not made of parts, Collective Intelligence is generalized here (emphasizing
the architecture of functional connections between subunits) and is not viewed as a radically distinct natural kind.
• Maslow’s Hierarchy of Needs–a motivational theory of psychology that focuses on the relative types of preferences and goals
which human (or other) systems pursue at various stages and scales of observation (Maslow, 1943). It also stresses degrees of
integration and the modulation of higher levels by the level of stress in subunits.
• Self—a coherent system emerging within a set of integrated parts that serves as the functional owner of associations, memories,
and preferences, and acts to accomplish goals in speciﬁc problem spaces where those goals belong to the collective and not
to any individual sub-component. Selves are deﬁned by the spatio-temporal scale and nature of the types of goals they can
pursue—their “cognitive light cone.” They have functional boundaries and material implementations but are not identical with
any speciﬁc type of substrate, and can overlap within other Selves at the same, higher, and lower-level Selves. A Self is a theoretical
construct posited by external systems (such as scientists, engineers, and conspeciﬁcs) and by systems themselves (via internal
self-models), which facilitates prediction and adaptive behavior by serving as an eﬃcient, high-level target for intervention and
control strategies.
• Stress—a system-level state which serves as a driver for homeostatic loops (operating over a variable that is progressively reduced
as activity gets the system closer to its desired region of action space). The spatio-temporal and complexity scale of events that
can possibly stress a system are a good indicator of that system’s cognitive sophistication. Stress can arise via discord between
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201

Levin
Mind as It Can Be
external states and the Self’s needs, between sensory stimuli and expectations, or between the goals of multiple subsystems within
an agent, either within or across levels of organization. Thus, geometric frustration (Sadoc and Mosseri, 2007) and material
scientists’ notions of stress as a high-level determinant of system behavior over time (Batterman and Rice, 2014; Batterman, 2015)
are minimal examples of the fundamental concept of Stress, on the same continuum as metabolic stress in bacteria, competing
cellular alignment forces in planar polarity of tissues, and “true psychological stress” in organisms.
Frontiers in Systems Neuroscience | www.frontiersin.org
March 2022 | Volume 16 | Article 768201
